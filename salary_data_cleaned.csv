Job Title,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors,company text,same_place,age,python_yn,Spark,aws,excel
Senior Data Scientist - GAIA,"Date: Mar 26, 2020

Ericsson is one of the leading providers of Information and Communication Technology (ICT) to service providers. We enable the full value of connectivity by creating game-changing technology and services that are easy to use, adopt, and scale, making our customers successful in a fully connected world. Headquartered in Stockholm, Sweden, Ericsson is proud of its global presence across 100+ countries and market areas. With a strong focus on innovation, we possess 49 thousand registered patents and a global strength of over 95 thousand competent professionals. We also take pride in supporting networks that cater to a capacity of 40 percent of the world’s mobile traffic, thereby connecting more than 2.5 billion subscribers and counting. We are a world leader in the rapidly changing environment of communications technology – by providing hardware, software, and services to enable the full value of connectivity.

Senior Data Scientist – Product Development (Global AI Accelerator India)

Job Description

Ericsson Overview:

Ericsson is world’s leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planet’s greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Senior Data Scientists to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericsson’s global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Senior Data Scientist, you will need to have strong programming skills and deep understanding of data science and Machine Learning tools. Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Define the model validation strategy and business success criteria in data science terms
Identify the right architecture and flow for the data and DS model
Design the implementation and deployment strategy for the model into production
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with unstructured data including text and images in AI/ML models
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MI’s needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 5+ years of ML and/or AI production level experience; and an overall industry experience of around 10+ years.
Proven skills of implementing a variety of Machine Learning techniques
Experience in Security, Internet of Things is a plus
Strong skills in the use of current machine learning frameworks such as H2O, Keras, TensorFlow, Spark ML etc.
Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability
Experience with Big Data technologies such as Hadoop, Cassandra etc.
Good with effective big data storage and retrieval strategies including indexing, partitioning, etc.
Hands on working with data pipeline and flow
Hands on with API design/development for AI/ML models
Strong grounding in math and statistics.
Proven ability of leading projects end-to-end.
Proven experience writing production-grade software
Extensive experience in model development and AI model life-cycle-management in one or more industry/application domain
Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
Good communication skills in written and spoken English
Creativity and ability to formulate problems and solve them independently
Ability to build and nurture internal and external communities
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics. Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development. Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems","Ericsson-Worldwide
",0,144,1,1,1,0
Senior Data Scientist (ML/Deep Learning Expert),"Skills:
1. Good understanding of basics of Statistics, Probability, Linear Algebra and Calculus
2. Should be able to explain all ML/DS projects mentioned in resume
3. Good in qualitative and result interpretation
4. Good understanding of business problem
5. Profound understanding of basic DS and ML skills like outlier handling, data imputation, bias, variance, cross validation etc.
6. Good understanding of basic ML algorithm, like linear regression, logistic regression, random forest etc.
7. Take Ownership of on boarding new customers and continuously improve our existing.
8. Experience in building machine learning models or optimization software to solve business problems.
9. Ability to communicate results clearly to both colleagues and less technically versed audiences.
10. Knowledge of multivariate preferably in the Python Data ecosystem.
11. Good communication skills.
12. Passion to learn new tools, languages and frameworks
13. Good either at Python or R from DS perspective
Good in terms of Python
• Understand and uses pandas, numpy, scikit-learn and other scientific libraries
• effectively and efficiently.
• Understand basic data structure of python
• Write pythonic code
Good in terms of R.
• Good understanding on using packages like data. table, ggplot, dplyr etc.
• Good understanding of matrix algebra and memory management.

Desired Skills:
1. Basic understanding of version control systems
2. Experience of working in agile development environment.
Supply Chain Nation
Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values
Check out Blue Yonder's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates","Blue Yonder
",0,35,1,0,0,0
Data Scientists,"CAREERS

Data Scientists

Bengaluru, India
JOB DESCRIPTION

As a Data Scientist with Tredence, you will play a key role in translating data into insights for our clients. You will design, develop and implement processes and framework that will help our clients make sense of the data they generate, and consume the insights to make informed decisions.
THE IDEAL CANDIDATE WILL

Have the ability to handle structured /unstructured data and have prior experience in loading, validating and cleaning various types of data.
Have very good understanding of data structures and algorithms.
Have excellent coding skills in one or more of the following languages: Python, Java, C++ or R
Have thorough understanding of one or more of the following: Machine Learning algorithms, Natural Language Processing techniques, and Information Retrieval techniques
Have the ability to apply these algorithms in a professional setting.
Be accountable for measuring and optimizing the quality of algorithms.
Have good background in Math and Statistics.
Have ability to identify opportunities where data science techniques can be applied to solve business problems.
Take ownership of the end to end system from Problem statement to Solution Delivery
Preferred Skills
Experience working with Hadoop/AzureML/Hive/H2O would be an added advantage.
Experience with deep learning techniques like Theano, Torch and TensorFlow is preferred.
ELIGIBILITY CRITERIA

BE/B. Tech/MS degree in Computer Science or related quantitative field with 2-8 years or relevant experience in a team building world class applications in the areas of Predictive Analytics and Data Science.
Send your CV to careers@tredence.com",3.7,"Tredence
3.7",Bengaluru,"San Jose, CA",501 to 1000 employees,2013,Company - Private,Consulting,Business Services,₹1 to ₹5 billion (INR),-1,"Tredence
",0,7,1,0,0,1
"Staff Engineer, Machine Learning","Twilio seeks a Staff Machine Learning Engineer to be a key leader in defining a new product offering at Twilio in the customer engagement space. The person in this role will be critical in shaping Twilio's data and intelligence strategy, which will empower our customers to create highly personalized communications and experiences for their contacts. Come be part of a team that's building a set of ML-driven APIs that deliver intelligent audience and personalization recommendations.

Who?

You have:
Personal traits: Curious, humble, team player
Professionally: Passionate, customer-obsessed, gets things done, highly collaborative, excellent communicator, and very comfortable with rapid change and uncertainty
You have hands on experience developing, deploying and monitoring a large scale machine learning model in production
Ph.D. or MS in Computer Science, Statistics, or related field
5+ years of applied ML experience in statistical and mathematical modeling such as supervised and unsupervised machine learning, deep learning, and/or reinforcement learning
You are familiar with concepts related to testing and maintaining models in production such as A/B testing, retraining, monitoring model performance
You've explored modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as DynamoDB or similar
You have a deep understanding of frameworks like - PyTorch, TensorFlow, or Keras, why and how these frameworks do what they do
Proficiency in Python is preferred. We will also consider strong quantitative candidates with a background in other programming languages
Experience working in an agile team environment
Big plus: Experience in AWS cloud computing
What?

You live the Twilio Magic values:
EMPOWER OTHERS: Be part of a small, high-impact and multi-talented engineering team. Show strong engagement in the team setting
WEAR THE CUSTOMER'S SHOES: Passion for and demonstrated track record of executing product opportunities deeply grounded in customer needs
DRAW THE OWL: Self-starter who can see the big picture and prioritize work to make the largest impact
BE BOLD: Help us take one of the world's most extensive communication data sets and transform it into leading-edge AI applications and products that solve meaningful customer problems
BE INCLUSIVE: Collaborating and brainstorming product ideas with product managers, data scientists and engineers
DON'T SETTLE: Experienced working at a massive scale with distributed, scalable systems, including making tradeoffs for consistency/availability
NO SHENANIGANS: Experience successfully applying machine learning to real-world problems
Why?

Today, Twilio powers the delivery of billions of the world's communications. Increasingly, we're hearing from our B2C customers that they're struggling to harness the massive amounts of valuable data they generate, much of which stems from the communications we help them send. We seek to uncover how Twilio can help customers utilize their valuable data to create unique, individualized experiences that their competitors can't replicate. We want to help them become more proactive (outcome-driven) than reactive (event-driven) in their customer engagements. We are a new initiative and team at Twilio that will function much like an internal start-up. If you want to shape the future of B2C Customer Engagement and Twilio, this project is for you!

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands, and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About us:

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1,"Twilio
",0,12,1,1,1,1
Data Scientist Intern,"Amazon's looking for Data Scientist to optimize one of the most complex logistics systems in the world. Academic and/or practical background in Computer Science, Engineering, Operations Research, or Process Control are particularly relevant for this position. Experience in the integration of model-based engineering tools and/or multidisciplinary analysis & optimization is also a plus.
Major Responsibilities:
· Use data analyses and statistical techniques to develop solutions to improve customer experience and to guide business decision making
· Identify predictors and causes of business related problems and implement novel approaches related to forecasting and prediction
· Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations
· Collaborate with multiple teams as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity
· Analyze and solve business problems at their root

Basic Qualifications

· Pursuing Masters or equivalent advanced degree from a top tier Technology school
· Record of delivering large analytical solutions with business impact
· Experience on R/SAS/Matlab and SQL
· Excellent Microsoft Office skills, including a strong working knowledge of Excel
· Problem solving ability and passion for big data
Excellent communication and data presentation skills
· Fluent written and spoken English

Preferred Qualifications

Masters or equivalent advanced degree in Computer Science, Computer Engineering, Statistics, Mathematics or related technical discipline. Hands-on experience and project based learning in computer science, engineering or mathematics is preferred.
• Academic experience in manipulating/transforming data, model selection, model training, cross-validation and deployment at scale.
• Academic or Project Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and PyTorch.
• Academic Experience with Big Data platforms like Apache Spark and Hadoop.
• Familiarity with data processing with Python, R & SQL.
• Familiarity with AWS services related to AI/ML highly desirable, particularly Amazon EMR, AWS Lambda, SageMaker, Machine Learning, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Green Grass etc.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,1,1,1
Machine Learning Engineer,"Role: Machine Learning Engineer

Job Description-

3+ years- experience in machine learning using SciKit-learn, Keras, TensorFlow, and/or Torch.
Project & Team Leadership capabilities
Healthcare experience preferred.
Production-level ML in cloud environment (AWS / Azure / GCP)
NLP and/or Imaging (DNNs) experience
Expertise in causal inference
Data science consulting experience - Understanding customer's business problem and designing data science solutions

Location - Mumbai & Bangalore

Education Background- Statistics and Mathematics background

Responsibilities:
The Data Scientist is responsible to perform statistical and Machine Learning/Deep learning research and help in delivery tasks related to CT products, solutions and services.
Developing advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner Implementing statistical and data mining techniques e.g. hypothesis testing, machine learning, and retrieval processes on a large amount of data to identify trends, patterns and other relevant information
Understanding and the experience on the data science model development and operationalization lifecycle
Lead multiple data science projects and help delivery lead in end to end delivery.",3.5,"Antal International
3.5",Bengaluru,"London, United Kingdom",1001 to 5000 employees,1993,Franchise,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,"Antal International
",0,27,0,0,1,0
Machine Learning/Deep Learning Experts,"We at CrunchMetrics are looking for talented Machine Learning Scientist with a background in Machine Learning development who desires to work on building solutions to complex challenges and can create, innovate, and define the next generation of autonomous analytics solutions. This role requires an expert level of data science knowledge as well as experience with data science techniques, systems and processes.

The position will report to the Head of Strategy and Products at CrunchMetrics and will be based in Bangalore, India

Info
Category :AI
Job Code :CMA01
No. of openings :7
Skills
Qualifications
BRIEF
6-8 years proven experience in building Machine Learning/ Deep Learning based solutions/ products.
Strong hands on skill in Python using libraries like NLTK, SkLearn or Hands on in R and Java.
Proven background in at least one of the following – Reliability models, Markov Models, Stochastic models, Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Non-parametric Methods, Multivariate Statistics.
Experience working with large data sets and tools like Elastic Search, Spark and Hive.
Excellent communication skills including the ability to present technical concepts to a wide range of audiences, both internal and external.
Ability to work effectively across teams.",-1.0,CrunchMetrics,Bengaluru,"Broomfield, CO",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,CrunchMetrics,0,-1,1,1,0,1
Data Scientist,"What You Should Expect

To ride the wave of AI/ML with deeply enmeshed Operations Research and Mathematics to make real impact in the world of Supply Chain Planning, Retail and Execution.

What your work will be

» Develop and operate solutions that optimize and automate business decisions using large data sets and algorithms

» Work with complex data analysis, data preparation and developing prognostic models based on modern statistical methods

» Develop a deep understanding of retail and supply chain problems

» Write productive software that generates value for our customers

Apply if you have

» Good understanding and insight of Machine Learning Techniques – Supervised, Unsupervised or Semi-Supervised

» Passion for writing software with emphasis on quality, testability and automation

» Experience in building machine learning models or optimization software to solve business problems

» Ability to communicate and contextualize results

We believe that the individuality and diversity of our employees make a decisive

contribution to our success. Our hiring process is based on qualifications and career profile.

Our Values

If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success – and the success of our customers. Does your heart beat like ours? Find out here: Core Values

Check out JDA's blog - Supply Chain Nation - the platform for supply chain trends and innovations.",4.3,"Blue Yonder
4.3",Bengaluru,"Scottsdale, AZ",5001 to 10000 employees,1985,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 billion (INR),"SAP, Oracle, Manhattan Associates","Blue Yonder
",0,35,0,0,0,0
Director Machine Learning,"Requirements

We are looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning, Pattern Recognition, Natural Language Processing, Computational Linguistics, Statistical Modelling, Inferencing, Information Retrieval, Large Scale Distributed Systems, Cloud Computing, Econometrics, Quantitative Marketing, Applied Game Theory, Mechanism Design, Operations Research, Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply.

We are looking for someone who can create and implement AI solutions. If you have built a product like IBM WATSON in the past and not just used WATSON to build applications, this could be the perfect role for you.

All successful candidates are expected to dive deep into problem areas of Zycus’ interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage the organization.

Skills:
Experience in predictive modelling and predictive software development
Skilled at Java, C++, Perl/Python (or similar scripting languages)
Experience in using R, Matlab, or any other statistical software
Experience in mentoring junior team members, and guiding them on machine learning and data modelling applications
Strong communication and data presentation skills
Classification (svm, decision tree, random forest, neural network)
Regression (linear, polynomial, logistic, etc)
Classical Optimization(gradient descent, newton raphson, etc)
Graph theory (network analytics)
Heuristic Optimisation (genetic algorithm, swarm theory)
Deep learning (lstm, convolutional nn, recurrent nn)
Roles & Responsibilities:
Act as a technical thought leader in collaboration with the analytics leadership team, helping to set the strategy and standards for Machine Learning and advanced analytics
Work with senior leaders from all functions to explore opportunities for using advance analytics
Provide technical leadership, coaching, and mentoring to talented data scientists and analytics professionals
Guide data scientists in the use of advanced statistical, machine learning, and artificial intelligence methodologies
Guide the work of other Machine learning team members to provide support and assistance, while also ensuring quality
Must Have:
Total experience: 14+ years
The ideal candidate must have proven expertise in Artificial Intelligence (including deep learning algorithms), Machine Learning and/or NLP
The candidate must also have expertise in programming traditional machine learning algorithms, algorithm design & usage
Programming expertise on Python or R
Preferred experience with large data sets & distributed computing in Hadoop ecosystem
Strong problem-solving skills
Fluency with databases
Benefits",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc","Zycus
",0,22,1,0,0,0
Machine Learning Engineer - Customer Engagement,"Because you belong at Twilio.

The Who, What, Why and Where

Twilio seeks a Machine Learning Engineer to be a key leader in defining a new product offering at Twilio in the customer engagement space. The person in this role will be critical in shaping Twilio's data and intelligence strategy, which will empower our customers to create highly personalized communications and experiences for their contacts. Come be part of a team that's building a set of ML-driven APIs that deliver intelligent audience and personalization recommendations.

Who?

You have:
Personal traits: Curious, humble, team player
Professionally: Passionate, customer-obsessed, gets things done, highly collaborative, excellent communicator, and very comfortable with rapid change and uncertainty
You have hands on experience developing, deploying and monitoring a large scale machine learning model in production
Ph.D. or MS in Computer Science, Statistics, or related field
4+ years of applied ML experience in statistical and mathematical modeling such as supervised and unsupervised machine learning, deep learning, and/or reinforcement learning
You are familiar with concepts related to testing and maintaining models in production such as A/B testing, retraining, monitoring model performance
You've explored modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as DynamoDB or similar
You have a deep understanding of frameworks like - PyTorch, TensorFlow, or Keras, why and how these frameworks do what they do
Proficiency in Python is preferred. We will also consider strong quantitative candidates with a background in other programming languages
Experience working in an agile team environment
Big plus: Experience in AWS cloud computing
What?

You live the Twilio Magic values:
EMPOWER OTHERS: Be part of a small, high-impact and multi-talented engineering team. Show strong engagement in the team setting
WEAR THE CUSTOMER'S SHOES: Passion for and demonstrated track record of executing product opportunities deeply grounded in customer needs
DRAW THE OWL: Self-starter who can see the big picture and prioritize work to make the largest impact
BE BOLD: Help us take one of the world's most extensive communication data sets and transform it into leading-edge AI applications and products that solve meaningful customer problems
BE INCLUSIVE: Collaborating and brainstorming product ideas with product managers, data scientists and engineers
DON'T SETTLE: Experienced working at a massive scale with distributed, scalable systems, including making tradeoffs for consistency/availability
NO SHENANIGANS: Experience successfully applying machine learning to real-world problems
Why?

Today, Twilio powers the delivery of billions of the world's communications. Increasingly, we're hearing from our B2C customers that they're struggling to harness the massive amounts of valuable data they generate, much of which stems from the communications we help them send. We seek to uncover how Twilio can help customers utilize their valuable data to create unique, individualized experiences that their competitors can't replicate. We want to help them become more proactive (outcome-driven) than reactive (event-driven) in their customer engagements. We are a new initiative and team at Twilio that will function much like an internal start-up. If you want to shape the future of B2C Customer Engagement and Twilio, this project is for you!

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands, and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About us:

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1,"Twilio
",0,12,1,1,1,1
Senior Data Scientist,"Amazon strives to be Earth's most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce platform. Amazon's evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the company's DNA.

Amazon Seller Services is looking for a Data Scientist to work hands on from concept to delivery on statistical analysis, prescriptive and predictive analysis, and machine learning implementation projects. We are looking for a problem solver with strong analytical skills and a solid understanding of statistics & Machine learning algorithm as well as a practical understanding of collecting, assembling, cleaning and setting up disparate data from enterprise systems.


Responsibilities:
· Understand business and figure out white spaces where machine learning methods can be applied for improving the process, expansion of business, profitability or for solving sellers or customer pain points.
· Understand a business problem and the available data and identify what statistical or machine learning techniques can be applied to answer a business question.
· Given a business problem, estimate solution feasibility and potential approaches based on available data.
· Understand what data is available, where, and how to pull it together. Work with partner teams where needed to facilitate permissions and acquisition of required data.
· Utilise Amazon systems and tools to effectively work with terabytes of data.
· Quickly prototype solutions and build models to test feasibility of solution approach.
· Build statistical models/ ML models, train and test them and drive towards the optimal level of model performance.
· Work with technology teams to integrate models by wrapping them as services that plug into Amazon's marketplace and fulfilment systems.
· Automate feedback loops for algorithms in production.
· Work across the spectrum of reporting and data visualisation, statistical modeling and supervised learning tools and techniques and apply the right level of solution to the right problem
· The problem set covers aspects of detecting fraud and abuse, improving performance, driving lift and adoption, recommend the right up-sell to the right audience, cost saving, selection economics and several others.
· Responsible for management and professional development of junior data scientist.



Basic Qualifications

· A MS or PhD in Computer Science or Machine learning or Operational research or Statistics or in a quantitative field with 5+ years of experience.
or
· 8+ year of experience and a bachelors degree in a technical field, preferably statistics, math or computer science is desired.
· A very strong grounding in applied statistical modeling and a very strong grasp of statistical concepts. Must be comfortable in the world of numbers, models, and algorithms
· A strong level of proficiency in Python is required
· Willingness to dive deep and work on difficult and ambiguous problems with unknown outcomes.
· Ability to partner and work efficiently with partner teams and stakeholders is critical.
· Strong grasp of machine learning, data mining and data analytics techniques
· Strong Problem solving ability.
· Understanding of how to apply predictive and machine learning techniques like logistic regression, random forest, GBM, Neural Nets, SVM etc is required
· Understanding of databases (RDBMS, NOSQL) from a perspective how to write queries and pull data from them is essential.
· 2+ years of team handling experience is required.
· Experience of putting ML model into production is required.

Preferred Qualifications

· A strong level of proficiency in SAS, R is preferred.
· Past publications in journals of repute.
· Conceptual understanding of Hadoop and cloud computing like AWS is preferred
· Demonstrated participation in contests like Kaggle is a plus
· Experience in the eCommerce, marketplace or supply chain areas is a plus.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,1,0
Developer Technology Engineer - AI,"NVIDIA is looking for a passionate, world-class computer scientist to work in its Compute Developer Technology (Devtech) team.

What you will be doing:
Study and develop cutting-edge techniques in deep learning, graphs, machine learning, and data analytics, and perform in-depth analysis and optimization to ensure the best possible performance on current- and next-generation GPU architectures.
Work directly with key customers to understand the current and future problems they are solving and provide the best AI solutions using GPUs.
Collaborate closely with the architecture, research, libraries, tools, and system software teams at NVIDIA to influence the design of next-generation architectures, software platforms, and programming models.
What we need to see:
A good degree from a leading university in an engineering or computer science related discipline (BS; MS or PhD preferred).
Strong knowledge of C/C++, software design, programming techniques, and AI algorithms.
Experience with parallel programming, ideally CUDA C/C++.
Strong communication and organization skills, with a logical approach to problem solving, good time management, and task prioritization skills.
You will need to travel from time to time for conferences and for on-site visits with developers.

Artificial intelligence, the dream of computer scientists for over half a century, is no longer science fiction. And in the next few years, it will transform every industry. Soon, self-driving cars will reduce congestion and improve road safety. AI travel agents will know your preferences and arrange every detail of your family vacation. And medical instruments will read and understand patient DNA to detect and treat early signs of cancer.

Where engines made us stronger and powered the first industrial revolution, AI will make us smarter and power the next. What will make this intelligent industrial revolution possible? A new computing model — GPU deep learning — that enables computers to learn from data and write software that is too complex for people to code.

NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant and talented people in the world working for us. Are you a creative and autonomous computer scientist with a genuine passion for parallel computing? Do you love a challenge? If so, we want to hear from you. Come, join our AI Compute DevTech team and help build the real-time, cost-effective computing platform driving our success in this exciting and quickly growing field.

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",4.5,"NVIDIA
4.5",Bengaluru,"Santa Clara, CA",10000+ employees,1993,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),-1,"NVIDIA
",0,27,0,0,0,0
ML (Machine Learning) Engineer,"Danaher Corporation
Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world

Danaher generates over $18 billion USD of annual revenue from five business segments: Life Sciences, Diagnostics, Dental, Water Quality, and Product Identification.

For additional company details, see www.danaher.com. Danaher Digital
Danaher Digital is our digital innovation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers.
Position Description
This position reports to Head of Data & Analytics and is responsible to help the Danaher Digital data science team develop, design and integrate mathematical models into production. You will be working cross-functionally with the Data Scientists, Software application developers and business groups and lead the development of innovative ML models for Danaher’s big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams. Responsibilities
Primarily responsible for productionizing pipelines/models and integrating them against our back-end services
Drive the system architecture and design decisions for Danaher Digital’s machine learning infrastructure, for both cloud and on-premise environments
Design, develop, determine test strategy, test, and maintain key software improvements related to machine learning capabilities at Danaher Digital.
Enjoy working in a collaborative team with data scientists, software leads, Product Owners/Product Managers from other business units and/or customers, to develop high-value solutions for our most complex data-based challenges.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
8+ years of commercial or open source product development experience, preferably in large scale cloud computing and/or distributed systems environments.
Knowledge in python and packages for data analysis (scikit-learn, scipy, numpy, pandas, matplotlib).
Knowledge of Deep Learning frameworks: Keras, Tensorflow, PyTorch, etc
5+ years of programming in large scale production systems, in languages such as Python, Java, Scala or C++.
Experience with one or more Container-ecosystem (Docker, Kubernetes)
Experience in building orchestration pipeline to convert plain python models into a deployable API/RESTful endpoint.
Good communication skills and team player attitude.
Bachelors in Computer Science or related fields",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,1,0,0,0
Machine Learning Engineer,"Description

Unbxd is an AI-driven eCommerce Search Platform that understands shopper intent and connects them to the products they are most likely to buy — across site search, navigation and recommendation purchase journeys.

The platform combines AI-based automation, powerful merchandising controls, and extensive user experience capabilities to enhance the onsite shopper experience and increase revenue for online retailers.

Your Role

As part of our Data Science team, you will solve some of the most challenging and impactful problems in Information Retrieval, NLP, Machine Learning, Deep Learning and Recommender Systems. In close coordination with the Data Scientists, you will design and develop Machine Learning models that will understand a user’s intent across modalities and devices, enabling them to make the right purchasing decisions. You will have the opportunity to build models across different verticals (fashion, home, electronics, autos, etc) to drive better user conversion and user engagement.

What you’ll do

Be a thought leader in identifying the right set of problems that will delight our customers.

Design and implement state of the art Machine Learning and AI algorithms into our products.

Integrating ML components into a fully functional software system.

Writing well-designed, testable, efficient code.

Become an expert in IR, NLP and help make an impact on the broader community as an Unbxd Brand Ambassador.

About You

Must have:

You have BS/BTech/MS/MTech (with 2+ years relevant experience) in Computer Science, Information Technology, Mathematics, Statistics or similar fields.

You are extremely strong in Algorithms, Data Structures and basic probability.

You have strong technical and programming skills(Python/R/Java).

You have strong problem solving and analytical skills.

You have basic understanding and demonstrable strong interest in two or more of Machine Learning, Information Retrieval, Natural Language Processing, Deep Learning, Recommender Systems or related fields.

You have an understanding of the full software development lifecycle.

You can work independently with little supervision to research and test innovative solutions

You have strong communication skills to influence and make the team around you better

You have demonstrated the ability to quickly prototype ideas to solve complex problems

You are able to prioritize and handle multiple tasks and changing priorities

Good to have:

You have hands-on implementation experience with building machine learning models into products.

You have hands-on experience with some ML frameworks like TensorFlow, PyTorch, Keras, Sklearn, nltk or similar.

You are familiar with Big Data technologies

You have experience working with Solr or other search platforms",3.7,"Unbxd Inc
3.7",Bengaluru,"Bengaluru, India",51 to 200 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,"Unbxd Inc
",1,9,1,0,0,0
Applied Scientist,"Amazons Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. We build software to find products not already sold on Amazon and algorithmically add them to the Amazon catalog. Our work involves building Information Retrieval (IR) infrastructure, Machine Learning systems, and distributed compute and storage systems to process data at cloud-scale to extend and enrich the Amazon catalog. We apply the state- of- the-art Web-mining, Cloud Computing and Deep Learning to process millions of products from the web every day and make the data actionable. We constantly stretch the boundaries of Machine Learning to tackle business challenges. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.

We are looking for ML Scientist to tackle challenging problems in the areas of information retrieval at internet scale using data science. You should have depth and breadth of knowledge in text mining, information retrieval and deep learning. You should also have programming and design skills to manipulate unstructured data and systems that work at internet scale.


You will encounter many challenges, including
· Scale (build models to handle billions of pages),
· Accuracy (extreme requirements for precision and recall),
· Speed (generate predictions for millions of new or changed pages with low latency),
· Diversity (models need to work across different languages, market places and data sources)

Come join us in our journey to make everything and yes, we do mean *everything* that anyone wants to buy, available on Amazon!

Basic Qualifications


· Bachelors/Master Degree in Computer Science with advanced degrees preferred.
· 5+ years of hands on experience in building machine learning systems for large data sets.
· Strong skills in problem solving, programming and computer science fundamentals.
· Expertise in using Python, Java / C++, or other programming languages, as well as ML toolkits such as scikit-learn, Theano, Tensorflow, Keras or similar machine learning tools.



Preferred Qualifications


· PhDs, specialized in Information Retrieval and Machine Learning.
· Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
· Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,0,0
Data Science Specialist / Sr. Data Scientist,"Function : Clustr

Experience : 8-12 yrs

Why should you join us?

Work in an exciting start-up that builds first-of-its-kind product and services

Access to a unique dataset covering > 85% of SMEs with unmatched diversity and complexity

Opportunity to build truly state-of-the-art algorithms and insight engines that consume and digest complex “Big” data and extract value out of them

Learning and exposure to multiple engineering areas (including Big Data technologies, DevOps) surrounded by a top-quality team

Accelerate your career in a fast-paced, open, non-hierarchical working environment

The Data Science team at Clustr builds algorithms and Machine Learning models that sit at the core of the company’s value proposition. This is a team of intellectuals with high aptitude, hacker attitude, strong curiosity about data, great comfort with Math, good coding discipline and excellent communication skills.

What will you be doing?

Data Science Specialist will be involved in all stages of the DS-based solution development cycle, working with various stakeholders in framing, designing and executing DS solutions considering both functional and non-functional aspects

Data Science Specialist would be in-charge of: translating a business problem to a DS problem, scope definition, data cleaning, explorations, feature engineering, feature selection, modeling, building prototype, documentation of an algorithm and insights. You would be involved in building scalable Machine Learning models for various problems in the areas of information extraction, entity resolution and linking knowledge base curation, machine translation, information retrieval and others

Involvement in all stages of the development cycle - building scalable machine learning models for various problems in the areas of information extraction, entity resolution and linking, knowledge base curation, machine translation, information retrieval and others

Who are we looking for?

D. or MS/M. Tech with 4+ years of experience or BE/B. Tech with 8+ years of experience in Data Science, Machine Learning, or NLP

Experience of working on production-grade Machine Learning-based solutions would be a plus

Prior publication record at AI/ML conferences would be a plus

Ability to formulate a business problem as a DS/ML problem, hypothesize, design, iterate and productionize solutions

Ability to scale and deploy DS-based solutions in production

Strong communication skills and ability to work with stakeholders across business, PM, and Engineering

Excitement & curiosity around data in general “Hacker” attitude with “go-getter” mind-set

High level of comfort with Math and ability to quickly master deep Mathematical concepts

In-depth understanding of Machine Learning techniques

Experience with Text Mining including hands-on knowledge of at least a few of the following areas: Information extraction, Natural Language processing, Knowledge graphs, Semantic Search, Information Retrieval, Probabilistic graphical models, Deep learning and Bayesian Learning techniques

Very good coding skills in any of these languages: R, Python, Matlab, Java, C and Machine Learning libraries like scipy, numpy, pyspark, tensorflow etc

Basic knowledge of Big Data stack: Spark, Cassandra, Map-Reduce, S3

Train/Mentor other team members

Keep abreast of the current state-of-the-art in Machine Learning and NLP areas

Prior experience with start-up environment preferred
Ready to join Clustr?
If you fit the bill, email your resume to careers@clustr.co.in with the position name in subject line",4.5,"Clustr
4.5",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,"Clustr
",1,7,1,1,0,1
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelor’s degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years’ experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. You’ll also get to visit other locations in India and beyond, so you’ll need to go where this journey takes you. In return, you’ll get the chance to work with teams impacting entire cities, countries – and the shape of things to come.

We’re Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.1,"Siemens Healthineers
4.1",Bengaluru,"Erlangen, Germany",10000+ employees,1847,Company - Public,Healthcare Services & Hospitals,Healthcare,₹500+ billion (INR),"GE Healthcare, Roche","Siemens Healthineers
",0,173,0,0,0,0
Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision),"Research Engineer - Data Analytics & Artificial Intelligence (Machine Vision)

With over 1900 researchers, Corporate Technology (CT) occupies a special position within Siemens' R&D facilities. It functions as an international network of expertise and as a global partner for technology and innovations.

Our Research Group (Advanced Data Management) is part of Business Analytics and Monitoring (BAM) Technology Field of CT Research. Headquartered in Munich, we are a hardworking distributed team of around 240 researchers, data scientists and architects distributed across the globe. In the team in Bangalore where we are based out of, we strive to seek complex problems in various domains ranging from mobility, industry, energy, and buildings to smart cities by applying methods and principles of data analytics and artificial intelligence. We are looking for equally hardworking techies to join us in this exciting journey of finding innovative solutions to some non-trivial industrial problems.

Change the Future with us

• You will analyze large, complex data sets by developing advanced machine learning and deep learning pipelines based on business initiatives.

• Your ability to move beyond theoretical models and build innovative, practical and robust real-world solutions for problems in traffic management, autonomous building control for energy and comfort optimization, medical image analysis for assisting pathologists/radiologists, smart robotics for Industry 4.0 will make valuable contribution.

• You will find it exciting to dive deep into an ocean of data and seek challenges associated with transforming and enriching large complex datasets.

• You will drive innovation and research in the form of patents and publishing papers at outstanding conferences/journals?

What you need to make real what matters

• You have PhD/Masters/Bachelors degree in Computer Science or related field from a reputed institute with grass-root experience of at least 2 years in solving complex problems.

• Closely follow the latest developments in artificial intelligence and be an early adopter of disruptive trends/technologies

• Collaborate with team members from prototyping through production, present developed solutions and recommendations to business partners, and influence future product roadmap and strategy based on insights

• Research, develop and prototype software technologies related to Object detection, tracking, 3D reconstruction, SLAM and photometric stereo

• Experience in Machine Learning techniques such as Forecasting, Classification, Clustering, Text Mining, Decision Trees, Random Forest and Search algorithms

• Understanding and tried hands-on experience in training deep convolutional and/or recurrent networks using frameworks like Tensorflow, Caffe, MXNet, etc.

• Minimum of 1-2 years experience working on image processing and computer vision problems with a clear understanding and ability to implement algorithms (especially deep learning algorithms)

• Hands-on experience using OpenCV and OpenGL

• Optimization techniques for model training and deployment on GPUs

Make your mark in our exciting world at Siemens

This role is based in Bangalore. Youll also get to visit other locations in India and beyond, so youll need to go where this journey takes you. In return, youll get the chance to work with teams impacting entire cities, countries and the shape of things to come.

Were Siemens. A collection of over 379,000 minds building the future, one day at a time in over 200 countries. We're dedicated to equality, and we welcome applications that reflect the diversity of the communities we work in. All employment decisions at Siemens are based on qualifications, merit and business need. Bring your curiosity and imagination, and help us shape tomorrow.

Find out more about department at: Corporate Research, Siemens India at www.ct.siemens.com and about Siemens careers at: www.siemens.com/careers

Organization: Corporate Technology

Company: Siemens Technology and Services Private Limited

Experience Level: Mid-level Professional

Job Type: Full-time",4.0,"Siemens
4.0",Bengaluru,"Munich, Germany",10000+ employees,1843,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),"GE, ABB, Philips","Siemens
",0,177,0,0,0,0
Data Scientist-1,"Required Technical Skills
Good understanding of machine learning (both analytics and engineering).
Hadoop and big data technologies skills, streaming technology.
Robotics Process Automation techniques.
Artificial Intelligence.
Analytical mindset.
Good in Data Structure.
Good in Problem solving.
Preferred Technical Skills
Deep understanding of statistics and ML algorithms work internally with proficiency in at least 2 supervised and unsupervised algorithms in each bucket.
Supervised algorithms : Regression [linear/polynomial], Decision Tree, Random Forest or classification [Logistic Regression, Naïve Bayes, SVM etc]
- Model design and implementation : Experience in deriving feature sets, model training and testing

- Preferred tools and programming languages: TensorFlow/Keras, Python

- Exposure to Deep Learning and NLP is an added advantage.

Required Soft Skills
A team player who values collaboration, innovation, and inclusion.
Interested in keeping update with the latest technological developments.
Comfortable working in an Agile environment.
Strong verbal and written communication skills.
Interest in the payments industry.",3.5,"Siemens
4.0",Bengaluru,"San Jose, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Square, Amazon, Apple","Siemens
",0,22,1,0,0,0
Principal Data Scientist & Software Development Manager,"Introduction
As a Data Scientist at IBM, you will help transform our clients data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether its investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities

IBM Global Technology Services (GTS) is the IT infrastructure and business process services segment of IBM, one of the largest IT and software companies in the world.

GTS Analytics team in IBM is building new innovative AIOPS solution by combining big data with Machine Learning and Deep Learning

AIOPS refers to multi-layered technology platforms that automate and enhance IT operations by using analytics and machine learning to analyse big data collected from various IT operations tools and devices, in order to automatically spot and react to issues in real time. AIOPS bridges three different IT disciplinesservice management, performance management, and automationto accomplish its goals of continuous insights and improvements.

Some of the Solutions we work involve the following

Ø Real time anomaly detection solutions that proactively identify service impacting incidents and prevent system downtimes. This is done by leveraging an ensemble of Deep learning and LSTM models.

Ø Natural Language Processing for entity, topic clusters and relationship extraction

Ø Text Analytics in human generated tickets and correlation with event tickets for event noise reduction. ApplyNatural Language Classification and RNN algorithms to automatically route tickets

Ø Log Analysis - Text mining, message clustering / templatization, Logs to metrics, anomaly detection, event annotation and sequencing

Ø Learn Log Message Sequence for each mainframe batch job and Identify Anomalies during job runs using sequence mining techniques and provide early warning / alerts

Ø Cloud Migration - Patterns-based discovery optimization: Identify potential business application boundaries using algorithmic approach from Cloudscape data.

Ø Wave planner: Employ goal-based reasoning from AI planning capabilities for Server affinity, cost, time, black-out windows, etc.

To power the above use cases, we have a Big Data system that can handle 2-3 TB of data daily and we manage a data lake that is 15 PB in size.

As a Principal Data Scientist, you will be responsible for identifying and supporting current and new hypotheses. With your understanding of complex concepts, you will translate hypotheses into actionable items that are understandable by non-technical business users.

As a Principal Data Scientist you will take the lead to provide strategic direction on large scale business problems. You understand challenges in multiple business domains, are able to discover new business opportunities and at times you may not even fully understand what the problem is before starting. The problems we address are significantly complex and we expect you to lead excellence in our data science methodologies. You have scientific and industrial maturity to deliver designs and algorithms that set the standard for the organization. You have a distinct ability to identify and implement robust, efficient and scalable solutions that leverage multiple techniques and/or technologies

You will gather, evaluate and document business use cases in the IT Infrastructure and Cloud domain and translate them to data science solution definition . You will Provide guidance and architecture support to platform development teams and oversee the development from initial concept to production deployment

Required Technical and Professional Expertise
Master's degree in a quantitative field such as computer science, applied mathematics, statistics, physics, engineering or finance
6+ years of industrial experience in implementing data science or AI solutions from exploration to production
3+ years of experience in a responsible senior or team lead role managing a team of data scientists who develop robust machine learning models to solve actual business problems
Extensive overview of applied methods in statistics, machine learning and artificial intelligence
Solid understanding of data analytics infrastructure and data engineering: data storage and retrieval, ETL pipelines, Docker, Kubernetes
Knowledge of software engineering practices such as version control, continuous delivery, unit testing, documentation, release management
Experience in natural language processing, text analytics, data mining, text processing or other AI subdomains and techniques
Preferred Technical and Professional Expertise
Experience with open-source distributed data processing frameworks, such as Spark
Experience working in a Linux environment
Experience working on a development team building product
Experience with presenting complex data science processes/information to non-data scientists
Experience with Information Retrieval and relevant tools such as Lucene, Elasticsearch, Solr
Experience with conducting projects from requirements generation, annotation, and modeling, through NLP output deliverables and management of internal/external clients
Prioritization skills; ability to manage ad-hoc requests in parallel with ongoing projects
Experience with Scikit-learn, TensorFlow, Keras, NLTK
Experience with leveraging best practices conducting advanced analytics projects
Experience building scalable machine learning applications and deploying them in production
About Business Unit
At Global Technology Services (GTS), we help our clients envision the future by offering end-to-end IT and technology support services, supported by an unmatched global delivery network. It's a unique blend of bold new ideas and client-first thinking. If you can restlessly reinvent yourself and solve problems in new ways, work on both technology and business projects, and ask, ""What else is possible?"" GTS is the place for you!

Your Life @ IBM
What matters to you when youre looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBMs greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.",3.9,"IBM
3.9",Bengaluru,"Armonk, NY",10000+ employees,1911,Company - Public,IT Services,Information Technology,₹500+ billion (INR),"Amazon, Accenture, Microsoft","IBM
",0,109,0,1,0,1
BIE Manager,"Amazon seeks an experienced Business Intelligence Manager to join the RBS (Retail Business Services) team. Our mission is to improve customer shopping experience with Amazon by independently auditing Amazon catalog to identify CX defects and fixing defects at scale. We screen millions ASINs every day. We develop ML models to improve CX.
Our team of high caliber software developers, applied scientists, data engineers, product managers and Business Intelligence Engineers use rigorous ML and deep learning approaches to ensure that we identify & fix the right catalog defect to ensure the good shopping experience for our customers.
As a BI Manager you will be leading a team of Business Intelligence Engineers and will play a thought leadership role in our team the team will look to you for advice on data and business issues facing them to create value for our customers. You work very efficiently and routinely deliver the right value. You will have a company-wide view of the BI solutions that you build, and you will consistently think in terms of automating or expanding the results company-wide. You will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.
This high impact role will have an opportunity to lead a team to help design and build our data needs and work with emerging technologies such as Redshift and associated AWS cloud services while driving business intelligence solutions end-to-end: business requirements, workflow instrumentation, data modeling and ETL. You should be expert at implementing and operating stable, scalable data flow solutions from production systems into end-user facing applications/reports. These solutions will be fault tolerant, self-healing and adaptive. You will implement data analytics using cutting edge analytics patterns and technologies that are inclusive of but not limited to various AWS Offerings -EMR, Lambda, Kinesis, Redshift and Spectrum. You should be detail-oriented and must have an aptitude for solving unstructured problems. You should work in a self-directed environment, own tasks and drive them to completion.
You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You own customer relationship about data and execute tasks that are manifestations of such ownership, like ensuring high data availability, low latency, documenting data details and transformations and handling user notifications and training.


Basic Qualifications

· 10+ years of experience as an analyst, BIE, data scientist in the data/BI space
· 5+ years of hand-on experience with multiple analytics framework development platforms such as R, Python, SQL, AWS Services etc.
· Experience managing a data or BI team
· Experience leading and influencing the BI strategy of your team or organization
· Experience working directly with business stakeholders to translate between data and business needs
· Experience with data visualization using Tableau, Quicksight, or similar tools



Preferred Qualifications

· Bachelor's degree in Math/Statistics/Engineering or other equivalent quantitative discipline.
· MBA or Masters in Math/Statistics/Engineering
· 8+ years in relevant experience as data scientist, software engineer, business intelligence engineer, or equivalent.
· Advanced knowledge of SQL, shell scripting, Python/R, and MS excel.
· Exposure to statistical modeling, data science and machine learning techniques
· Strong active listener with solid written and verbal communication skills.
· Proven ability to work cross-functionally and delivering automated solutions for customer-facing data science problems.
· Ability to work cross-functionally, building and maintaining trust with internal stakeholders.
· Strong understanding of BI technologies and their application including database warehousing and dash-boarding
· Experience on at least one data visualization tools (e.g. OBIEE, Tableau, QlikView)
· Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams
·",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,1,1
Data Scientist/Senior Data Scientist - Deep Learning,"Danaher Corporation
Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world
Danaher generates over $20 billion USD of annual revenue from business segments: Life Sciences, Diagnostics, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers. Position Description
This position reports to Director of Data & Analytics and is responsible for leading the vision, design and development of scalable Machine Learning (ML) solutions for Danaher’s IoT and Analytics (ML) initiatives. You will work with other Data Scientists, Software engineers and business groups and lead the development of innovative ML models for Danaher’s big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams. Responsibilities
Understand business challenges and propose new modeling and algorithmic solutions that leverages the latest in statistical and machine learning techniques.
Study new data sources and find insights/correlation to investigate how data can be used to solve new business challenges. Create prototypes with data sets and provide guidance on leveraging and combining new data sources for new business insights.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in diverse industrial domains.
Provide strategic leadership in selection of platform, tools, techniques and processes in the practice of Data Science discipline.
Work collaboratively with other Product Owners/Product Managers from other business units and/or customers to translate business requirements in to technical requirements that can be answered with statistical and machine learning techniques. Guide and work with engineers and domain owners to produce the required data if not available.
Provide mentorship to other Data Scientists in the team.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of statistical programming languages such as R, Python, and SQL.
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Must have delivered data science components as part of a commercial solution at scale.
Readiness to work with engineering teams to develop a prototypes of software products leveraging exploratory data analytics.
Desirable: Consultative experience providing technology and solution consultation to customers/clients.
Expert knowledge of data visualization, using tools such as Tableau or PowerBI.
Experience working with the cloud computing, including AWS and/or Azure
Experience working with distributed data storage and computing, including Hadoop, Spark, Cassandra, and so forth
Experience working with traditional databases, such as MS SQL, Teradata, MySQL, and Postgres.
Expert knowledge of Experimental Design and Statistical Decision Theory
Agile mindset to jump in to a diverse set of projects.
Ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills.
Willingness to travel up to 25% required.
Experience

Required:
7+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
7+ years communicating effectively with project and business stakeholders about Data Science and data science projects
5+ years building production-ready image or video analysis models using Deep Learning techniques such as CNN and RNN.
3+ years leveraging tools such as TensorFlow or Theano.
5+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
5+ years translating business requirements into data science problem statements and execution tasks
5+ years leading the organization towards adoption of a data-driven culture
3+ years mentoring and supporting junior team members

Desired:
7+ years building operations analytics models, including demand forecasting, inventory optimization in manufacturing or related industries.
7+ years building IoT analytics models, including failure diagnosis and failure prediction
7+ years executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation, and so forth.
5+ years executing data science in the fields of life sciences, medical diagnosis, biostatistics, and so forth.",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,1,1,1,0
Data Scientist/Senior Data Scientist - Deep Learning,"Danaher Corporation
Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world
Danaher generates over $20 billion USD of annual revenue from business segments: Life Sciences, Diagnostics, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging digital trends.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world, including IoT, Data, AI, cloud, mobile, Augmented Reality (AR), Blockchain and other Digital frontiers. Position Description
This position reports to Director of Data & Analytics and is responsible for leading the vision, design and development of scalable Machine Learning (ML) solutions for Danaher’s IoT and Analytics (ML) initiatives. You will work with other Data Scientists, Software engineers and business groups and lead the development of innovative ML models for Danaher’s big data from health sciences, medical diagnostics, industrial and other markets. You will use your Agile experience to work collaboratively with other Product Managers/Owners in geographically distributed teams. Responsibilities
Understand business challenges and propose new modeling and algorithmic solutions that leverages the latest in statistical and machine learning techniques.
Study new data sources and find insights/correlation to investigate how data can be used to solve new business challenges. Create prototypes with data sets and provide guidance on leveraging and combining new data sources for new business insights.
Apply statistical analysis and modeling techniques on small and large datasets to solve specific business problems in diverse industrial domains.
Provide strategic leadership in selection of platform, tools, techniques and processes in the practice of Data Science discipline.
Work collaboratively with other Product Owners/Product Managers from other business units and/or customers to translate business requirements in to technical requirements that can be answered with statistical and machine learning techniques. Guide and work with engineers and domain owners to produce the required data if not available.
Provide mentorship to other Data Scientists in the team.
Own and drive contemporary best practices in applying and deploying data science at scale.
Requirements
Advanced degree (Ph.D. preferred) in Engineering, Science, Mathematics, or related
Expert knowledge of statistical programming languages such as R, Python, and SQL.
Expert knowledge of probability, statistics and machine learning theory including experience in: Deep Learning, Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, and Random Forests for prediction and recommendations.
Must have delivered data science components as part of a commercial solution at scale.
Readiness to work with engineering teams to develop a prototypes of software products leveraging exploratory data analytics.
Desirable: Consultative experience providing technology and solution consultation to customers/clients.
Expert knowledge of data visualization, using tools such as Tableau or PowerBI.
Experience working with the cloud computing, including AWS and/or Azure
Experience working with distributed data storage and computing, including Hadoop, Spark, Cassandra, and so forth
Experience working with traditional databases, such as MS SQL, Teradata, MySQL, and Postgres.
Expert knowledge of Experimental Design and Statistical Decision Theory
Agile mindset to jump in to a diverse set of projects.
Ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills.
Willingness to travel up to 25% required.
Experience

Required:
7+ years working with business stakeholders as a trusted adviser in Data Science and Monetization
7+ years communicating effectively with project and business stakeholders about Data Science and data science projects
5+ years building production-ready image or video analysis models using Deep Learning techniques such as CNN and RNN.
3+ years leveraging tools such as TensorFlow or Theano.
5+ years providing mentorship, education, and thought leadership to organizational stakeholders regarding best practices in data science
5+ years translating business requirements into data science problem statements and execution tasks
5+ years leading the organization towards adoption of a data-driven culture
3+ years mentoring and supporting junior team members

Desired:
7+ years building operations analytics models, including demand forecasting, inventory optimization in manufacturing or related industries.
7+ years building IoT analytics models, including failure diagnosis and failure prediction
7+ years executing customer advanced analytics, including marketing mix analysis, segmentation, retention modeling, targeted marketing, basket analysis, next product recommendation, and so forth.
5+ years executing data science in the fields of life sciences, medical diagnosis, biostatistics, and so forth.",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,1,1,1,0
Principal Data Scientist - Product Development (Global AI Accelerator,"Date: Mar 30, 2020

Ericsson Overview:

Ericsson is worlds leading provider of communications technology and services. Our offerings include services, consulting, software and infrastructure within Information and Communications Technology.

Using innovation to empower people, business and society, Ericsson is working towards the Networked Society: a world connected in real time that will open up opportunities to create freedom, transform society and drive solutions to some of our planets greatest challenges.

We are truly a global company, operating across borders in over 180 countries, offering a diverse, performance-driven culture and an innovative and engaging environment. As an Ericsson employee, you will have freedom to think big and the support to turn ideas into achievements. Continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals. We invite you to join our team.

Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator (GAIA) in the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Machine Intelligence, the combination of Machine Learning and other Artificial Intelligence technologies is what Ericsson uses to drive thought leadership to automate and transform Ericsson offerings and operations. MI is also a key competence for to enable new and emerging business. This includes development of models, frameworks and infrastructure where we in our advancements push the technology frontiers. We engage in both academic and industry collaborations and drive the digitalization of Ericsson and the Industry by developing state of the art solutions that simplify and automate processes in our products and services and build new value through data insights.

Ericsson is now looking for Principal Data Scientists to significantly expand its global team for AI acceleration for our group in Bangalore and Chennai.

Do you have in depth understanding of Machine Learning and AI technologies?

Do you want to apply and extend those skills to solve real complex problems with high societal impact; going beyond ML/AI for consumption and advertising?

Then, you do want to join Ericssons global team of Engineers/Scientists pushing the technology frontiers to automate, simplify and add new value through large and complex data.

Role Summary:

As a Principal Data Scientist, you shall build and deploy AI models into production with focus on scaling, monitoring and performance. You shall build effective AI models using stacking/ensemble techniques; and provide prediction explainability and prescriptive capability in ML models. You shall work with business stakeholders to define and formulate the right business problem.

Your knowledge and experience in Data Science methodologies will be applied to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.

Key Responsibilities:
Lead multiple AI/ML projects for a certain product/business
Manage communication, planning, collaboration and feedback loops with business stakeholders.
Work with huge datasets including petabytes of 4G/5G-networks, IoT and exogenous data
Identify the model monitoring strategy in prod and retraining plan.
Define data sourcing, access and pipeline design. Identify and plan for sourcing external data.
Model the business problem statement into AI/ML problem.
Define the Data sourcing strategy and works with stakeholders to procure data. Contribute to IP creation for Ericsson in AI/ML
Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL Databases. Design data pipelines and flow strategies.
Design APIs for AI/ML models with focus on business, modularity and versioning; and build standard/canonical data models by combining multiple data sources.
Lead functional and technical analysis within Ericsson businesses and for strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solutions addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical models, deep learning, reinforcement learning and other machine learning systems
Lead studies and creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and be the ambassador for them in MI Communities within Ericsson, nurturing the communities and mentoring junior data scientists.
Provide MI Competence build-up in Ericsson Businesses and Customer Serving Units
Develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives
Engage with external ecosystem (academia, technology leaders, open source etc.) to develop the skills and technology portfolio for MIs needs
Present and be prominent in MI related forums and conferences, e.g., publishing patents, presenting papers, organizing sessions etc.
Key Qualifications:
Bachelors/Masters/Ph.D. in Computer Science, Data Science, Artificial Intelligence, Machine Learning, Electrical Engineering or related disciplines from any of the reputed institutes. First Class, preferably with Distinction.
Applied experience: 8+ years of ML and/or AI production level experience; and an overall industry experience of about 15+ years.
Proven skills of implementing a variety of Machine Learning techniques
Strong Programming skills (R/Python) with proficiency in at least one
Strong grounding in mathematics, probability, statistics needed for data analysis and experiments
Proven ability of leading AI/ML projects end-to-end with complete ownership
Proven skills in building AI/ML based solutions using a variety of frameworks such as Python, R, H2O, Keras, TensorFlow, Spark ML etc.
Experience in implementing new algorithms and methodologies from leading open source initiatives and research papers
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Experience in building models using semi-structured and unstructured data
Hands-on experience in designing and building AI models using Deep Neural Networks for applicable scenarios
Experience in using ensembles and stacking techniques to solve complex ML problems
Able to build and deploy AI models into production with focus on scaling, monitoring and performance
Knowledge of building explainable models (XAI) and prescriptive analytics
Experience with working in Big Data technologies such as Hadoop, Cassandra etc.
Able to Define/Design data storage and retrieval strategies from various kind of data sources such as NOSQL DBs
Knowledge of designing data pipelines and flow strategies
Familiarity with data pipelining frameworks such as Air Flow, AWS Sagemaker, etc. would be a plus
Able to design APIs for AI/ML models with focus on business, modularity and versioning
Experience in writing and presenting white papers, journal articles and technical blogs on the results
Soft Skills:
Good communication skills in written and spoken English
Great Team worker and collaborator
Creativity and ability to formulate problems and solve them independently
Self-driven and ability to work through abstraction
Ability to build and nurture internal and external communities
Additional Requirements:
Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Experience with data visualization and dashboard creation is a plus
Knowledge of Cognitive models is a plus
Ability to work independently with high energy, enthusiasm and persistence
Experience in partnering and collaborative co-creation, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence
Ericsson provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetics.

Ericsson complies with applicable country, state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities. In addition, Ericsson supports the UN Guiding Principles for Business and Human Rights and the United Nations Global Compact.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and development.

Ericsson expressly prohibits any form of workplace harassment based on race, color, religion, sex, sexual orientation, marital status, pregnancy, parental status, national origin, ethnic background, age, disability, political opinion, social status, veteran status, union membership or genetic information.

Primary country and city: India (IN) || || Bangalore || R&D",3.9,"Ericsson-Worldwide
3.9",Bengaluru,"Stockholm, Sweden",10000+ employees,1876,Company - Public,Telecommunications Services,Telecommunications,₹500+ billion (INR),"Huawei Technologies, IBM, Cisco Systems","Ericsson-Worldwide
",0,144,1,1,1,0
Technical Lead - Machine Learning,"The Company

We are a young, fast-growing AI company shaking up how work gets done across the enterprise. Every day, we help clients identify opportunities for automation, and then use a variety of AI and advanced automation techniques to rapidly model manual work in the form of code. Our impact has already been felt across some of the most reputable Fortune 500 companies, who are consequently seeing major gains in efficiency, client satisfaction, and overall savings. It’s an exciting experience to watch companies transform themselves rapidly with Soroco!

Based across US, UK, and India, our team includes several PhDs and graduates from top-notch universities such as MIT, Harvard, Carnegie Mellon, Dartmouth, and top rankers/medalists from the IITs and NITs. The senior leadership includes a former founder of a VC/hedge fund, a computer scientist from Harvard, and a former founder of a successful digital media firm. Our team has collectively published more than 100 papers in international journals and conferences and been granted over 20 patents. Our board members include some of the most well-known entrepreneurs across the globe, and our early clients include some of the most innovative Fortune 100 companies.
The Role

A Technical Lead (TL) – Machine Learning - will drive the company’s intelligent automation solution design and delivery by working with engineering teams, client teams and the senior leadership of the company. S/he will fuel the growth of the company’s operations by developing computer vision and NLP products that can be applied to a wide range of automation tasks.

Responsibilities include (but are not limited to):
A TL will typically lead client solution teams to create and deliver complex proprietary systems.
Drive ‘best in class’ automation solution implementation on Soroco automation platform
Collaborate with client’s business and technical teams on implementation aspects including requirement validation, solution design and validation, external system and environment integration, release planning and technical/ end-user training
Analyze client data and estimate the efficacy of machine learning algorithms for information extraction
Propose intelligent algorithms to improve state of the art results on visual detection and recognition
Contribute to full stack development of machine learning algorithms from design to product implementation
Develop a deep understanding of Soroco platform, products and associated features and design automation solutions using these products
Review and contribute to the code, testing, deployment and support of the solutions.
Handle technical questions and escalations from clients
Interact and collaborate with our high-quality Soroco technical, engagement and project management teams across India and the US
Support the business development team and engagement team on account management by providing technical oversight on growth opportunities

The Candidate

The ideal Technical Lead will be a mid-tenure engineer who is passionate about leading and guiding high-tech software development teams working on enterprise-grade software solutions touching several computer science areas such as distributed systems, machine learning, NLP, computer vision, programming languages, computer security, networking, cloud computing, analytics and big data.

Key Requirements and Qualifications:

·7-14 years of work experience with a good undergrad GPA

·At least 5 years of software development experience in a modern object-oriented programming language

·At least 2 years of experience in leading technical teams

·At least 2 years of experience in customer-facing global delivery environment

·Experience of the complete software development lifecycle of at-least couple of solutions from requirements and design through to deployment and go-live

·Experience in designing and building multi-tier applications at an enterprise level

·Experience in working with enterprise architects, business analysts and business development teams

·Ability to build and review large enterprise-grade solutions

·Ability to communicate and collaborate with business and technical teams

·High learnability quotient, good value system and must be a disciplined team player

·Hands-on development mentality, with a willingness to troubleshoot and solve complex problems

·Expertise in Bayesian statistics and machine learning

·Expertise in deep learning for visual recognition, detection and segmentation

·Experience with data modeling with generative and discriminative models

·Experience with graphical models, parameter learning and inference

·Experience in NLP including text embedding and sequence transduction

·Experience leading/mentoring engineers

·Experience writing code in Python, C++, Java, and/or Go

Bonus Requirements:

·Experience in building large systems in Python and Go

·Experience in cloud infrastructure like AWS and Azure

·Experience in CI/ CD pipelines and DevOps

·Experience in automated and manual testing",3.0,"Soroco
3.0",Bengaluru,"Boston, MA",51 to 200 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,"Soroco
",0,6,1,0,1,0
Software Development Manager,"Software Development Manager - ML, Selection Monitoring

Amazons Selection Monitoring team has an opportunity for you. The Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. In order to drive expansion of the Amazon catalog, we use web mining and cluster-computing technologies like MapReduce, Spark and Hive to process billions of products and algorithmically find products not already sold on Amazon. We work with structured and unstructured content such as text and images and apply machine-learning algorithms, such as classification, natural language and image processing.

We are looking for a Software Development Manager (SDM) to tackle difficult problems in the areas of information retrieval, data science and distributed systems of cloud-scale. This is a tremendous opportunity for SDMs who want to lead and grow a team of talented SDEs and Scientists to build a reliable and scalable solution to enhance selection for Amazon's customers.


Basic Qualifications

Successful candidates will have the following:

· Experience in leading a software development and data science teams.
· Passion for building a strong Engineering culture.
· Experience in delivering reliable and scalable solutions for both internal and external customers on time with high quality.
· Strong knowledge of software development methodologies and practices.
· Solid programming skills and a deep understanding of object oriented design.
· A Bachelor's Degree in Computer Science with advanced degrees preferred.
· A minimum of 15+ years of relevant industry experience.
· Experience from international working environment with good command of English language


Preferred Qualifications

Successful candidates will have the following:
· Masters or higher degree preferred in mathematics, computer science, or related discipline
· Experience in designing and implementing information retrieval and web mining systems
· Expertise with data science, machine learning algorithms, natural language processing, and computer vision
- Experience with MapReduce, Spark, Hive and Scala.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,0,1,0,0
DATA SCIENTIST,"Employment: Full time.

Role: Data Scientist

Job Summary

We are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real-time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover useful and valuable information and finally supporting the engineering team to build the results into the end product. You will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.

Responsibilities and Duties
Collaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.
Bring analytical rigour and statistical methods to the challenges of measuring quality, improving security products, and understanding the behaviour of end-users, computer systems, and network devices.
Build innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.
Multi-task and work independently
‘Think like an adversary’
Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.
Identifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.
Uses appropriate methods, tools, and algorithms to analyze the data and create an implementation plan from the business problem.
Validates the results of the data analysis to avoid errors.
Interprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.
Monitors and continuously improves the data sources, usability and data
mining results.

Required Experience, Skills and Qualifications Education and Experience
Bachelor’s or Master’s degree in Computer Science, Statistics or similar quantitative field
3-5 years of working experience in machine learning and data science projects;
2-3 years of experience in working with large scale production data sets
Good understanding of the foundations of machine learning methods
Exceptional coding skills in SQL, and Python or R
Excellent communication skills
Knowledge and Skills

Basic Qualification:
Experience with deep learning methods, models and frameworks
Familiarity with multiple programming and scripting languages (such as Java, Javascript, C/C++, Perl, etc.)
Familiarity with data visualization tools
Experience with passive and active measurement techniques
Experience with applying statistical modelling, machine learning and data mining algorithms to business problems.
A profound understanding of big data systems
Must have:
Background in statistics
Linux System knowledge as user and administrator
Experience with Vertica or other column store databases is a plus
Experience in cybersecurity, network data
Knowledge of networking concepts and devices (Firewalls, Routers, Switches,
and Load Balancers)
Knowledge of network and web related protocols (such as TCP/IP, UDP, IPSEC,
HTTP, HTTPS, DNS, SSH, routing protocols)",-1.0,Inference Labs,Bengaluru,"Bengaluru, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,Inference Labs,1,-1,1,0,0,1
"Data Scientist, Data Engineer, Deep Learning,","Opening for Data Scientist At Bangalore (Hebbal )

Experience- Min 2 Years
Location - Bangalore (Hebbal )

Role & Responcibility -

2 - 4 years of experience applying ML / Deep Learning algorithms and techniques to real-world data sets
Expert knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.)
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Major ML frameworks: TensorFlow, PyTorch, Keras, Scikit-Learn
Strong analytical thinking
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Strong written and oral skills (in English)
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Kindly revert your Opinion
00-6.00 Years",-1.0,TechPro HR Consultancy,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,TechPro HR Consultancy,0,-1,1,0,0,0
Staff Machine Learning Engineer - Customer Engagement,"Twilio seeks a Staff Machine Learning Engineer to be a key leader in defining a new product offering at Twilio in the customer engagement space. The person in this role will be critical in shaping Twilio's data and intelligence strategy, which will empower our customers to create highly personalized communications and experiences for their contacts. Come be part of a team that's building a set of ML-driven APIs that deliver intelligent audience and personalization recommendations.

Who?

You have:
Personal traits: Curious, humble, team player
Professionally: Passionate, customer-obsessed, gets things done, highly collaborative, excellent communicator, and very comfortable with rapid change and uncertainty
You have hands on experience developing, deploying and monitoring a large scale machine learning model in production
Ph.D. or MS in Computer Science, Statistics, or related field
5+ years of applied ML experience in statistical and mathematical modeling such as supervised and unsupervised machine learning, deep learning, and/or reinforcement learning
You are familiar with concepts related to testing and maintaining models in production such as A/B testing, retraining, monitoring model performance
You've explored modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as DynamoDB or similar
You have a deep understanding of frameworks like - PyTorch, TensorFlow, or Keras, why and how these frameworks do what they do
Proficiency in Python is preferred. We will also consider strong quantitative candidates with a background in other programming languages
Experience working in an agile team environment
Big plus: Experience in AWS cloud computing
What?

You live the Twilio Magic values:
EMPOWER OTHERS: Be part of a small, high-impact and multi-talented engineering team. Show strong engagement in the team setting
WEAR THE CUSTOMER'S SHOES: Passion for and demonstrated track record of executing product opportunities deeply grounded in customer needs
DRAW THE OWL: Self-starter who can see the big picture and prioritize work to make the largest impact
BE BOLD: Help us take one of the world's most extensive communication data sets and transform it into leading-edge AI applications and products that solve meaningful customer problems
BE INCLUSIVE: Collaborating and brainstorming product ideas with product managers, data scientists and engineers
DON'T SETTLE: Experienced working at a massive scale with distributed, scalable systems, including making tradeoffs for consistency/availability
NO SHENANIGANS: Experience successfully applying machine learning to real-world problems
Why?

Today, Twilio powers the delivery of billions of the world's communications. Increasingly, we're hearing from our B2C customers that they're struggling to harness the massive amounts of valuable data they generate, much of which stems from the communications we help them send. We seek to uncover how Twilio can help customers utilize their valuable data to create unique, individualized experiences that their competitors can't replicate. We want to help them become more proactive (outcome-driven) than reactive (event-driven) in their customer engagements. We are a new initiative and team at Twilio that will function much like an internal start-up. If you want to shape the future of B2C Customer Engagement and Twilio, this project is for you!

Twilio is a company that is empowering the world's developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bangalore, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, Wednesday dinners, bi-weekly All Hands, and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers' experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About us:

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world's communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world's most demanding applications. By making communications a part of every software developer's toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world's largest organizations — to reinvent how companies engage with their customers.",3.9,"Twilio
3.9",Bengaluru,"San Francisco, CA",1001 to 5000 employees,2008,Company - Public,Internet,Information Technology,₹100 to ₹500 billion (INR),-1,"Twilio
",0,12,1,1,1,1
Staff Research Scientist,"Company Description

FireEye is the leader in intelligence-led security-as-a-service. Working as a seamless, scalable extension of customer security operations, FireEye offers a single platform that blends innovative security technologies, nation-state grade threat intelligence, and world-renowned Mandiant® consulting. With this approach, FireEye eliminates the complexity and burden of cyber security for organizations struggling to prepare for, prevent, and respond to cyber attacks. FireEye has over 7,500 customers across 67 countries, including more than 50 percent of the Forbes Global 2000.
Job Description

We are seeking Sr. Research Scientist with the passion and experience necessary to solve the malware problem across multiple platfrorms including both mobile and desktop. The candidate will work for FireEye’s security research team, which is a group of top notch security researchers specializing in areas from Machine Learning to reverse engineering advanced malware.

Responsibilities:
Perform leading edge malware research, analysis (data-mining) and generate content for use in our products.
Enhance FireEye’s security content infrastructure, process workflow, and the malware intelligence portal.
Run the FireEye’s security content release process, controlling content selection, packaging, and coordination with DEV/QA/Customer-Support teams.
Qualifications

Requirements:
At least 5 years direct or equivalent experience in areas of malware-analysis, software/security-content build/release, networking/system administration or software development
BS/MS in computer science or equivalent experience
Knowledge in Malware Analysis and Reverse Engineering
Proficiency with network traffic analysis tools such as wireshark and tcpdump
Knowledge in Security and Malware detection technologies
Solid programming skills with scripting languages such as Perl or Python is required
Working knowledge of databases such as Postgres or MySQL
Working knowledge of Rapid Web development frameworks/languages and environments such as PHP etc
Deep working knowledge of networking concepts: TCP/IP, HTTP, HTTPS, FTP, IRC, RPC, DNS etc
Host based IDS/IPS knowledge and experience a definite plus
Additional Qualifications:
Strong problem solving, troubleshooting and analysis skills
Experience working in fast-paced development environments
Excellent written & verbal communication skills
Excellent inter-personal and teamwork skills
Self-driven, proactive, hardworking, team-player with a good sense of humor",3.2,"FireEye, Inc.
3.2",Bengaluru,"Milpitas, CA",1001 to 5000 employees,2004,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Palo Alto Networks, Tanium","FireEye, Inc.
",0,16,1,0,0,1
Data Scientist / Senior Data Scientist,"Position Summary

NextNav is launching a groundbreaking location service for smartphones, IOT, and other devices – an ability to determine floor level altitude service across the country – a capability that does not exist at scale anywhere today! No longer constrained by legacy “flat earth” technologies, applications and users will be able to determine floor-level altitude, which is essential for navigation, user context and relevancy and many other applications that are used indoors.

This position will consist of building tools to aid with alerting of our system, developing real-time metrics of our end-to-end network performance, and calibration quality at all levels. The position will also develop models to aid in our end-to-end system, including calibration and forecasting, as well as applying machine learning and deep learning algorithms.

Responsibilities

·Develop algorithms to further improve the accuracy of NextNav's Z-axis solution.

·Efficiently clean, prune, fix, prepare, process and analyze network and field data.

·Create and develop machine learning algorithms to help aid in positioning and calibration of devices and network.

·Develop strong domain expertise with atmospheric science.

·Interpret data and guide company to maximal benefit.

Desired Skills& Experience

Required:

·Bachelor's degree with 2-3 years’ experience, orMaster's/PhDin engineering disciplines such as mechanical engineering, electrical engineering, or sciences such as mathematics, statistics, computer science, physics, or another closely related field, with research emphasis on data modelling and analysis.

·Solid foundation in statistics and data processing, including data reduction, regression, automation and visualization.

·Strong scientific coding skills, including proficiency in one or more of the following: Python, R, MatLab, SQL, etc. Expertise with object-oriented languages such as Java or C++ a bonus.

·Familiarity with machine learning and deep learning framework applied to real world problems.

·Ability to work independently and collaboratively across multiple departments, including hardware and software.

·Strong written and oral communication skills, with the ability to communicate clearly and effectively across teams.

Preferred:

·Experience in performing analysis of large data sets by exploiting parallel computing infrastructure.
1-2 years’ experience with machine learning and deep learning framework, including scikit-learn, Tensor Flow, or PyTorch.
·Experience in providing data support for internal and external engagements for trials and demos.

·Demonstrated experience as a problem solver and a data analyst of a variety of gridded and point weather data.

·Experience with driving projects across all stages, including ideation, testing, and marketing.

·Track record of source code contribution to open source projects.",3.2,"NextNav
3.2",Bengaluru,"Sunnyvale, CA",51 to 200 employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1,"NextNav
",0,13,1,0,0,0
Applied Scientist I,"Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

The Moderation and Relevance System (MARS) team, based in Bangalore, is responsible for ensuring that ads are relevant and is of good quality, leading to higher conversion for the sellers and providing a great experience for the customers. We deal with one of the worlds largest product catalog, handle billions of requests a day with plans to grow it by order of magnitude and use automated systems to validate tens of millions of offers submitted by thousands of merchants in multiple countries and languages. We are looking for a highly motivated, top notch applied scientist to build machine learning models at scale to enforce our policy guidelines. A successful candidate will have demonstrated experience in at least some of the following areas: NLP, Image Recognition and Classification, Video Recognition and Classification, Generative Models, Reinforcement Learning, Active Learning, Weak Supervision

Your areas of responsibility include:
·

· Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve ad policy enforcement and creative intelligence, including NLP, deep image and video models, generative models
· Perform analysis of data and metrics relevant to ad content generation and policing
· Gathering ad policy related requirements from business owners, other tech teams, as well as by analyzing customer feedback and translate them into modeling problems
· Integrate and productize ML models with overall engineering infrastructure to be made available at scale
Ad Quality protects the customer experience and is a critical component of our business success. One of the earliest teams to be established in Amazon Bangalore, Ad Quality has both Operations and Development teams in Bangalore supporting multiple ad programs in markets around the world.

sspajobs

Basic Qualifications

Basic Qualifications:
· Very good English skills (including the ability to read and write technical papers in English)
· Bachelors (BS/BE) in Computer Science or related field
· Publications in top-tier NLP and or ML/DL conferences or journals
· Skills with programming language like R, Python and/or Scala or similar scripting language
· At least 5+ years of hands-on-experience in predictive modeling and analysis
· At least 5+years of algorithmic development experience
· At least 2+years of R, Python or equivalent, as well as Java, C++ or equivalent

Preferred Qualifications


· Advanced Degree (MS/ME/PhD) in Natural Language Processing, Machine Learning, Statistics or equivalent. Significant peer reviewed scientific contributions in relevant field
· 5+ years of extensive experience applying theoretical models in an applied environment.
· Expertise on a broad set of practical experience of applying techniques, including Deep Learning, statistics, NLP, Recommendation systems and or information retrieval
· Strong fundamentals in problem solving, algorithm design and complexity analysis
· Expert in more than one more major programming languages (Java, C++ or similar) and at least one scripting language (Python, or similar)
· Strong personal interest in learning, researching, and creating new technologies with high commercial impact.
· Experience with defining organizational research and development practices in an industry setting.
· Great verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts
· Proven track record in leading, mentoring and growing teams of scientists (teams of 3 or more scientists)
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,0,0
Data Scientist / Data Analyst,"This position will be responsible for Finance Analytics product offerings thereby generate Business Performance Improvement opportunities for the Stake Holders. Our Client is looking for an experienced Senior Data Scientist to join our talented engineering team. As our data guru, you’ll be responsible for analyzing the large data set and making recommendations that will impact major business decisions. They are looking for a proven technical leader that can excel in a fun, fast-moving startup environment and help them elevate their customer experience.

Job Responsibilities

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to drive optimization and improvement of sales projections, processes, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modelling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Develop algorithms and predictive models, create prototype systems and visualizations
Implement and keep models in optimal production state
Strong data & visual presentation skills and ability to explain insights using tools like tableau, D3 charts or other tools.
Experience working with big data tools such as MapReduce, Pig, Spark and NoSQL data will be an add-on
Must have end-end hands-on experience in delivering & implementing data analytics models in production. Must have skills, such as Synthesizing data, defining the problem, feature engineering, building the model, deploying the same in production.
Ability to work closely with others to execute projects rapidly in a multi-disciplinary environment
Demonstrated data science experience in the Sales & Marketing domain with at least 3 to 4 projects delivered end-to-end, Ability to collaborate business and data science.
Strong project management skills, a passion to drive task based processes to successful completion – organized, strong communicator, high-energy and takes initiative
Consultative and collaboration skills; able to influence complex stakeholder communities
Education : Bachelor’s degree in computer science, statistics, engineering and relevant fields,

Experience : with 6+ years of hands-on experience in the following:

Statistical analysis tools such as R, Python, SAS, etc.
Machine learning techniques for classification, regression, clustering, decision trees, text analytics, deep learning & time-series data etc.
Scripting languages such as Python, Perl, Ruby, etc.

Strong communicator written and oral; able to work effectively with remote, global project teams

What You Need for this Position

You should have knowledge of:
Data Science
Data Analyst
SQL
R
Python
SAS
Python
Perl
Ruby
MapReduce
Pig
Spark and NoSQL
Aditional
No. of Positions
3
Education level
Bachelor’s Degree in Computer Science
Career level
Experienced",4.8,"Bloom Consulting Services
4.8",Bengaluru,"Nagpur, India",1 to 50 employees,2015,Company - Private,IT Services,Information Technology,₹10 to ₹50 million (INR),-1,"Bloom Consulting Services
",0,5,1,1,0,1
Tech Lead - Data Scientist (NLP),"AI team at Ultria is working on state of the art Natural Language Processing technologies including document structure detection, domain specific neural embeddings, deep neural network architectures for extraction and classification tasks etc. We are looking for a passionate data scientist to develop new statistical models for delivering high-quality NLP products.

RESPONSIBILITIES:
Identify new opportunities to apply Machine Learning to different parts of the product
Develop advanced algorithms to solve problems of high dimensionality in a computationally efficient and statistically effective manner
Have responsibility for the creation and development of our Text Analytics strategy and software
Take end to end ownership of Machine Learning products
Partner with other teams such as Data, Design and Product to collaborate on projects across the company
Work with the engineering management team to develop new initiatives and improve existing processes across the entire engineering team
Implement small and large scale projects in Advanced Analytics to help derive business insights for measurable success
Evaluate emerging datasets and technologies that may contribute to our products
Requirements
3 -7 years of strong Python development experience
3+ years of experience in Machine Learning/Deep Learning, specifically in NLP and text analytics domain including:
Extracting, cleaning and embedding text data
Text classification
Entity extraction/NER
Text summarization
Similarity and sentiment analysis
Topic modelling
Research experience in machine learning or natural language processing
Experience in deploying ML projects in production environment
Strong statistical analysis skills and demonstrated experience in deriving insights from unstructured data
Ability to run experiments scientifically and analyze results
Good understanding of ML tools/libraries like: Tensorflow, Keras, Pandas, Spacy, Pytorch, NLTK, SkLearn etc
Knowledge of big data technologies like Hadoop, Hive, Scala or Spark is preferred
Strong collaborative mindset
Excellent critical thinking and problem solving skills
Benefits

About Ultria

Ultria offers end-to-end, SaaS-deployed, Contract Lifecycle Management solution for the Enterprise—Ultria CLM. It is a market-proven solution with a legacy of successful deployments over more than seven years. With a workflow based authoring and approval tool, and a comprehensive repository of contracts and clauses, Ultria CLM helps companies across the spectrum derive greater value from their contracts. By connecting with eSignature and CRM solutions, Ultria CLM seamlessly streamlines the quote to contract conversion process. Its post-signoff contract management capabilities empower the enterprise to extract the maximum value out of contracts, mitigate risks, and ensure regulatory compliance.

Our Products are built around an intuitive user experience, leveraging a comprehensive knowledge base, robust Artificial Intelligence technology, encapsulates industry's best-of-breed processes and methodologies.

Several of Fortune 500 companies have chosen Ultria solutions for the following reasons:
In-depth industry and domain expertise with a robust implementation methodology
Ability to ensure semantic and structural data integrity and quality
End-to-end solution for Data Governance renowned by leading market Analysts
To know more, you can visit our website: www.ultria.com",4.2,"Ultria
4.2",Bengaluru,"Princeton, NJ",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Ultria
",0,-1,1,1,0,1
"Principal Engineer - Computer vision, opencv,Tensorflow","Description:

Join us as a PRINCIPAL ENGINEER Computer Vision

Similar Industry Titles and Key Words: Video analytics, AI, Deep learning, machine learning

About Vision computing platform Our mission is to provide core capabilities in vision computing and machine learning. We want to enable unparalleled guest experience by deriving insights from structured data and unstructured content (videos, images and documents) using vision computing and machine learning platform and capabilities. The platform will provide end to end ubiquitous experience including acquiring, processing, analyzing and understanding content and extraction of high-dimensional data in order to produce numerical or symbolic information, e.g., in the form of decisions. Machine learning platform would enable ML developers to focus on writing efficient ML models solving business problems and train/ deploy/ manage with minimal effort.

About the Role

The key to the success of this position is having strong & innovative approach to problem solving, great technical leadership, excellent communication (written and verbal, formal and informal), flexibility, and a self-motivated working style with attention to detail.

Use your skills, experience and talents to be a part of groundbreaking thinking and visionary goals. As a Principal Engineer, youll take the lead as you
Manage in the decision-making process related to the selection of technology framework, architecture and end-end stack for building machine & deep learning based vision apps.
Design and develop vision based apps to handle the enterprise scale, provide consultation and lead implementation of ideas on complex problems.
Partner with various in-house teams and vendors in designing and productizing algorithms and ML models across different type of infrastructure (datacenter, edge, far edge compute infrastructure)
Implement complex technical problems in retail business setting.
Keep abreast of industrial and academic research. mentor and train engineers/data scientists.
Curious to learn from the industry, follow emerging trends from established enterprises and startup ecosystem and continuously innovate and drive POCs/ POTs.
Focus on scale and performance with the need to optimize and execute for realtime needs.
Engages in development/ operations and with engineering team
Work with engineering leaders in building a high performing engineering team and talent
Mentor and build a high performing full stack engineering team
Provides leadership, coaching, motivation and assistance to team
Participates in the selection and assessment of technical talent in the organization to identify and develop technical leadership backups. Help in hiring and building team
Engages in external tech community (writing blogs, contributing to open source, present in meetups/ conferences, etc)
Provide strong leadership and communication skills and use broad technical knowledge that draws upon diverse experiences.
Requirements
PhD in computer science/electronics engineering with a research focus on computer vision.
Over 12+ years of industry experience in building software application with min 2 yrs in computer vision. Image processing/ ML
4-5 years of hands-on experience in machine and deep learning techniques.
Strong math background and a proven ability to design computationally intensive algorithms from scratch.
Proficient in one or more of Python, C++, Java, Scala or equivalent programing languages. Fluency in machine/deep learning frameworks (e.g. Tensorflow, pyTorch, scikit-learn, opencv).
Deployed large scale deep learning models/algorithms in prior experience.
Hands on experience in deep learning neural networks like CNN, RNN for object detection/recognition/tracking/classification and optimization for targeted infrastructure.
Experience in data related technologies and open source frameworks preferred.
Experience in real-time video analytics pipeline.
Familiar with software development practices/pipelines (DevOps - kubernetes, docker containers, CI/CD tools).
Qualifications:",3.8,"Target
3.8",Bengaluru,"Minneapolis, MN",10000+ employees,1962,Company - Public,General Merchandise & Superstores,Retail,₹500+ billion (INR),-1,"Target
",0,58,1,0,1,1
Applied Scientist II,"RBS Tech is committed to support business growth across WW Retail through standardization, simplification and automation. We are developing an automated solution ACE to fix catalog defects. ACE uses Machine Learning/Deep Learning to fix attribute defects identified by Sherlock (auto audit platform) across Amazons selection that will improve customer shopping experiences. The defects are reviewed for validation and fixed, in the process helping the machine to learn.
Last year the team worked on discoverability challenges customers are facing on Amazon properties by backfilling hidden attributes by applying various deep learning techniques and an ensemble of classifiers. This year, we are working on highly ambiguous use cases like size variations problems, expanding the scope of discoverability use cases. All these use cases are ideal candidates to apply various Deep learning techniques.
We are hiring applied scientists who can creatively solve these use cases.
As an Applied Scientist in RBS ACE team, you will work with talented peers to develop novel algorithms and modeling techniques to solve these high impact issues. You will leverage Amazons heterogeneous data sources and large-scale computing resources to accelerate advances in artificial intelligence. You will collaborate with other scientists and work in a fast paced team environment. Your work will directly impact our customer shopping experience, save millions in concessions. You will constantly stretch the boundaries of Machine Learning to tackle business challenges.
If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.

Basic Qualifications

· PhD/Master Degree in Computer Science with experience in Deep Neural Network specialization either in Computer Vision and/or Natural Language Processing.
· 3+ years of hands on experience in building machine learning systems for large data sets.
· Strong skills in problem solving, programming and computer science fundamentals.
· Expertise in using Python programming language.
· Well versed in DeepLearning Frameworks like Tensorflow, MXNet or alternatively front ends like Keras along with numpy, pandas and scikit-learn

Preferred Qualifications

· PhDs, specialized in Information Retrieval and Machine Learning.
· Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
· Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,0,0
"Data Scientist (Only from IIT, NIT,IIIT,IIM,VIT,BIT)","About Zycus :

Headquartered in Princeton, U.S. in 1998, Zycus has grown every day to be established as an organization which now is a leading global provider of complete Source-to-Pay suite of procurement performance solutions.

We develop cloud-based (SaaS) Source-to-Pay solutions for large global enterprises, and have successfully deployed about 200 solutions to over 1000 Global clients. We are proud to have as our clients, some of the best-of- breed companies across verticals like Manufacturing, Automotives, Banking and Finance, Oil and Gas, Food Processing, Electronics, Telecommunications, Chemicals, Health and Pharma, Education and more.

With a team of 1000+employees, we are present in India with 3 development centers at Bengaluru, Mumbai & Pune and offices in the U.S., U.K., Australia, Dubai, Netherlands and Singapore.

Know more about the LEADER of: Gartner’s 2013, 2015 & 2017 Magic Quadrant for Strategic Sourcing Application Suites and The Forrester Wave™: eProcurement, Q2 2017

We are in process of launching Merlin A.I. Studio™.

The artificial intelligence (AI)-based platform will allow procurement teams to to build and deploy bots across the source-to-pay process.

The bots will be used by firms leveraging more than 1,100 APIs from Zycus’ solution suite.

“By deploying the intelligent bots from Merlin A.I. Studio™, procurement can put themselves in cruise control mode as the bots work towards accomplishing tasks with zero human intervention,” The Fortune 500-serving firm explained in its press release

“Be it running an RFI event, discovering contract risks, negotiating with suppliers or transnational procurement; all one needs to do is launch the bot and see the magic unfold.”

“It will empower procurement to transform their routine, repetitive & mundane procurement tasks, so that time, effort & resources can be optimized towards more strategic initiatives.”Exp : 1 to 10 Years

Role : Data Scientist

Location : Bangalore

Drive Timings : 9 AM to 2.00 PM

Education : Any Engineering From IIT ,NIT , IIIT ,VIT , BITS Pilani

Venue Details :

ZYCUS INFOTECH PRIVATE LIMITED

SEZ UNIT,6TH FLOOR,GARNET Building,

Bagmane Developers Pvt Ltd SEZ II,

Bagmane World Technology Centre SEZ,

Mahadevapura,Outer ring Road,

KR Puram Hobli, Bengaluru (Bangalore) Urban,

Karnataka, 560048

Contact Person : Priyanka

Contact Number : 7899408877

Please carry your original ID proof along with Hard Copy of Resume

Requirements

We are especially looking for applicants with a strong background in Analytics and Data mining (Web, Social and Big data), Machine Learning and Pattern Recognition, Natural Language Processing and Computational Linguistics, Statistical Modelling and Inferencing, Information Retrieval, Large Scale Distributed Systems and Cloud Computing, Econometrics and Quantitative Marketing, Applied Game Theory and Mechanism Design, Operations Research and Optimization, Human Computer Interaction and Information Visualization. Applicants with a background in other quantitative areas are also encouraged to apply. If you are passionate about research and developing innovative technologies of interest to Zycus and the research community at large, the BigData Experience Lab may be the right place for you.

All successful candidates are expected to dive deep into problem areas of Zycus’s interest and invent technology solutions to not only advance the current products, but also to generate new product options that can strategically advantage Zycus

Skills
Master’s or Ph.D. in statistics, mathematics, or computer science
Only from Tier 1 Colleges
Experience using statistical computer languages such as R, Python, SQL, etc.
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis
Experience working with and creating data architectures
Knowledge of machine learning techniques such as clustering, decision tree learning, and artificial neural networks
Knowledge of advanced statistical techniques and concepts, including regression, properties of distributions, and statistical tests
1- 10 years of experience manipulating data sets and building statistical models
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data.
Data Scientist will report in to Director Engineering - Data Scentist & the roles & responsibilities are as below:
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Analyze data for trends and patterns, and Interpret data with a clear objective in mind
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Benefits

Along with a competitive compensation structure, Zycus believes in an open culture learning environment, where everyone gets a chance to share their ideas and deliver par excellence. Here's a sneak peek to our life at Zycus.",3.4,"Zycus
3.4",Bengaluru,"Princeton, NJ",501 to 1000 employees,1998,Company - Private,Computer Hardware & Software,Information Technology,₹500 million to ₹1 billion (INR),"SAP Ariba, GEP, Coupa Software Inc","Zycus
",0,22,1,1,0,1
"Statistician, 2","About Epsilon:

Positioned at Publicis Groupe's core, Epsilon is a leader in interaction management, empowering brands to transform ordinary customer experiences into meaningful, human experiences. Our connected suite of products and services combine leading-edge identity management, industrial strength data and technology expertise with big brand acumen gained over five decades working with the industry's top brands. Our human-powered, data-led marketing delivers unmatched depth, breadth and scale to help brands turn meaningful human interactions into exceptional business outcomes. For more information, visit www.epsilon.com. Follow us on Twitter at @EpsilonMktg.

Who we are looking for

At Epsilon, our people use real human insights to find solutions that empower some of the biggest brands in the world. Our team is now growing, and we are on the lookout for talented individuals who use descriptive, predictive and prescriptive analytics to impact consumer behavior every day.

So, are you someone who enjoys leading conversations with influential stakeholders to help clients understand the value of their investments? Then you could be exactly who we are looking for.

Apply today and be part of a creative, innovative and talented team who constantly share insights, solve problems and create the remarkable.

SUMMARY:

The Analytic Consulting Group partners with both internal and external clients and data providers, leveraging predictive analytics and advanced statistical techniques to drive strategic thought and effective decision making. The core charter is to develop analytics/machine learning solutions, products using both internal and external data across the customer journey to drive Acquisition, engagement, Retention using advanced Analytics, Machine Learning capabilities and data platforms. The Senior Data Scientist is someone who can rapidly navigate from generating the idea to implementing the solution and has a passion to see own work translated in business results. You will own end-to-end the scope, management and delivery of large-scale projects, with strong focus on customer insights, data quality, automation, process improvement and efficiency.

RESPONSIBILITIES:

• Deliver ML / DL projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.

• Helping to build production systems that take inputs from multiple models and make decisions in real/near time

• Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.

• Provide requirements to develop analytic capabilities, platforms, and pipelines.

• Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
BASIC QUALIFICATIONS:

• Master's in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)

• 5 years of experience in a ML or data scientist role and a track record of building ML or DL models

• In depth knowledge and working experience in statistical and data mining techniques: GLM, Random Forest, Boosting Trees, Neural Network, Text mining, kNN, Clustering

• At least 5 years of experience with data querying languages-SQL, scripting languages-Python

• Ability to write production level code, which is well-written and explainable

• Primary experience with data scripting languages such as Python and SQL,experience using ML libraries, such as scikit-learn, Knowledge and experience of writing and tuning SQL

• Statistical/mathematical software (e.g. R, SAS, or Matlab), Knowledge of SparkML will be an added advantage

• Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format

• Experience giving data presentations, Strong written and verbal communication

DESIRABLE QUALIFICATIONS:

• Advanced degree (Master's/PhD) in Statistics, Economics or other quantitative discipline

• Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences will be an added advantage

• Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR will be an added advantage, working knowledge of Hadoop, Map-reduce and other big data technologies",3.8,"Epsilon
3.8",Bengaluru,"Irving, TX",5001 to 10000 employees,1969,Subsidiary or Business Segment,Advertising & Marketing,Business Services,₹100 to ₹500 billion (INR),Merkle,"Epsilon
",0,51,1,1,1,0
Machine Learning Fellowship Bengaluru- Sep,"Data Science is not knowledge to be acquired but rather an art that must be learned through practice. The number one qualification employers look for when hiring a data science candidate is previous experience. Our fellowship gives aspiring data scientists the chance to hone their skills by building real-world machine learning applications.
build scalable machine learning models with agile software development methodology
full-time for 4 months mentoring by seasoned data scientists pair program with other fellows and mentors
apply latest research in deep learning, ensemble learners, optimization techniques, etc.
interface directly with commercial customers
work on enhancement to our platform.ai

Fellows from previous cohorts are now in data science roles at Facebook, Uber Advanced Technologies Center, Google Brain, Sentient Technologies, Yelp, Orange, etc.

Please apply at www.fellowship.ai/apply",3.2,"Fellowship.AI
3.2",Bengaluru,"Austin, TX",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Fellowship.AI
",0,-1,0,0,0,0
Data Scientist - Machine Learning/Artificial Intelligence/ Python -BFSI,"Experience 4 - 10 Years
Salary 8 LPA - 16 LPA
Job Location Bengaluru

Industry:
IT-Software / Software Services

Keywords:
Data Scientist

About Job:
Core Responsibility :
Strong experience in delivering projects in using Python.
Strong experience in developing models using Image Processing and Computer Vision algorithms
Designing, developing, and deploying deep learning models on AWS environment.
Experience and Skills :
4 - 6 years- experience in Designing and Deploying Deep Learning Solutions
Excellent knowledge of Deep Learning Architectures/Convolutional Neural Networks
Excellent knowledge of Supervised Learning, Adversarial Learning
Excellent Python Coding Skills with at least 4 years of Python coding
Robust working knowledge with deep learning frameworks (like Tensorflow, Keras, PyTorch)
Hands on experience on Image Processing and Computer Vision algorithms
Experience with GPU/CUDA programming
Deep knowledge of mathematics, probability, statistics and algorithms
Understanding of data structures, data modelling and software architecture
Excellent communication skills
Ability to work in a team
Outstanding analytical and problem-solving skills
Must Have :
Aware of the Software Development Life Cycle and Quality concepts
Excellent experience in Python programming language for data analysis.
Excellent verbal and written communications skills; Strong interpersonal skills
Managing available resources such as cloud services, data
Good to Have :
Experience with System Development Life Cycle methodologies (CMMI)",4.0,"Careerera
4.0",Bengaluru,"Wayland, MA",501 to 1000 employees,-1,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1,"Careerera
",0,-1,1,0,1,1
Data Engineering Manager,"Amazon seeks an experienced Data Engineer to join the RBS (Retail Business Services) team. Our mission is to improve customer shopping experience with Amazon by independently auditing Amazon catalog to identify CX defects and fixing defects at scale. We screen millions ASINs every day. We develop ML models to improve CX.

Our team of high caliber software developers, applied scientists, data engineers and product managers use rigorous ML and deep learning approaches to ensure that we identify & fix the right catalog defect to ensure the good shopping experience for our customers.


As a Data Engineering Manager you will be leading a team of Data Engineers and Business Intelligence Engineers and will play a thought leadership role in our team the team will look to you for advice on data and business issues facing them to create value for our customers. You work very efficiently and routinely deliver the right things. You will have a company-wide view of the Data Engineering solutions that you build, and you will consistently think in terms of automating or expanding the results company-wide. You will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.


This high impact role will have an opportunity to lead a team to help design and build our data infrastructure and work with emerging technologies such as Redshift and associated AWS cloud services while driving business intelligence solutions end-to-end: business requirements, workflow instrumentation, data modeling and ETL. You should be expert at implementing and operating stable, scalable data flow solutions from production systems into end-user facing applications/reports. These solutions will be fault tolerant, self-healing and adaptive. You will implement data analytics using cutting edge analytics patterns and technologies that are inclusive of but not limited to various AWS Offerings -EMR, Lambda, Kinesis, Redshift and Spectrum. You should be detail-oriented and must have an aptitude for solving unstructured problems. You should work in a self-directed environment, own tasks and drive them to completion.

You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions. You own customer relationship about data and execute tasks that are manifestations of such ownership, like ensuring high data availability, low latency, documenting data details and transformations and handling user notifications and training.






Basic Qualifications

· 5+ years of experience as a Data Engineer or in a similar role
· Experience managing a data or BI team
· Experience with data modeling, data warehousing, and building ETL pipelines
· Experience leading and influencing the data strategy of your team or organization
· Experience in SQL
· Degree in Computer Science, Engineering, Mathematics, or a related field and 9+ years industry experience
· 2+ years of hands-on experience hiring and managing teams of Data Engineers and 3+ as a hands-on Data Engineer
· Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
· Proficiency with at least one Object Oriented language (e.g. Java, Python, Ruby)
· Highly proficient in SQL and knowledgeable about data warehousing concepts.
· Working knowledge of software development methodologies like Agile
· Strong customer focus, ownership, urgency and drive.
· Excellent communication skills and the ability to work well in a team.
· Effective analytical, troubleshooting and problem-solving skills.

Preferred Qualifications

· Masters in Computer Science, Engineering or related technical field
· Experience building data products incrementally and integrating and managing datasets from multiple sources
· Experience with AWS Tools and Technologies (Redshift, S3, EC2)
· Experience providing technical leadership and mentor other engineers for data engineering best practices
· Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases
· Demonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,1,1
Machine Learning Engineer (Data Science Engineer),"We are looking for Machine Learning Engineers/ Data Scientists to join our talented software team in building high performing, low latency, enterprise grade and cloud-based product suite. You will play a key role in building our innovative product pipeline. Using your deep understanding of modern web architectures and Cloud platforms, programming expertise and operational experience, you will help building successful SaaS products at Pype.

Please join our ML team and work together in breaking barriers and bringing AI to the construction software industry. Applicants should have a strong computer science background with good analytical, problem solving skills apart from good foundations in Machine learning with bent towards NLP/Image Understanding. Working proficiency with Python is mandatory. Knowledge of distributed systems like Hadoop/Spark is a plus.

Roles & Responsibilities

Formulate, code and evaluate machine learning models required for the product/application
Production deployment with required optimization, vectorization and system integration
Verification/validation and continuous integration of advanced variations
Identify/adopt feedback loops to maintain high fidelity data governance across the product portfolios

Qualifications:
Bachelor’s/Master’s degree in Computer Science or equivalent area from reputed institutes
Around 2-6 years of experience in applied or theoretical Machine learning roles in the industry or research institutes
Good grasp of Linear Algebra, Probability and Statistics
Working knowledge and inclination towards Statistical pattern recognition, Machine learning, Neural Nets, Image Processing
Experience with Python/Scikit-Learn/TensorFlow/OpenCV
Ability to work with a team in an Agile environment
To apply send your resume to hr-india@pype.io",4.1,"Pype
4.1",Bengaluru,"Herndon, VA",1 to 50 employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,"Pype
",0,7,1,1,0,0
Data Scientist,"Job Summary
Job Title: AI and ML or Computer Vision
Location: Bangalore
The purpose of hiring this person is for his Robust experience in the area of Software Development in Computer Vision using a blend of traditional Image Processing based & modern Machine Learning/Deep Learning based techniques.

Responsibilities and Duties
Roles & Responsibilities:
 Experience with object detection, tracking, classification, recognition, scene understanding  Excellent programming & rapid prototyping skills in Python & C/C++ (Optionally)  Exposure to Data structures / Algorithms is a must  Expertise on OpenCV, DLib  Excellent knowledge on any/all of the given concepts in Computer Vision - namely Image Classification, Object Detection and Semantic Segmentation developed using state of the art deep learning algorithms.  Hands on experience in developing efficient and real-time convolution neural network models.  Hands on working experience with anyone of the deep learning frameworks - TensorFlow, Caffe, Pytorch, Keras, MXNet, Theano  Exposure to model compression and pruning in deep learning.  Familiarity with GPU computing (CUDA, OpenCL) and HPC.  Experience/exposure to usage of Open Source technologies  Experience/exposure to Product development methodologies & Software Engineering processes  Experience in owning technical architecture of the products, planning roadmaps & technically managing the team
Qualifications and Skills

Job Requirements:
 BE/B.Tech, MS/M.Tech (Electronics, Computer Science or related) Experience - 4+ Years  Strong Problem Solving & Communication skills  Highly Motivated, Creative and a Team player

Job Type: Full-time

Salary: ₹600,000.00 to ₹1,000,000.00 /year

Experience:
total work: 3 years (Required)
Education:
Master's (Preferred)
Benefits:
Health insurance
Paid leaves / Leave encashment
Flexible work hours
Other
Industry:
Software Development",4.0,"Lincode Labs
4.0",Bengaluru,"Menlo Park, CA",1 to 50 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹10 to ₹50 million (INR),-1,"Lincode Labs
",0,3,1,0,0,1
Data Scientist,"Locations: Bangalore, Data Science & Analytics, Mountain View, New Jersey, New York

Alphonso is a TV data company and the market leader in providing brands and agencies with verified TV audiences across all screens. Alphonso’s TV data platform processes billions of data points every day about TV content and ad viewership, in the US and internationally.

Our best-in-class automated content recognition (ACR) uses advanced fingerprinting technology to identify ads and programming on TV in real time. With the industry’s largest TV data footprint, we map ad exposure data from tens of millions of households to a broad range of third-party data sets such as demographic data, location data, transaction data, web visit data and more, all in a privacy-safe fashion, to help brands understand consumer behavior across the digital and offline realms.

We are looking for data scientists / ML engineers who go above and beyond textbook solutions; critical thinkers who apply their expertise to solve unique problems and draw deep insights from this vast pool of data. You will have the opportunity to drive impact across the board, including making strategic decisions about our products and infrastructure.

Responsibilities:
Develop scalable data models, machine learning algorithms to facilitate data-driven decision making
Take advantage of massive amounts of structured data to understand end user behavior and help our advertising customers get better bang for the buck
Design and evaluate experiments
Use AI/deep learning techniques in conjunction with our ACR technology to extract deep insights
Be a thought leader and go-to expert on everything data

Requirements:
MS/PhD in Computer Science, Statistics, Engineering, or another relevant quantitative field
Experience with machine learning algorithms and/or statistical modeling
Proficiency in Python/R/Scala or other programming languages
Familiarity with Big data technologies like Hadoop, Map/Reduce, Spark, Hive etc. is a plus",4.1,"Alphonso
4.1",Bengaluru,"Mountain View, CA",51 to 200 employees,2012,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,-1,"Alphonso
",0,8,1,1,0,0
Head of Product - Data,"About the Role:
Gojek is looking for an experienced, data-driven Head of Product to lead the Product Management group within our Data organisation. As the Head of Product for Data, you will own the innovation and execution of product roadmaps for our entire data platform. You will have a pivotal role in enabling internal use cases for our data platforms, as well as external use cases on the Gojek platform, to ensure that we stay true to our objective of being the most preferred SuperApp for our customers. You will manage a group of Senior Product Managers and support cross-functional partners in driving the conceptual and technical development of data products. As a key member of the Product Management leadership team, you will also help shape the strategic direction of the Product Management function at Gojek.

An ideal Head of Product should have demonstrated experience in managing and/or collaborating with engineers, designers, data scientists, Machine Learning practitioners and researchers to deliver great products and solutions. A successful leader in this role would require strong executive presence, ability to work effectively with remote teams and a proven track record of taking end-to-end ownership and successfully delivering results. You also need high empathy, for both your customers as well as your colleagues.

What you will do
Lead Data Product Managers and their teams to develop and be accountable to a unified roadmap that will become the foundation of our advanced analytics platform at Gojek
Define OKRs for Gojek’s data platforms and hold the teams accountable for meeting those OKRs. This includes being accountable for individual OKRs of all Product Managers within the Data organisation
Be outcome-driven, everything we do needs metrics and you will be expected to define, report and improve these metrics
Be an effective leader who solves for customer needs. We expect you to build enough business context to effectively partner and collaborate with many types of stakeholders, including engineers, analysts, and leaders from different teams and functions. Stakeholders include Data Science, Machine Learning Infrastructure, Fraud & Risk, Businesses Intelligence, all Product and Platform groups, Operations
Manage and support Product Managers in your product group, providing them with guidance and mentorship to maximise their potential
Recruit, hire and train new team members as you grow your product area
Continue to strive for innovation. Be aware of developments that are happening in the data platform and advanced analytics space. Help us understand the trade offs between build vs. buy, and guide us to make informed decisions. Build strategic partnerships with global companies that will give us a competitive edge
Be execution and delivery driven. We care about delivering solutions on time and on budget
What you will need
A Bachelor’s / Masters or an equivalent degree, preferably in engineering or management
10+ years of product experience including at least 4 years as a group lead managing other product managers.
Successful track record in planning, developing and executing strategy for multiple projects while collaborating cross-functionally
Expertise in building Data Science and Machine Learning products/ platforms
Understanding of ML lifecycle and algorithm development
Experience as a software engineer and working with distributed teams are highly desired
Ability to easily transition from high level strategic thinking to creative and detailed execution
Solid organisation, leadership, team-building, and mentorship experience
Fluent in English, a confident communicator
Entrepreneurial spirit, comfortable working in a complex and face-paced environment
Analytical and data-driven, you love digging into the data to understand what’s happening and define and measure success on every project
Passion for customers, always bringing questions back to what will serve them best

About the Team:
The Data organisation’s mission is to enable user delight, ensure trust and create asymmetric value for our customers and company through data and advanced analytics. Our team strives to build a deep understanding of Gojek’s customers, so that we can inspire data-informed decision-making and maximise the impact of data on business outcomes

Gojek is an equal opportunity workplace that is committed to diversity and inclusion. At Gojek we celebrate our differences, because we believe that diversity not only creates a healthier work environment for our employees, but also helps our business thrive.

About us

Gojek is a technology startup based in Jakarta, Indonesia. Specialising in ride-hailing and logistics, we are also the only company in Southeast Asia to be part of Fortune's 50 Companies That Changed the World (2017).

Gojek is a Super App: one app with over 20 services including food delivery, commuting, digital payments, shopping, hyper-local delivery, massages, and many more.

Gojek is Indonesia’s first and fastest growing unicorn building an on-demand empire. Our total of 2,000,000 driver-partners collectively travel 16.5 million KM daily – making us Indonesia’s de-facto transportation choice.

Gojek is a verb! Gojek is a way of life!",4.1,"GO-JEK
4.1",Bengaluru,"Jakarta, Indonesia",1001 to 5000 employees,2010,Company - Private,Transportation Management,Transportation & Logistics,Unknown / Non-Applicable,-1,"GO-JEK
",0,10,0,0,0,0
AWS Data Lab Solution Architect,"Are you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?


At AWS, were hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Lab is located in Seattle, New York, Herndon, London, and now Bangalore. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Lab Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!




Roles & Responsibilities
· Understand customer requirements and render those as architectural models that will operate at large scale and high performance. Where customers have architectures prepared, validate them against non-functional requirements and finalize the build model.
· Work alongside customers to build data management platforms using Elastic Map Reduce (EMR), Redshift, Kinesis, Amazon Machine Learning, Amazon Athena, Lake Formation, S3, AWS Glue, DynamoDB, ElastiCache and the Relational Database Service (RDS)
· Render working, high performance data management solutions, as CloudFormation and reusable artifacts for implementation by the customer
· Prepare architecture and design briefs that outline the key features and decision points of the application built in the Data Lab
· Work with customers to advise on changes as they put these systems live on AWS
· Extract best-practice knowledge, reference architectures, and patterns from these engagements for sharing with the worldwide AWS solution architect community

Basic Qualifications

· Highly technical and analytical, possessing seven or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.
· Possess significant experience of software development and/or IT and implementation/consulting experience.
· Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.
· Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
· Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.
· Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.
· Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.
· BS level technical degree required; Computer Science or Mathematics background preferred. [DB1]
· AWS Certification, eg. AWS Solutions Architect, Developer, or AWS Certified Big Data - Specialty

Preferred Qualifications

· Hands on experience leading large-scale global database, data warehousing and analytics projects.
· Demonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.
· Deep understanding of data, application, server, and network security
· Experience with Statistics, Machine Learning and Predictive Modelling.
· Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.
· Experience working within the software development or Internet industries is highly desired.
· Technical degrees in computer science, software engineering, or mathematics
· Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps.

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,0,1,1,0
Data Scientist,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning
Manipulate and prepare large, heterogeneous data sets to support advanced analytics
Iteratively conceptualize, design and build data-driven analytical models
Develop processes and tools to monitor and analyze model performance and data accuracy
Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.
Productionalizing machine learning code and interfacing with industry standardmsoftware systems
Understand and manipulate unstructured data from different platforms.
Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value
Qualifications:
Required:

Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
4 years of experience applying advanced AI techniques to real-world problems
Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)
Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)
Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, 3PL, travel...)
Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).
Demonstrable familiarity with code and programming concepts.
Knowledge of Spark and/or Hadoop
Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning
Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau
Strong problem solving skills with an emphasis on product development
Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style
Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1,"Noodle.ai
",0,4,1,1,0,0
Member of Technical Staff- UI,"Qubole is a simple, open, and secure Data Lake Platform for machine learning, streaming, and ad-hoc analytics. Our platform provides end-to-end services that reduce the time and effort required to run Data pipelines, Streaming Analytics, and Machine Learning workloads on any cloud. No other platform offers the openness and data workload flexibility of Qubole while lowering cloud data lake costs by over 50 per cent. Qubole customers process nearly an exabyte of data every month. Qubole investors include Charles River, Institutional Venture Partners, Lightspeed, Norwest, Harmony and Singtel Innov8.

UI engineers in Qubole are responsible for the rich web application hosted at api.qubole.com. We build user interfaces that cater to a wide variety of personas such as Data Analysts, ETL Engineers, and Data Scientists. We are looking for engineers to craft the next generation of Qubole’s user interface.

Some examples of work that UI engineers have done:
An IDE like interface for composing and analyzing big data queries.
QuEST UI to build streaming pipelines in a few clicks.
Interfaces for exploring object stores and large datasets.
Support for multiple clouds such as Microsoft Azure, Google Compute Cloud etc.
Cluster management UI to create and manage big data clusters.
Reports and dashboards for monitoring performance of commands, clusters etc.… and many more
What you'll be doing
Interact with UX designers and PMs to iterate and develop the product.
Use efficient abstractions and good programming practices to write testable, reusable and maintainable code.
Participate in design and code reviews.
Willingness to deep-dive across various levels of the stack to debug/understand/solve issues.
Interact with support engineers to identify customer pain points and address them.
Willingness to develop and execute test automation using Node.js
Required experiences and skills
Strong grasp of JavaScript, HTML, and CSS fundamentals.
Familiarity with building MVC applications. Knowledge of RoR a plus.
Knowledge of client side frameworks such as Ember, React.js is a plus.
Ability to write clean, modular, unit testable, and maintainable code.
Awareness of performance, web security, and cross-browser compatibility issues.
Attention to detail in UX.
Good understanding of RESTful API design patterns.
Basic understanding of SQL
Qubole is hitting that growth inflection point where we need talented people to help us scale up. Our company culture is special, and we are looking for people to join us who want to continue building a great company while going after the big data activation market.
Check us out on Glassdoor and LinkedIn
Learn more about us here, here, and here

Culture at Qubole
Trust and Autonomy: We absolutely pride ourselves on the lack of bureaucracy at work, and believe in delegating power and responsibility, aggressively to our employees.
Transparency and Teamwork: Complete transparency in all our thoughts and actions is integral to our genetic character, and it helps us to stick together and function effectively as a team.
Who Thrives: If you are a self-starter and thrive on complexity and independence and truly understand and live the tenets of humility, hunger and honesty and you will love Qubole.

Qubole is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Qubole does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Qubole also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.",4.5,"Qubole
4.5",Bengaluru,"Santa Clara, CA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,"Qubole
",0,9,0,0,1,0
SENIOR DATA SCIENTIST,"Data Scientist

About Happiest Minds Technologies

Happiest Minds, the Mindful IT Company, applies agile methodologies to enable digital transformation for enterprises and technology providers by delivering seamless customer experience, business efficiency and actionable insights. We leverage a spectrum of disruptive technologies such as: Big Data Analytics, AI & Cognitive Computing, Internet of Things, Cloud, Security, SDN-NFV, RPA, Blockchain, etc. Positioned as “Born Digital . Born Agile”, our capabilities spans across product engineering, digital business solutions, infrastructure management and security services. We deliver these services across industry sectors such as retail, consumer packaged goods, edutech, e-commerce, banking, insurance, hi-tech, engineering R&D, manufacturing, automotive and travel/transportation/hospitality.

Headquartered in Bangalore, India; Happiest Minds has operations in USA, UK, The Netherlands, Australia and Middle East.

Skills

Required Skills: Data Science, Machine Learning, Deep Learning, Python

Desired Skills:
Roles and responsibilities
Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, Statistics
Have ability to solve Business problems using Data
Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets
High level of proficiency in statistical tools like R, Python
Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights.
Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems
Good to Have
Expertise in programming languages like Java/C/C++/Python
Experience with relational databases and SQL is good to have
Relevant experience in Big Data platforms like Hadoop eco-system
Come up with innovative algorithms and solutions
Staffing Type: Permanent",4.1,"Happiest Minds Technologies
4.1",Bengaluru,"Bengaluru, India",1001 to 5000 employees,2011,Company - Private,IT Services,Information Technology,₹5 to ₹10 billion (INR),-1,"Happiest Minds Technologies
",1,9,1,0,0,0
Data Scientist,"Implement and support data discovery and predictive analytics models by analyzing business data.

Qualifications:
3+ years of experience with R
3+ years of experience with mahout or machine learning algorithms
1+ years of experience with deep learning libraries like TensorFlow or equivalent
Working experience with java or python
Database experience with MySQL or NoSQL database solutions
Ability to design the models to work on small to very large data sets
If interested, please send the latest CV to data@scalein.com or contact using our contact page.",-1.0,ScaleIn,Bengaluru,"San Jose, CA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,ScaleIn,0,-1,1,0,0,0
Senior Data Scientist,"Data Scientist / Sr. Data scientist

At Razorpay, we rely on insightful data to power our systems and solutions. We’re seeking experienced data scientists to deliver those insights to us on a daily basis. Our ideal team member will have the mathematical and statistical expertise you’d expect, along with natural curiosity and creative mind that’s not so easy to find. As you mine, interpret, and clean the data, we will rely on you to ask questions, connect the dots, and uncover opportunities that lie hidden with the ultimate goal of realizing the data’s full potential. You are expected to bring in a strong experience of using a variety of data mining methods and tools in building models and running simulations. You must have a proven ability to drive business results with data-based insights and more importantly you should be comfortable working with a wide range of stakeholders and functional teams. You will be instrumental in helping the business continue its evolution into an analytical and data-driven culture.

Roles & Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.
Develop a use case roadmap for a problem area or capability for the business. Frame the business problem into a Data Science or modelling problem.
Extract data from multiple sources. Mine and analyze data from company databases to drive optimization and improvement of product.
Work as the data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products.
Enhance data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data.
Run data exploration to understand relationships and patterns within the data, develop data visualisation to represent and be able to demonstrate the relationships identified from data exploration.
Data mining using state-of-the-art methods. Selecting features, building and optimizing classifiers using machine learning techniques.
Refine and deepen understanding of the algorithmic and inferential aspects of statistical analysis. Evaluate new algorithms from latest research and develop intuition about the problems for which they are likely to improve the state of the practice.
Build training pipelines for the production environment. Develop and execute on a plan for continuous iteration and refinement of a new model.
Provide inputs for design, quality assurance parameters and support implementation for the model in online environment.
Provide inputs and determine infra requirements and infra management for model deployment.
Lead debugging of data pipelines and model behaviour in production environment.Develop dashboards to enable easy tracking and communication of model impact.
Desired Skills & Experience
We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, with a Bachelor’s/Master’s/PhD degree in Statistics, Mathematics, Computer Science or another quantitative field, from any of the top-tier colleges.
Data-oriented personality. Strong problem solving skills with an emphasis on product development.
Great communication skills. Excellent written and verbal communication skills for coordinating across teams.
Good applied statistics skills such as distributions, statistical testing, regression.
Good scripting and programming skills. Experience using statistical computer languages, Python, R, SQL to manipulate data and draw insights from large data sets. Familiarity with Scala, Golang or Java is an asset.
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, artificial neural networks and their real-world advantages or drawbacks. Knowledge of deep learning techniques is a plus.
Experience with common data science toolkits such as R, NumPy, MatLab, Pandas, Scikit-learn, TensorFlow, Keras etc.
Experience with data visualisation tools such as D3.js, GGplot.
Proficiency in using query languages such as SQL.
Experience with NoSQL databases such as MongoDB, Cassandra, HBase is desired.
Experience with distributed data/computing tools like Map/Reduce, Hadoop, Hive, Spark is a big plus.",4.1,"Razorpay
4.1",Bengaluru,"Bengaluru, India",501 to 1000 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,"Razorpay
",1,6,1,1,0,1
Sr. Technical Program Manager - CTPS,"The Transaction Risk Management Systems (TRMS) division at Amazon is looking for a passionate, results-oriented, inventive technical program manager to take the abuse prevention program to next level. The TRMS division is responsible for the prevention of fraudulent transactions and malicious behavior on Amazon and delivers cost savings direct to Amazon's bottom line.

Amazon.com's Risk Management Team has a worldwide reputation as the #1 in eCommerce Fraud Prevention. Trust and Safety of our customers comes first. Always. We thrive on maintaining the highest bar of customer experience while we maintain those tenets. Do you want to join a team that uses cutting edge technology including machine learning and statistical modeling techniques, cloud computing services and highly available and scalable distributed systems that supports hundreds of millions of transactions across the globe?

Amazon's Abuse Prevention Program, is one of the flagship programs of TRMS, that strives to protect Amazon businesses exposed to customer abuse while maintaining the highest level of customer experience for our good customers. This means building highly sophisticated, data-centric systems that can detect abusive patterns across millions of transactions. We build highly scalable, flexible and distributed systems that utilize the power of data at every step - compute predictive variables, build models using machine learning algorithms and plug into different pipelines to prevent abusive transactions from taking place. As Amazon businesses grow, abusers morph to find new ways to take undue advantage, our engineers and scientists are constantly innovating to stay ahead of the game and protect Amazon and our customers. We are looking for senior software engineers who have a strong sense of ownership and a passion for solving complex problems elegantly. Come help us build the next generation Risk Management platform, processes and detection algorithms. You will be highly encouraged to own, innovate and make significant contribution toward our long term vision and architecture.

We're seeking a Technical Program Manager for the Abuse Prevention Program, a flagship program of TRMS. In this role you will be responsible for scoping and delivering large projects end-to-end. Responsibilities include collection of business and systems requirements from internal and external customers, writing specifications, driving project schedules from design to release, and managing the production launch. You will lead and coordinate design/implementation efforts between internal teams and outside merchants and vendors to develop optimal solutions. You will be expected to make appropriate tradeoffs to optimize time-to-market, clearly communicate goals, roles, responsibilities, and desired outcomes to internal cross-functional and remote project teams.

The right candidate will possess a strong technical program management background, will have demonstrated experience leading medium to large projects, and will have a well-rounded technical background in current web technologies. You must be able to thrive and succeed in an entrepreneurial environment, and not be hindered by ambiguity or competing priorities. This means you are not only able to develop and drive high-level strategic initiatives, but can also roll up your sleeves, dig in and get the job done. As a TPM, you will anticipate bottlenecks, provide escalation management, anticipate and make tradeoffs, and balance the business needs versus technical constraints. An ability to take large, complex projects and break them down into manageable pieces, develop functional specifications, then deliver them in a successful and timely manner is expected. Maturity, high judgment, negotiation skills, ability to influence, analytical talent and leadership are essential to success in this role.

Basic Qualifications
• BS in a technical discipline (Engineering, Computer Science, Mathematics).
• 5+ years of experience in technical program management
• 5+ years of experience building and/or managing large distributed solutions
• Great problem solving skills, desire to solve problems that have no textbook solution
• Experience working in or leading teams following agile software development practices (Scrum, etc).
• Excellent written and verbal communication skills.
• Self-starter, quick learner and passionate problem resolver

Preferred Qualifications
• Experience creating enterprise and consumer products
• A deep understanding of software development, architecture, and infrastructure.
• Strong desire in building high-performance, highly-available and scalable distributed systems
• Design and coding skills in some language on some OS platform
• Good debugging and troubleshooting skills, with an enthusiastic attitude to support and resolve customer problems
• Working experience in at least 1 modern programming language (Java, C#, C/C++, Perl, Ruby, Python, etc).



Basic Qualifications

· Experience managing projects across cross functional teams, building sustainable processes and coordinating release schedules
· 7+ years of relevant engineering experience
· 5+ years of technical program management experience
• BS in a technical discipline (Engineering, Computer Science, Mathematics).
• 5+ years of experience in technical program management
• 5+ years of experience building and/or managing large distributed solutions
• Great problem solving skills, desire to solve problems that have no textbook solution
• Experience working in or leading teams following agile software development practices (Scrum, etc).
• Excellent written and verbal communication skills.
• Self-starter, quick learner and passionate problem resolver.



Preferred Qualifications

• Experience creating enterprise and consumer products
• A deep understanding of software development, architecture, and infrastructure.
• Strong desire in building high-performance, highly-available and scalable distributed systems
• Design and coding skills in some language on some OS platform
• Good debugging and troubleshooting skills, with an enthusiastic attitude to support and resolve customer problems
• Working experience in at least 1 modern programming language (Java, C#, C/C++, Perl, Ruby, Python, etc).",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,0,1
Data Engineer,"Overview


INBE is a Bangalore-based technology startup that’s building a retail platform — Paisool — for Kirana stores, small retailers and neighbourhood supermarkets. This is our attempt at reimagining the urban grocery retail space. Paisool, with its super simple Point of Sale device, uses distributed learning systems to understand buying behaviour of households and localities. This knowledge is used to help stock the stores with hyper-targeted inventory from our curated marketplace of products and suppliers — thus, offering a superior selection for consumers while optimising inventory & cash flow for stores. Our platform is live in 15 pilot stores, with plans to add another 85 stores by 31st March 2018.

Paisool Data Platform collects, store, analyse and visualize data to better business insights on urban grocery consumption space. Developers use that information to identify problems and generally make our platform and app ecosystem more awesome. To build data-driven features, and foster a data-informed culture. We need your help!

As a Data Engineer at Paisool, you work on the Paisool data platform, that collects the purchase data, Peer networked Paisool platform data pipeline that share and store data, and the tools that enable developers to analyse and visualize the data.

About You


We are seeking an experienced technologist in building trusted data management, data tools and data analytics services. If you are the engineer we are looking for, these next statements will resonate with you. You are someone who can build maintain and mature our data services as a whole, bringing robust, secure and scalable solutions to Paisool. You enjoy solving complex problems, making data more accessible and delivering high-quality service.

What You’ll do :
You will implement and operate data systems to meet the needs of the organization by synthesizing organizational requirements and identifying the best method of presenting the data for business decisions.
Develop, recommend and implement process and procedure changes to systematically improve data integrity.
You will collaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing to design existing and new features and build data sets for efficient analysis.
You will contribute to Paisool’s data platform and data-driven decision-making by architecting, building, installing, testing, monitoring and maintaining data handling and data management systems.
You will pay attention to industry trends in data science and engineering, evaluating and learning new technologies
You will work with product managers, engineers and data scientists to experiment and build features into Paisool platforms driven by data and algorithms
You will build & deploy machine learning algorithms and statistical models in multidimensional problem spaces.
You will design experiments and interpret the results to draw detailed and actionable conclusions

What you'll need :


A logical mindset is a must, ideally combined with a strong engineering or mathematics background
Deep understanding of experimental design and the scientific method.
2+ years of relevant experience in a software development or programming role.
Demonstrated authority in one, or proficiency in more than one, programming language (Python or R ...)
A strong foundation in database systems (non-relational and SQL); experience working with large datasets is a plus
Good theoretical understanding and previous work experience with relevant algorithms
Ability to deliver on tight timelines and move quickly while maintaining attention to detail
Collaborate closely with cross-functional teams to execute decisions
Self-driven and proactive with the ability to work in a self-guided manner
Excellent communication and organization skills

Bonus Points


Our team requires skills in a variety of domains. You should ideally have experience with some of the areas listed below, and be interested in learning new things. We’re excited to see:
Understanding of distributed systems.
A strong background in statistical foundations of experimental or observational data
Experience with tools and technologies we’re using: Python, Twisted, React Native, CoffeeScript, Polymer, Cordova, WebSockets, WebRTC etc
Experience with product analytics
Experience with machine learning
Working knowledge of web development technologies: HTML, Javascript, CSS
Experience in open-source development and contribution to open-source technology.
If you’re deeply interested in working on Data Engineer post at Paisool and have relevant skills and experience, please consider applying even if your background doesn’t perfectly match our ideal credentials. If you have different experiences and skills from the ones listed above but have something else to contribute, please contact us

hiring@inbe.com",5.0,"Paisool
5.0",Bengaluru,"Bengaluru, India",1 to 50 employees,2012,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,"Paisool
",1,8,1,0,0,1
Sr Data Scientist,"Description

SHIFT: Day Job

SCHEDULE:

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will assist in defining and developing software for tasks associated with the developing, debugging or designing of software applications or operating systems. Provide technical leadership to other software developers. Specify, design and implement modest changes to existing software architecture to meet changing needs.

Duties and tasks are varied and complex needing independent judgment. Fully competent in own area of expertise. May have project lead role and or supervise lower level personnel. BS or MS degree or equivalent experience relevant to functional area. 4 years of software engineering or related experience.

Qualifications

Oracle Cloud Infrastructure (OCI) is a strategic growth area for Oracle. It is a comprehensive cloud service offering in the enterprise software industry, spanning Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). OCI is currently building a future-ready Gen2 cloud Data Science service platform. At the core of this platform, lies Cloud Cognitive Service.

What OCI Cognitive Services are: A set of services on public cloud, that are powered by ML and AI to meet the Enterprise modernization needs, and that work out of the box. These services and models can be easily specialized for specific customer/domain by leveraging existing OCI services.

Key Points: Enables customers to add AI capabilities to their Apps and Workflows easily via APIs or Containers, Useable without needing to build AI expertise in-house and Covers key gaps – NLP, Computer Vision, for Public Clouds and Enterprise in NLU, NLP, Vision and Conversational AI.

You’re Opportunity: As we blaze the trail to provide a single collaborative ML environment for data-science professionals, we will be extremely happy to have you join us and share the very future of our Machine Learning platform - by building a Cognitive Cloud service.

We are addressing exciting challenges at the intersection of artificial intelligence and cutting-edge cloud infrastructure. We are building cloud services in natural language processing (NLP) and, computer vision that works out of the box for enterprises. Our product vision includes the ability for enterprises to be able to customize the services for their business and train them to specialize in their data by creating micro models that enhance the global AI models.

What You’ll Do
Provide machine learning methodology leadership.
Build a core model of cognitive service using various open source and machine learning principles and techniques (CNN, learning rates, fast.ai, DL based NLP, NLU).
Brainstorm and Design various POCs using ML/DL/NLP solutions for new or existing enterprise problems.
Work with fellow data scientists/SW engineers to build out other parts of the infrastructure, effectively communicating your needs and understanding theirs and address external and internal shareholder's product challenges.
Building core of Artificial Intelligence and Cognitive Service as Vision, Text, NLP, NLU, and others.
Leverage Cloud technology – Oracle Cloud (OCI), AWS, GCP, Azure, Heroku or similar technology.
Build models with Python and machine learning libraries (Numpy, Tensorflow), Big Data, Hadoop, HBase, Spark, etc
Capable of quickly becoming familiar with new approaches to Machine Learning.
You have been exploring or working on some of the latest advancements in the deep learning space like TensorFlow.
Qualifications
MA/MS or Ph.D. degree in computer science, artificial intelligence, machine learning, speech recognition, natural language processing, operations research, or related technical field.
4+ years of Experience designing and implementing machine learning pipelines in production environments.
Working knowledge of current techniques and approaches in machine learning and natural language processing: text categorization, text summarization, information retrieval, question answering, sentiment analysis, semantic parsing, etc.
Experience using ML and DL languages using Python and Java, to manipulate data and draw insights.
Practical experience and deep knowledge in algorithms for NLP, NLU, sentiment analysis, Text to Speech, Vision, recommender systems, reinforcement learning, and another cognitive service.
Practical experience in feature engineering and evaluation, automation of such tasks, model interpretation &visualization.
Experience or willingness to learn and work in Agile and iterative development and DevOps processes.
Strong drive to learn and master new technologies and techniques.
Deep understanding of data structures, algorithms, and excellent problem-solving skills.
You enjoy a fast-paced work environment.
Additional Details
Experience with Cloud Native Frameworks tools and products is a plus
Have an Impressive portfolio on Kaggle Profile is a plus.
Hands-on experience with horizontally scalable data stores such as Hadoop and other NoSQL technologies
Our vision is to provide an immersive AI experience on Oracle Cloud. Aggressive as it might sound, our growth journey is fueled by highly energetic, technology savvy engineers like YOU who are looking to grow with us to meet the demands of building a powerful next-generation platform. Are you ready to do something big?

]]>",3.6,"Oracle
3.6",Bengaluru,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,₹500+ billion (INR),"SAP, Salesforce, Microsoft","Oracle
",0,43,1,1,1,1
Software Development Manager - Amazon Search,"Amazon Search is looking for an outstanding Business Intelligence Manager to help improve Amazon Search for our worldwide customers by delivering analytical insights to monitor & improve Search, a toolset enabling others to analyze, and evaluations of search experiments.

This leader will lead a team of engineers to build needed software systems, business intelligence engineers for an in-depth analysis, and technical product/program managers to run this program end to end.

The ideal candidate will have a track record of building teams that span both business and technical competencies, gathering business requirements and creating analytics solutions that have measurable customer impact and demonstrating exemplary written and verbal communication skills. The candidate will have to set the right vision, strategy, and roadmap and work alongside stakeholders in the organization to make it happen. The candidate knows and loves working with business intelligence tools, can model multidimensional datasets, and can partner effectively with business leaders to answer critical business questions.


S/he will need to be a self-starter, comfortable with ambiguity in a fast-paced and ever-changing environment, and be able to lead a team to innovate and think big while diving deep to meet our bar for quality and accuracy.

Primary Responsibilities

In this role, you will:
· Define and deliver metrics to monitor the quality of Amazon Search and its components and identify opportunities to improve it.
· Design, implement, and support platforms that provide business teams and data scientists ad-hoc access to large datasets (e.g., data visualization tools for non-tech business users).
· Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive critical business decisions.
· Identify new metrics and means to analyze and monitor Search.
· Create statistical techniques that increase the accuracy, speed, and agility of analytics.
· Decide build- vs-buy for the software needed for your domain.
· Build a strong relationship with your leadership, customers, peers, and stakeholders. Interface with business customers, gathering requirements, and delivering complete reporting solutions as well as guide strategic investments.
· Build a strategy and a roadmap of deliverables balancing short & long-term needs.
· Engage closely with the team and provide hands-on technical leadership, strategic direction, and oversight to ensure timely delivery with high quality.
· Attract, excite, coach, and retain top talent in software engineering and analytics.
· Establish a culture fueled with customer-obsessed innovation and engineering excellence.
· Be connected and influential within the Amazon BI community. Work with Data engineering, Software development teams to enable the appropriate capture and storage of crucial data points.






Basic Qualifications

· 7+ years of relevant engineering experience
· 3+ years of people management experience, managing engineers
· Experience in partnering with product and program management teams
· Bachelor's degree or higher in a quantitative/technical field (e.g., Computer Science, Information Systems, Statistics, Engineering).
· 8+ years of experience in business intelligence. 4+ years of experience in building BI software. 2+ years of people management experience.
· Expert in statistical techniques such as sampling, A/B testing, etc.
· Proven success in producing analytical insights with significant business impact.
· Expert in at least one statistical/machine learning software such as in R, Python, SAS, MATLAB
· A strong track record of iterative design, working closely with customers and peers and developers from inception through implementation.
· Excellent communication, presentation, and interpersonal skills. Demonstrated experience engaging and influencing senior executives and managing stakeholders. Ability to communicate effectively with both technical and non-technical stakeholders.
· Ability to discover the real requirements underlying customer requests, recommend alternative technical and business approaches, and deliver to those requirements



Preferred Qualifications

· Experience with industry-standard software components for business intelligence stack such as RedShift, Teradata, Quick Sight, Tableau, PowerBI, etc.
· Proven ability to meet tight deadlines, multi-task, and prioritize workload
· Building and growing teams of high-performing engineers from scratch
· Experience with working with leadership and stakeholders in the USA
· Experience with developing on AWS
· Experience with Search and eCommerce domain",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,1,1
Technical Lead - Data and Machine Learning Engineering,"Company Overview Danaher Corporation
Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world Danaher generates over $18 billion USD of annual revenue from five business segments: Life Sciences, Diagnostics, Dental, Water Quality, and Product Identification.

For additional company details, see www.danaher.com.

Danaher Digital

Danaher Digital is our digital innovation, incubation and acceleration center where we’re bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danaher’s digital innovation journey by partnering with Danaher operating companies (OPCOs) to monetize and commercialize the potential of emerging and disruptive digital trends such as AI, Machine Learning (ML), Big Data, IoT, Augmented Reality (AR), Cloud (SaaS/PaaS) and other Digital frontiers. If you are driven to forge new disruptive and transformative digital apps, platforms and services by working with such cool and emerging technologies, you belong in Danaher Digital.

True to Danaher’s shared purpose of “Helping Realize Life’s potential”, we work alongside industry’s leading companies in large, diverse and growing markets segments – from industrials to environmental sciences to life sciences to medical diagnostics. If you are inspired by and motivated to create true impact on lives and industries, at a scale and breadth that Danaher is uniquely positioned for, then you belong in Danaher Digital.

If you thrive in startup-like environments where you can envision, architect and rapidly build hi-tech solutions that are ground-breaking in the diverse markets Danaher is uniquely positioned to lead, then Danaher Digital is where you want to be.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world. And now we are establishing a strategic talent and innovation hub in India’s Silicon Valley – Bangalore, with broad ranging product capabilities and leadership.
Position Description
As a Technical Lead for Data and Machine Learning (ML) Engineering, you will join a team of skilled Data Scientists, Software engineers and Cloud Architects to drive Danaher’s Digital transformative initiatives in Data and Analytics (Machine Learning/AI) platforms and applications targeted at multiple industrial segments such as Life Sciences, Diagnostics, Industrial manufacturing and environmental sciences. You will lead a team of engineers tasked with building cloud-based data and analytics services to translate Danaher’s strategic vision in to technical reality.
You will be called upon to work collaboratively with our business stakeholders, Architects, Product Managers/Owners, to set goals for your team and guide them with hands-on technical expertise. You will not hesitate to get your hands dirty in technical implementations. You will bring your proficiency in Data Engineering, SQL/NoSQL databases, ML Engineering, analytics pipelines, SQL/NoSQL databases and detailed SW planning/execution acumen.
You will have the opportunity to build new teams and mentor them to become highly efficient in what they do and in on-time delivery of tasks. You will work with a globally distributed Agile team in a fast-paced environment. Responsibilities
Lead a team of skilled engineers to build data pipelines and production level ML infrastructure in a fast-paced environment.
Lead your team of Data and ML engineers to translate Data & Analytics requirements in to short- and long-term implementation plans. Be comfortable with details and be hands-on to make sure the delivery expectations are met.
Lead your team to launch new data ingestion, extraction, transformation and loading processes on AWS/Azure cloud with a keen focus on scalability, reliability, performance and reusability. Build key data sets and lead feature engineering efforts to empower exploratory analysis and advanced analytics.
Collaborate with our data scientists to identify and build data pipelines and patterns that are relevant to advanced analytical model building and then curate, clean, wrangle and prepare data for efficient use at large scale.
Lead your team to understand Machine Learning/Deep Learning model performance requirements, refactor model code as necessary, design model deployment frameworks and deploy models in prototype/production environments.
Closely collaborate with other engineering teams to ship machine learning products to production.
Interact with both business and technical stakeholders to deliver high quality products and services that meets/exceeds business customer, and technical requirements.
Leverage your experience to evaluate new data technologies and build a scalable data engineering and ML engineering framework.
Share in code and design reviews with agile team
Integrate 3rd party software components into existing software applications
Work with geographically distributed teams while maintaining highest standards in collaboration and communication. Requirements
7+ year of demonstrated experience in developing highly scalable, reliable, and real-time data processing pipelines combined with experience in Machine Learning workflow and model deployment
7+ years of experience leading and software product development teams in an Agile environment
5+ years of experience with a variety of SQL and No-SQL data stores such as MongoDB, Cassandra, HBase, MySQL/Postgres
5+ years of demonstrated experience in developing data pipelines using Python/Java/Scala on various frameworks(especially on Apache Spark) on AWS, Azure, or similar cloud platforms; Demonstrated experience in Data security aspects and implementation.
2 to 3 years of demonstrated experience in designing and deploying software using frameworks for machine learning such as TensorFlow, Theano, Keras, Scikit-learn, Spark ML, CNTK, Torch, Caffe, MXNet, H2O
Ability to work with structured, semi-structured and unstructured datasets uncovering information and identifying complex links across different data sets
Experience with Docker and Kubernetes
Experience with one or more programming languages such as Java, Scala or Python.
Ability to nurture/mentor others in the team.
A can-do attitude in anticipating and resolving problems to help your team to achieve its goals.
Excellent communication skills with direct team members as well as external teams and stakeholders.
Must have experience in Agile development methods.
Willingness to travel (< 20%)",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,1,1,1,1
Data Scientist DA4AD,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",4.2,"Daimler
4.2",Bengaluru,"Stuttgart, Germany",10000+ employees,1886,Company - Public,Transportation Equipment Manufacturing,Manufacturing,₹500+ billion (INR),"Audi, Porsche, BMW","Daimler
",0,134,1,0,0,1
Data Scientist DA4AD,"Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality

Responsibilities
Selecting features, building and optimizing classifiers using machine learning and Deep Learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance

Skills
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, CNNs, etc.
Very good experience with common data science toolkits of Python like numpy, pandas, pyTorch. Excellence in at least one of these is highly desirable
Great communication skills
Experience with data visualisation tools like matplotlib, Tableau
Proficiency in using query languages such as SQL
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality",3.5,"Mercedes-Benz Research and Development India Private Limited
3.5",Bengaluru,"Chakan, India",1001 to 5000 employees,1996,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),"Volkswagen, Tata Motors","Mercedes-Benz Research and Development India Private Limited
",0,24,1,0,0,1
Data Engineer,"Summary:

You have experience with client projects and in handling vast amounts of data working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques. You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Analytics team. Play a key role on projects from a data engineering perspective, working with our Architects and clients to model the data landscape, obtain data extracts and define secure data exchange approaches.
Plan and execute secure, good practice data integration strategies and approaches
Acquire, ingest, and process data from multiple sources and systems into Big Data platforms
Create and manage data environments in the Cloud
Collaborate with our business analysts and data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Have a strong understanding of Information Security principles to ensure compliant handling and management of client data
This is a fantastic opportunity to be involved in end-to-end data management for cutting edge Advanced Analytics and Data Science
Qualifications:
Experience on client-facing projects, including working in close-knit teams
Experience and interest in Big Data technologies (Hadoop / Spark / NoSQL DBs)
Experience or familiarity with real-time ingestion and streaming frameworks is a plus
Experience and desire to work with open source and branded open source frameworks
Experience working on projects within the cloud ideally AWS or Azure
Experience with NLP, Machine Learning, etc. is a plus
Experience working on lively projects and a consulting setting, often working on different and multiple projects at the same time
Strong development background with experience in at least two scripting, object oriented or functional programming language, etc. SQL, Python, Java, Scala, C#, R
Data Warehousing experience, building operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Excellent interpersonal skills when interacting with clients in a clear, timely, and professional manner.
A deep personal motivation to always produce outstanding work for your clients and colleagues
Excel in team collaboration and working with others from diverse skill-sets and backgrounds
Cervello is a dynamic technology company that is focused on business analytics and planning. We take an innovative approach to making complex solutions simple so our clients can focus on running their businesses. Our services and applications enable our clients to gain the benefits of a world-class analytics and planning capability without the headaches.

Powered by JazzHR",4.1,"Cervello Inc
4.1",Bengaluru,"Boston, MA",51 to 200 employees,2009,Company - Private,IT Services,Information Technology,₹1 to ₹5 billion (INR),-1,"Cervello Inc
",0,11,1,1,1,1
Data Scientist,"Experience: 2-5 Years

Job Summary

Design and execute statistical analysis, modelling, and simulation efforts for clients that lead to actionable decisions affecting operations.

Analyse data sets to summarize, identify trends, predict future states, and characterize uncertainty.

Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, and R.

Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory.

Use statistical theory on modelling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modelling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in Python for ML model development.
Experience with machine learning & Deep learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Skills and Abilities Required for Consideration:
Sound experience in using statistical and data mining techniques to solve real business problems
Having skills on Python for ML model Development
Passion for problem-solving, developing creative solutions, and continuous learning.
1+ years of Experience in Automotive / Mechanical background.
2+ years of ML/ Data science Experience
Good to have: Having worked on connected device. Having Idea on Clustering etc
Preferred : Deep Learning with Pytorch or TensorFLow Location: Bangalore",4.0,"Careator Technologies
4.0",Bengaluru,"Hyderabad, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Careator Technologies
",0,-1,1,0,0,0
Senior Data Scientist- AI,"Description:
Background:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Description:
We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 5-7 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Lymbyc Solutions
",1,-1,1,1,0,1
Sr. Business Intelligence Engineer,"Amazon Indias Supply Chain Analytics team is looking for talented Sr. Business Intelligence Engineer (Sr. BIE), who enjoys the challenge of diving into complex business problems, providing data driven insights, and making recommendations that directly impact business. As a Sr. BIE you will use broad technical skills to build analytics and reporting capabilities that enable the optimization of our fulfillment network. The ideal candidate is a highly analytical, critical thinker with advanced problem solving, data mining, and data engineering or software development skills. They will enjoy working with research scientists, program managers, product managers, data engineers, and software developers to drive decisions across Amazons retail and operations teams. Successful members of this team are customer obsessed, flexible, and collaborative team players who enjoying working across functions and organizations to solve problems and get results. They thrive in ambiguity, ask hard questions, and build scalable solutions that provide critical business insights necessary to influence decision making across organizations. They find timely answers buried in large data sets and complex systems, identify root causes, and are obsessed with generating business insights. This position requires superior analytical thinkers, able to quickly approach large ambiguous problems and apply technical and engineering expertise to rapidly prototype and deliver solutions. The scale is massive; as is the opportunity!
In this role, you will be asked to:
· Perform simultaneous large, complex, and business critical analyses that serve major parts of the business.
· Develop scalable models and tools that speed up both decision making and accuracy for the team.
· Be a key influencer in strategy and contribute significantly to overall planning.
· Navigate discordant views, find the best way forward, and influence stakeholders around a solution.

In this role, responsibilities will include:
· Defining, developing, and maintaining critical business and operational reports reviewed on a weekly, monthly, quarterly, and annual basis
· Analysis of historical data to identify trends and support decision making, including written and verbal presentation of results and recommendations
· Collaborating with software development teams to implement analytics systems and data structures to support large-scale data analysis and delivery of machine learning and econometric models
· Mining and manipulating data from database tables, simulation results, and log files
· Identifying data needs and driving data quality improvement projects
· Understanding the broad range of Amazons data resources, which to use, how, and when
· Thought leadership on data mining and analysis
· Modeling complex/abstract problems and discovering insights using statistics, data mining, and visualization techniques
· Helping to automate processes by developing deep-dive tools, UIs, metrics, and dashboards to communicate insights to the business teams
· Collaborating effectively with internal end-users, cross-functional software development teams, and technical support/sustaining engineering teams to solve problems and implement new solutions.


Basic Qualifications

· 5+ years of experience as an analyst or engineer in the data/BI space
· Experience working directly with business stakeholders to translate between data and business needs
· Experience with data visualization using Tableau, Quicksight, or similar tools
· Experience with SQL
· Bachelor's degree in Math/Statistics/Engineering or other equivalent quantitative discipline.
· 5+ years in relevant experience as data scientist, software engineer, business intelligence engineer, or equivalent.
· Advanced knowledge of SQL, shell scripting, Python/R, and MS excel.
· Strong active listener with solid written and verbal communication skills.
· Proven ability to work cross-functionally and delivering automated solutions for customer-facing data science problems.
· Ability to work cross-functionally, building and maintaining trust with internal stakeholders.
· Strong understanding of BI technologies and their application including database warehousing and dashboarding
· Experience on at least one data visualization tools (e.g. OBIEE, Tableau, QlikView)
· Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams

Preferred Qualifications

· Master's degree in Math/Statistics/Engineering or other equivalent quantitative discipline.
· 8+ years in relevant experience as data scientist, software engineer, business intelligence engineer, or equivalent.
· Advanced knowledge of SQL, shell scripting, Python/R, and MS excel.
· Strong active listener with solid written and verbal communication skills.
· Proven ability to work cross-functionally and delivering automated solutions for customer-facing data science problems.
· Familiarity with supply chain management concepts - planning, forecasting, optimization, and logistics - gained through work experience or graduate level education
· Strong understanding of BI technologies and their application including database warehousing and dashboarding
· Experience communicating with senior management (Senior leaders/decision makers) as well as with colleagues from computer science, operations research, and business backgrounds.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,0,1
Data Scientist,"What you will get to do:
As a Data Scientist, your role will encompass
You will have complete ownership of the data science roadmap
You will set the solutioning strategy for the company by guiding business and product teams in product prioritization and ML transformation.
Developing analytical solutions across verticals from scratch and implementing the same for the various teams in the organization.
You will raise the functional bar for the team, bringing industry best practices and advanced ML techniques to the team.
You will hire, guide and coach your team, and scale the Data Science organization to keep pace with fast growth.
Leading and conducting ambitious projects in the transformation of clients through data
Ability to leverage the following tools and techniques:
Predictive statistical models
Customer profiling
Segmentation Analysis
Data Analysis and Mining
Machine Learning and Deep learning models for prediction and explanation
Explainable AI
Determine quantitative methods for solving client problems
Assist in presenting ideas and findings to future and existing clients
Proactive and effective interaction with other internal groups
Evaluation and improvement of internal tools and processes
Ability to gain domain expertise and formularize new modules in Products that leverage Data science-based solutions.
What you will need to make an impact
A Master’s degree in machine learning, mathematics, computer science, or related fields
10+ years of hands-on experience developing and applying data-driven solutions in a corporate
or consulting setting, preferably in a consumer marketing context (experience in the web industry is a plus)
Ability to apply statistical techniques such as linear regression, logistic regression, analysis of variance, cluster analysis, CHAID, CART, time series, principal components, factor analysis to business problems.
Ability to design Machine Learning models-based solution. Experience with R, Python, Spark, TensorFlow, Caffe, PyTorch and Big data platforms like Apache Spark and Hadoop
Strong experience and knowledge of data processing, data modeling, algorithms, and data architecture
Experience leading a technical project in a business context
Intellectual curiosity and excellent problem-solving skills, including the ability to structure and prioritize an approach for maximum impact
Excellent written and spoken Spanish and English skills.
Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and Torch.
Experience with Big Data platforms like Apache Spark and Hadoop.
Experienced in data processing with Python, R & SQL.
What we are looking for
A Doer: you get things done and inspire your teams to do the same
An Analyst: you LOVE data and think every company should take their decisions with facts
A Pragmatist: you have a hacker mindset and always find the quick wins
A Mentor: your clients and teams naturally seek for advice
An Adventurer: you’re an entrepreneur constantly looking for problems to solve
Job Types: Full-time, Volunteer

Salary: ₹3,500,000.00 to ₹4,000,000.00 /year

Experience:
work: 8 years (Required)
total work: 10 years (Required)
Education:
Bachelor's (Required)",4.2,"Multi Recruit
4.2",Bengaluru,"Bengaluru, India",1 to 50 employees,2013,Company - Private,Staffing & Outsourcing,Business Services,₹10 to ₹50 billion (INR),-1,"Multi Recruit
",1,7,1,1,0,1
Data Scientist,"About us & Vision

Sequretek is an Indian MNC focused on Information Security and Information Management space. The company is backed by industry veterans who have come together with a vision to build India’s leading Information Security company.
Sequretek’s customers have appreciated its solution offerings, and within a short span the company has acquired marquee clientele in Financial, Pharmaceutical, IT/ITES, and Retail and Logistics sectors.
Sequretek probably is the one of the very few companies that offers a blend of its own core threat intelligence products along with both on-premise and cloud solutions. Our end point detection, protection, and response technology – EDPR is the industry’s only product that replaces up to six different endpoint technologies for our customers.
Our vision is to establish and sustain Sequretek as a Global Leader in terms of the ‘Security’ of Enterprise-level Information-Assets through the consistent delivery of world-class products and solutions that leverage state-of-the-art technologies relevant to the contemporary digital economy.

Why Sequretek?

You will be part of an award winning ""Security Product Company of the Year – 2019” announced by Data Security Council of India (A NASSCOM Initiative).
The team is highly visible, agile, and working on critical problems that directly affect the company’s success.
Our researchers regularly appear at various global conferences and are some of the most sought-after thought leaders in the security industry.
Our ML Engine was certified by ICSA Labs for its detection against unknown / little known malwares.
As part of the research group, you will leverage your problem-solving and analytical skills to further our capabilities, as well as publish and present new and novel research.

Education & Experience

Education:The candidate must have any of the below:
BE/B.Tech/MTech in Computer Science, Statistics, or Data Science.
Experience:
Minimum 1-2 years of experience in applying ML/Deep Learning algorithms and
techniques to real-world data sets.

Key Responsibilities

Skills:
Knowledge of Core Python
Proficiency in Machine learning algorithms (SVM, Decision Trees, PCA, Clustering etc.).
Knowledge and Experience of Deep Learning Algorithms (CNN, RNN, LSTM etc.)
Knowledge of major ML frameworks such as TensorFlow, PyTorch, Keras, and Scikit-Learn.
Strong analytical thinking and problem solving.
Designs scalable processes to collect, manipulate, present, and analyze large datasets in a production-ready environment
Demonstrated participation on platforms like Kaggle is a plus
Prefer great appreciation or expertise in Security products such as End point detection, protection and response, Managed detection and response etc
Must be proactive and flexible and have the ability to work under pressure and possess good follow-through skills.
Must possess excellent written and verbal communication and a quick learner.
Responsibilities:
Wants to build and develop innovative intellectual property through the research and implementation of new approaches in machine learning and simplifying security
Approaches problems from an adversarial mindset in an effort to circumvent prediction systems
Works with internal product and engineering teams to drive development of new products
Has the capability to translate and implement newly published research on specific datasets and problems to validate approaches and potentially improve
Experienced wrangling large volumes of data and applying machine learning techniques towards real product and business problems
Invests time in research including publications, and is committed to keeping up with AI trends
Develop working prototypes of algorithms and evaluate and compare metrics based on large, real-world data sets",4.0,"Sequretek
4.0",Bengaluru,"Mumbai, India",201 to 500 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,"Sequretek
",0,7,1,0,0,1
Data Scientist-ONWARD,"Data Scientist-ONWARD
Job Description


At Kimberly Clark, we believe in a truly diverse and inclusive culture and towards this end a brand new initiative – ONWARD, Career Restart Program has been recently launched .

The vision of the program is to broaden and diversify candidate talent pools by empowering experienced professionals to restart their careers, following a hiatus, with Kimberly Clark. Seasoned professionals (often women) with a career break are highly skilled and are an untapped pool of experienced talent. Through this program we will provide a road to re entry, strengthening our workforce diversity and maximizing women’s workforce participation.

If you think you qualify for this program and have the skills, check out the following open job with us-

IT Data Scientist- ONWARD

Job Description Summary

The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

This role is viewed as an expert in making sense of complex data environments, encompassing both business data and process understanding and technical expertise. Leads in developing innovative, technical solutions to important, highly complex strategic and operating problems. Has strong knowledge in business and technical functions that are touch points with their area of expertise. Provides technical consulting on complex projects. Acts as a source of direction, training and guidance for other team members. Is knowledgeable in industry best practices in their area of expertise and uses resources outside of KC to deliver solutions.

Duties and Responsibilities:Job Details
Development of advanced analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity.
The Data Scientist must understand complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations).
Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery.
Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance.
Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions.
Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders.
Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals.
Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented.
Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities.
Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction
Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.
Education required/ preferred:
B.A. or B.S. in Information Technology, Data Science, or related field.
At least 8 years of IT experience and at least 4 years or more of work experience in data scientist discipline.
Deep knowledge of machine learning, statistics, optimization or related field.
Experience with R, Python, Matlab is required.
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc.
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc.
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.).
Excellent written and verbal communication skills along with strong desire to work in cross functional teams.
Consumer products experience in an online and/or retail/manufacturing environment is preferred.
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges.
Provide thought leadership while keeping up with industry trends and disseminating information across the organization.
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources.
Strong Technical leadership of advanced analytics teams and vendors.
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Travel may include less than 10% of work time. Travel may also include travel via aircrafts and motor vehicles to various locations, if applicable. Varying working conditions may include prolonged sitting, typing and viewing computer/laptop screens, along with occasional bending, reaching, lifting, carrying, climbing, twisting, stooping, walking and standing.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bangalore GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever","Kimberly-Clark
",0,148,1,1,0,1
"Manager, BI","About the Team
Workplace Health and Safety (WHS) is constantly looking for ways to improve the safety programs and processes in our sites, so that our associates can stay healthy and safe. The WHS Tech team is a critical partner in these initiativesby delivering deep business insights, developing predictive models and risk frameworks, and creating products and applications that enhance the technology footprint in the core processes. We have just started scratching the surface in terms of possibilities, and are exploring a wide array of technology options to anticipate, assess, and manage workplace hazards and risks, better.

We are looking for a BI leader to lead our Analytics efforts in the area. Data and Insights form the basis of every decision at Amazon, and as such we are looking for an individual who can further drive analytical rigor and advance the maturity of the BI functionacross business reporting, program design and measurement, and Impact & Driver analysis. The individual should have excellent analytical abilities, outstanding business acumen, and strong comfort in working with technical teams and systems. Strong attention to detail is a must, and so is the ability to work in a fast-paced and ever-changing environment. The individual should also be comfortable with ambiguity and have demonstrated experience in creating and driving the charter of a mid-sized BI team.

Responsibilities
· Hire, manage, coach and lead a high performing team of Business Intelligence Engineers and/or Data Scientist.
· Engage with leadership and diversified stakeholder groups to understand their data and analytics needs and recommend BI or ML solutions
· Partner with the Data Engineering teams to define the data elements and data structure that the team should leverage to enable analytical capabilities
· Design, implement, and support platforms that provide business teams ad-hoc access to large datasets (e.g. data visualization tools for non-tech business users)
· Own the design, development, and maintenance of ongoing performance metrics, reports, analyses, dashboards, etc. to drive key business decisions
· Standardize data and report consumption across all customer groups
· Recognize and adopt best practices in reporting and analysis: data integrity, analysis, validation, and documentation
· Proactively develop new metrics and studies to quantify safety risks and identify program opportunities
· Work with Data Engineering, Machine learning, and Software Development teams to drive capture and storage of key data points, and on implementation of new dashboards/analyses
· Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication


Basic Qualifications

· Bachelor's/Master's degree in a quantitative field or equivalent.
· 9+ years of relevant work experience in business intelligence, analytics, statistics, data science, or a related field.
· Advanced proficiency in SQL, data modeling, and working with Big Data
· Experience with data visualization using Tableau or similar tools
· Experience with statistical modeling and analyzing large data sets
· Experience in managing and prioritizing a project backlog
· Experience in hiring, retaining, coaching, and managing a high-functioning team
· Strong critical thinking skills and attention to detail
· Both technically deep and business savvy enough to interface with all levels and disciplines within the organization
· 5+ years work experience in managing a team of Business Intelligence Engineers/Analysts or Data Scientists. Experience in managing layered teams is preferred.
· Strong organizational and multitasking skills with ability to balance competing priorities


Preferred Qualifications

· Masters/PhD is a plus
· DS/ML Team Leadership experience is desired, but not mandatory",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,0,0,0,1
Data Scientist- AI,"Description:
Lymbyc is the first and currently the only player, in the predictive engine-based self-service analytics product space for end business users. We have created the world’s first data scientist, Leni, capable of understanding plain English queries from user, and autonomously being able to take decisions ranging from data selection to algorithm selection and finally visualisation and narratives, without any human intervention. And now we are embarking on bringing explainable component to our AI based solutions, to make the business decisions simpler, easier and adaptable to larger stakeholders.

By way of our acquisition, we at Lymbyc now are working full tilt with LTI’s global reach to take Leni to the world’s major businesses.

Descriptions

We need ace data scientists who can develop best in class predictive models, machine learning models and deep learning models and at the same time they should be able to explain the decisions taken by the models automatically through plain simple English language. The explainable elements should not be limited to the numbers and formulas, there must be a bit of personalization also to understand the context of the problem.

Roles and Responsibilities:
Passion for learning new technologies and be up to date with the scientific research community.
Work in technical teams in development, deployment, and application of machine learning solutions, leveraging technical components and explaining the modelling decisions
Take responsibility for insights, reports and explanability of the decisions taken by predictive models
Responsible for taking an idea from concept to production thoroughly with feedback from all stakeholders.

Qualification:
Masters’ in Computer Science/M. tech/PhD/Statistics/Econometrics/Applied Mathematics/Applied Statistics/Operations Research is a must
Hands on Experience with data mining or machine learning, deep learning, computer vision, natural language processing
Hands on Experience in developing deep learning models and explaining the results of deep learning models in a business-friendly manner

Skills Required:
Must have minimum of 3-5 years of industry experience in developing data science models.
Deep understanding and experience in the field of Machine Learning, Deep Learning and statistical learning
The person should be excellent at Classification (logistic regression, svm, decision tree, random forest, neural network), Regression (linear regression, decision tree, random forest, neural network), Classical optimisation (gradient descent, newton rapshon, etc), Graph theory (network analytics), Heuristic optimisation (genetic algorithm, swarm theory)
Should be strong at Deep leaning (CNN, LSTM, RNN, Bi-LSTM)
Must have thorough mathematical knowledge of correlation/causation, decision trees, classification and regression models, recommenders, probability and stochastic processes, distributions, priors and posteriors.
Skilled at scientific programming languages such as Python, R, Matlab and writing deployable code into production.
Understand the model lifecycle of cleansing/standardizing raw data, feature creation/selection, writing complex transformation logic to generate independent and dependent variables, model selection, tuning, A/B testing and generating production ready code.
Knowledge of Numerical optimization, Linear/Non-linear/Integer programming, Statistics, Combinatorial optimization is a plus.
Familiarity with R, Apache Spark (Scala, Python), PyMC3/theano/tensorflow/Keras and other scientific python/R modules is a must.
AI skillsets – hands-on Machine learning and Deep Learning algorithms and platforms, neural networks in any, or all the following areas, specifically, in Data & Analytics use cases
Language – Natural Language Processing, machine translation, emotion detection, language detection, classification
Vision – computer vision, object recognition/tracking, face/gender/age/emotion recognition, OCR/handwriting recognition
Knowledge and experience in some of the key AI platforms will be important, e.g. IBM Watson, Microsoft Azure, Google Api.Ai, Facebook Wit.Ai, Chatbots using Microsoft Bot Framework
Knowledge and experience of key machine learning and deep learning framework, e.g. Keras, TensorFlow, Caffe, CNTK, Jiraffe, MXNet and PyTorch commercial technologies/platforms, etc",3.5,"Lymbyc Solutions
3.5",Bengaluru,"Bengaluru, India",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Lymbyc Solutions
",1,-1,1,1,0,1
Data Engineer,"At Rockstar Games, we create the games we would want to play ourselves.

A career at Rockstar is about being part of a team working on some of the most creatively rewarding, large-scale projects to be found in any entertainment medium. You would be welcomed to a friendly, inclusive environment where you can learn, and collaborate with some of the most talented people in the industry.

Rockstar India is on the lookout for talented Data Engineers who possess a passion for Game Analytics. This is a full-time permanent position based out of Rockstar's unique game development studio in Bangalore, India.

WHAT WE DO
The Rockstar Analytics team provides insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.
We work together with a number of departments to design and implement data and pipelines.
We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses and machine learning applications.
RESPONSIBILITIES
Resolve operational issues as they occur to maintain the team's SLAs.
Implement and support big data tools and frameworks such as HDFS, Hive, and Impala.
Implement and support data models using Spark and Spark-ML.
Assist in the development of deployment automation and operational support strategies on Hadoop and Snowflake.
Deliver near-real time and non-near-real-time data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholders.
Maintain and extend our CI/CD processes and documentation.
QUALIFICATIONS
5+ years of work experience with ETL, Data Modeling, and Business Intelligence Big Data Architectures.
5+ years of experience with the Hadoop ecosystem (Map Reduce, Spark, Spark-ML, Oozie, Hive, Impala, etc.) and big data ecosystems (Kafka, Cassandra, etc.).
Experience developing and managing data warehouses on a terabyte or petabyte scale.
Experience developing Machine Learning pipelines and data models.
Strong experience in massively parallel processing & columnar databases.
Experience with Python and shell scripting.
Experience working in a Linux environment.
Deep understanding of advanced data warehousing concepts and track record of applying these concepts on the job.
SKILLS
Expert in at least one SQL language such as T-SQL or PL/SQL.
Good communication skills.
Dynamic team player.
A passion for technology - we are looking for someone who is keen to leverage their existing skills and seek out new skills and solutions.
PLUSES


Please note that these are desirable skills and are not required to apply for the position.
Experience in real-time analytics applications.
Experience in Lambda architecture and On-Premise Clusters.
Experience with Java or Scala programming languages.
Experience with CI/CD.
Knowledge of RestAPI and Artifactories.
Knowledge of the video game industry.
HOW TO APPLY


Please apply with a CV and cover-letter demonstrating how you meet the skills above. If we would like to move forward with your application, a Rockstar recruiter will reach out to you to explain next steps and guide you through the process.

Rockstar is proud to be an equal opportunity employer, and we are committed to hiring, promoting, and compensating employees based on their qualifications and demonstrated ability to perform job responsibilities.

If you've got the right skills for the job, we want to hear from you. We encourage applications from all suitable candidates regardless of age, disability, gender identity, sexual orientation, religion, belief, or race.",3.9,"Rockstar Games
3.9",Bengaluru,"New York, NY",1001 to 5000 employees,1998,Subsidiary or Business Segment,Video Games,Media,₹1 to ₹5 billion (INR),-1,"Rockstar Games
",0,22,1,1,0,0
Data Scientist/ML Engineer,"About Us: https://paytm.com/about-us/

Why Us:
Looking for a company that encourages passion, courage and imagination, where you can be part of the team crafting the future of payments, ecommerce, and financial services? Want to craft how millions of people transact, buy, sell, connect, and share? If you’re passionate about building large scale recommendation engines, fraud detection, discovery, and joining a purpose driven community that is dedicated to creating an ambitious and inclusive workplace, join Paytm – a company you can be proud to be a part of.

About Team:
The ML team within Paytm provides opportunities to innovate in a fast-paced organization that contributes to game-changing projects and technologies that get deployed on devices and the cloud. As an ML engineer, you'll partner with technology and business teams to build new services that surprise and delight our customers. You will be working with massively large data to solve real-world problems. You'll design and run experiments, research new algorithms, and find new ways of recommendations, optimizing risk, profitability, and customer experience.

We’re looking for top data scientists capable of using ML and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.

Experience Required: 4-8 yrs
Job Location: India

Responsibilities

Use deep learning, machine learning and analytical techniques to create scalable solutions for business problems

Have excellent Programming/Debugging skills in Python/Java/Scala.

Have strong hands-on experience with Hadoop, MapReduce, Hive, Spark, Flink.Design, develop, evaluate, and deploy innovative models for predictive learning, content ranking,
Credit scoring and fraud detection.

Interact with customers directly to understand the business problem, help and aid them in implementation of DL/ML algorithms to solve problems.

Analyze and extract relevant information from large amounts of data to help automate and optimize key processesActively identify new areas where data science can be leveraged across the organization.

Hands on experience building models with frameworks like Tensorflow, Caffe, Theano, etc. The motivation to achieve results in a fast-paced environment.

For more Information please connect on monika1.jain@paytm.com",3.5,"Paytm
3.5",Bengaluru,"Noida, India",1001 to 5000 employees,2010,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,"Paytm
",0,10,1,1,0,1
CIEL/SEL/1882: Data scientist,"Experience in
Python
&
R
programming
Â· Experience in
Machine Learning / Deep Learning
Â· Experience with common data science packages such as
NumPy, MatLab, Keras, Tensorflow, PyTorch, scikit learn
etc
Â· Should proactively fetch information from various sources and analyze it for better understanding and build AI tools that automate certain processes.
Â· The primary focus will be in applying data mining techniques, doing statistical analysis, and building high-quality prediction systems integrated within the products",4.5,"CIEL HR Services
4.5",Bengaluru,"Bengaluru, India",201 to 500 employees,2015,Company - Private,Staffing & Outsourcing,Business Services,₹1 to ₹5 billion (INR),-1,"CIEL HR Services
",1,5,1,0,0,0
Data Scientist,"Machine Learning & AI - Bangalore, IN

Responsibilities

We are looking for a capable data scientist to join the Analytics team, reporting locally in India Bangalore. This person’s responsibilities include research, design and development of Machine Learning and Deep Learning algorithms to tackle a variety of Fraud oriented challenges. The data scientist will work closely with software engineers and program managers to deliver end-to-end products, including: data collection in big scale and analysis, exploring different algorithmic approaches, model development, assessment and validation – all the way through production.

Qualifications
At least 3 years of hands-on development of complex Machine Learning models using modern frameworks and tools, ideally Python based.
Solid understanding of statistics and applied mathematics
Creative thinker with a proven ability to tackle open problems and apply non-trivial solutions.
Experience in software development using Python, Java or a similar language.
Any Graduate or M.Sc. in Computer Science, Mathematics or equivalent, preferably in Machine Learning
Ability to write clean and concise code
Quick learner, independent, methodical, and detail oriented.
Team player, positive attitude, collaborative, good communication skills.
Dedicated, makes things happen.
Flexible, capable of making decisions in an ambiguous and changing environment.
Advantages:
Prior experience as a software developer or data engineer – advantage
Experience with Big data – advantage
Experience with Spark – big advantage
Experience with Deep Learning frameworks (PyTorch, TensorFlow, Keras) – advantage.
Experience in the Telecommunication domain and/or Fraud prevention - advantage",3.3,"Tomia
3.3",Bengaluru,"Vienna, VA",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Tomia
",0,-1,1,1,0,0
**Principal SA - Autonomous Computing**,"Are you passionate about developing impactful, novel Machine Learning (ML) technology strategy and taking it to large-scale production? Are you passionate about engaging the AI community (AI researchers, developers building AI products, roboticists making robots that work, data scientists, and innovative entrepreneurs in hot startups and large enterprises)?


Artificial Intelligence (AI) has the potential to transform our society and community for generations. Impacting transportation, mobility, telecommunication, energy, healthcare and insurance, rescue and emergency response, hospitality. Achieving this requires implementing one of the most complex computing systems to-date at unprecedented scale. AWS Autonomous Compute is taking a fresh approach with providing an end-to-end, scalable cloud environment that simplifies the development, scaling and production deployment of AI technology. Including a global cloud footprint, infinitely scalable cloud storage, advanced networking and security, state-of-the-art AI platforms and services, rigorous engineering, and a team with the longest experience building cloud technologies.
AWS Autonomous Computing is seeking a Principal Solutions Architect (SA) for our Autonomous Computing business. The SA will be responsible for defining, building and deploying effective and targeted technology strategy to accelerate broad pre-sales engineering activities. The SA will facilitate the enablement of solutions architecture with specific customer centric value proposition and demos about end-to-end AI technologies data ingestion, data preparation, model development including architecture optimization, model validation, large-scale orchestration, deployment and model lifecycle management on the AWS cloud. The SA will directly interface with the AWS product and software development teams regarding customer and partner requirements. The SA will work closely across multiple internal and external organizations AWS product engineering, business development, sales, marketing, partners, and machine learning research communities to position the AWS platform for customers and partners; and provide guidance on the value proposition and benefit to those customers and partners.

The ideal candidate will possess a deep technical background combined with business acumen that enables them to drive an engagement and interact at the highest levels of startups and large Enterprises. The candidate will have the technical depth and business experience to easily articulate the potential and challenges of AI (different platforms and frameworks in the AWS cloud) to engineering/research teams and C-Level executives. This requires deep familiarity with state-of-the-art approaches to AI, as well as target AI use cases using distributed computing systems in the cloud.



As the ideal candidate, you will be the thought leader responsible for helping customers understand the value proposition of production-grade AI on AWS, creating the most compelling content and demos to help customers understand the use cases and value propositions, and building the right programs to increase awareness and adoption. You will also be a trusted advisor to customers and internal teams; helping develop the AI knowledge and skills of Solutions Architects, as well as the technical field community. Additionally, you will work with the AWS Machine Learning and AWS EC2 engineering and product management teams to shape product vision and prioritize features for AI products and solutions. You will get to work on a leading technology field and growing business; and have a material impact, every day. You will be able to facilitate relationships with senior personnel, as well as easily interact and give guidance to technical experts, researchers, software developers, IT pros, and system architects. This requires a demonstrated ability to think strategically about business, product, research, and technical challenges.

This is an opportunity to be a thought leader in the emerging space of autonomous computing and make a significant contribution to enable transformation across several industries.


About AWS

Amazon Web Services (AWS) is the pioneer and recognized leader in Cloud Computing. Our web services provide a platform for IT infrastructure in-the-cloud that is used by hundreds of thousands of developers and businesses around the world. These customers range from start-ups to leading web companies to Global 2000 companies in financial services, pharmaceuticals, and technology. AWS customers are looking for ways to transform their businesses and solve their own complex business challenges with machine learning (ML) technologies in the cloud. AWS is leading the way in providing customers with powerful, end-to-end machine learning platforms such as Amazon SageMaker.

Roles & Responsibilities:
· Architect advanced solutions leveraging AWS services like EC2, S3, SPOT, and ML related services, working closely with our customers to deeply understand their business needs and to design technical solutions that take advantage of the AWS Cloud platform.
· Demonstrate the viability of each solution through mechanisms like proof-of-concepts, prototypes and pilots including applied research activities that bring early-stage products to market.
· Develop best practices documentation, and develop a strong go-to-market technical strategy.
· Craft and develop compelling audience-specific messages and tools (product videos, customer success stories, advanced demos, white papers, presentations, how to guides, etc.)
· Evangelize AWS AI architectures and technologies through forums such as AWS Blogs, white papers, reference architectures and public-speaking events such as AWS summit, and user-group events.
· Collaborate with AWS field sales, professional services, training and support teams to help partners and customers learn and effectively use AWS for AI.
· Serve as a key member of the business development and account management teams helping to ensure customer and partner success in AI on the AWS platform.
· Act as a technical liaison between customers, service engineering teams and support teams.
· Gain recognition and credibility as a regular panelist and keynote speaker for multiple internal and external events.
· Deliver compelling presentations, product demos, roadmap reviews, sample solutions and discussions to drive adoption of AI on AWS.
· Identify leads for potential engagement needing pre-sales support.
· Collaborate with internal teams to define the product road map, market positioning and developer program initiatives
· Assess training requirements and coordinating with various training teams on scheduling and delivery of training to both internal and external audiences.





Basic Qualifications

- MS in Engineering (or related STEM fields)
- 7+ years experience working with a few of these technologies: advanced machine learning, probabilistic modeling, optimization, sensor fusion and scalable computing systems.
- Demonstrated ability to work with multiple technical and stakeholder groups to bring a complete solution to production.
- Strong track record of publications in peer-reviewed journals, conferences and/or curated blogs.
- Deep knowledge and extensive experience building and deploying one or more of these technologies in production: Deep learning (e.g. CNN, RNN, LSTM, GAN, etc.), Reinforcement Learning, Accelerated compute (e.g. GPU, FPGA, ASICs, etc.), ML Frameworks (e.g. TensorFlow, PyTorch, etc.), ML engineering (e.g. Containers, Kubernetes, Kubeflow, etc.), Probabilistic Modeling (e.g. Bayesian modeling, Probabilistic Deep Neural Networks, Probabilistic Graphical Models, etc.), Global non-convex optimization (e.g. Genetic Algorithms, Particle Swarm, etc.) and non-linear estimation techniques (e.g. Unscented Kalman Filters, Particle filters, etc.) and time series forecasting.

- Experience with one or more general purpose programming languages, including but not limited to: Python, Go, C/C++, JavaScript, Java.
- Solid enterprise communication skills, and business and financial acumen.
- Strong analytical skills, and demonstrated ability to turn detailed data analysis into useful strategic insight in order to drive customer adoption and make appropriate recommendations to the business.
- Strong verbal and written communications skills are a must, as well as leadership skills.
- Demonstrated ability to work effectively across internal and external organizations.




Preferred Qualifications

- Ph.D. in Engineering (or related STEM fields)
- Experience developing, deploying and managing AI products at scale.
- 10+ years of engineering, development, data science and modeling experience.
- Demonstrated experience solving end-to-end large-scale problems in aerospace, transportation, energy, manufacturing, telecommunications, genomics, healthcare and/or robotics with proven AI technologies deployed at scale.
- Experience with cloud computing and distributed computing.",4.2,"Amazon
4.2",Bengaluru,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,₹500+ billion (INR),"Google, Microsoft, Walmart","Amazon
",0,26,1,0,1,0
Data Scientist,"Location: Bangalore, India.

Dasceq: Data – Science – Equilibrium
Transforming Collections with AI/ML and Big Data
In the digital age, businesses have access to more data than ever before, and this data can be leveraged to drive decision-making for improved growth and seamless consumer experience including collections. Since being founded in 2017, our team of data scientists and domain experts at Dasceq (Data – Science – Equilibrium) have created a AI platform to boost collections efficiency and amount collected. We are leading edge AI Startup converging Machine learning, AI with deep collection and servicing experience leveraging AI/ML and Big Data to create a unique platform for Collections. Our next generation product is enabling clients to improve consumer experience and ROI. Dasceq’s next-gen SaaS AI platform optimizes collections with data-driven insights.

We experiment and innovate leveraging the latest technologies to engineer breakthrough AI product, customer experiences, and bring simplicity and humanity to collections. At Dasceq Center for Artificial Intelligence and Innovation, you’ll be part of an elite team accelerating adoption of AI, ML and Big Data for Fortune enterprises in USA.

Do you have it in you to join Dasceq? We are a committed and passionate team of hard working individuals who are making a difference for our clients, our industry and our team members. We are looking for passionate individuals who are great performers and willing to be part of team passionate about building production-quality applications using cutting-edge machine learning algorithms? They must be Self Starter, Hard Workers, Great Team Spirit and a willing to become experts in their domain? If the answer is YES then APPLY

We are looking for a Data Scientist who will work in our AI/Data Science Innovation Team and will leverage data to gain insights by analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.
They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
Responsibilities for Data Scientist:
Data mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications for Data Scientist
Has a bachelor’s degree in Computer Science, Economics, Statistics or another quantitative field, and is familiar with data science algorithms.
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets and experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 3-5 years of experience manipulating data sets and building statistical models, has a master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several language C++, python, R.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc.
Experience visualizing/presenting data for stakeholders using: BI tools.
Only those candidates can apply:
Have a great attitude, willing to learn and work hard and excel in career.
Are available for full time (in-office) to work at our Jaynagar Office in Bengaluru
can start the between 1st March19 and 15th April’19
Other requirements:
Should have an ability to work in a team with good communication skills
Should have the ability to meet routine production deadlines
Should be well versed with computer concepts of the internet, networking, browser, website, apps, MS Office, etc.
Should have basic knowledge of Excel, Word, Presentation, Google Sheets, and Google Docs
Should have a strong attitude to learn and logical reasoning
Open to work long hours and weekend as needed (one to two weekend a month).
* Women willing to start/restart their career can also apply.
Perks:
Daily Lunch and Snacks Provided
Bi-Weekly Team Events and Office Party.

Required for Interview:
Current and past jobs pay slip and appointment letter (pdf)
All diploma and certificate copies (pdf)
Three References",2.0,"Dasceq
2.0",Bengaluru,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Dasceq
",0,-1,1,0,0,1
Data Scientist,"Key Responsibilities
Build Data Pipelines for AI/ML Solutions using Python
Build Data Pipelines deployed at the edge (customer locations)
Programming skills:- Python (with working experience in most of common libraries like Scikit , numpy, pandas, mathplotlib, keras, tensorflow, nltk, genism, spacy etc)
Good knowledge in statistics and deep understanding on ML algorithms and their usage
Working experience in end to end data science project life cycles from use case framing, data collection, data exploration, model building, deployment
Working experience in most of the common Machine Learning techniques related to Time series, Regression, Classification, Clustering, NLP, working with IoT data
Good to have working exposure in common cloud environments and understanding of robust on premise data science infrastructure.
Nice to have understanding of big data related technologies and DevOps(Dockers, Singularity)
Other skills/ expectations
Good communication and presentation skill
Proven ability be creative and analytical in trouble shooting issues
Ability to work in a fast-paced and high-pressure environment to manage competing priorities
Qualifications

Education
Bachelor's Degree in computer sciences or related field
3+ total years of Experience
1+ years of relevant Experience

Functional Knowledge

Demonstrates expanded conceptual knowledge in own discipline and broadens capabilities

Business Expertise

Understands key business drivers; uses this understanding to accomplish own work

Leadership

No supervisory responsibilities but provides informal guidance to new team members

Problem Solving

Solves problems in straightforward situations; analyzes possible solutions using technical experience and judgment and precedents

Impact

Impacts quality of own work and the work of others on the team; works within guidelines and policies

Interpersonal Skills

Explains complex information to others in straightforward situations

Qualifications

Education:
Bachelor's Degree

Skills

Certifications:
Languages:
Years of Experience:
2 - 4 Years

Work Experience:
Additional Information

Travel:
Yes, 10% of the Time

Relocation Eligible:
Yes

Applied Materials is committed to diversity in its workforce including Equal Employment Opportunity for Minorities, Females, Protected Veterans and Individuals with Disabilities.",3.7,"Applied Materials Inc.
3.7",Bengaluru,"Santa Clara, CA",10000+ employees,1967,Company - Public,Electrical & Electronic Manufacturing,Manufacturing,₹500+ billion (INR),-1,"Applied Materials Inc.
",0,53,1,0,0,0
Data Scientist,"Description
BizViz provides a 360 degree view of a business's data, serving any vertical and meeting the demanding needs of all business executives. With a 50+ strong team building the BizViz platform over several years, it is targeted at creating technological solutions that will give our customers the edge they need to succeed.

We strongly believe that our success lies in the success of our customers. We aim to build applications the way they envisioned, keeping each business' unique ideas and requirements in mind. We offer businesses a better alternative to using standard cookie-cutter ERP templates.

Job Summary
Design and execute statistical analysis, modeling, and simulation efforts for clients that lead to actionable decisions affecting operations. Analyze data sets to summarize, identify trends, predict future states, and characterize uncertainty. Author complex written products documenting study results. Apply analytical approaches using statistical programming languages, including Python, SAS, and R. Work closely with teammates from non-mathematical disciplines to ensure that operational strategies are considered in the context of applying statistical theory. Use statistical theory on modeling, simulation, and data analysis to deliver measurable improvements to organizational policies and programs.

Responsibilities
Engage in data mining, algorithm development, statistical analysis, regression, and machine-learning initiatives
As part of ongoing work and interaction with the broader team, identify new opportunities to use modeling and advanced analytics to drive business value
High Proficiency in SQL
Expertise in applied statistics.
Able to translate business objectives into actionable analyses.
Able to communicate findings clearly to both technical and non-technical audiences
Expertise in at least one statistical software package such as SAS or Python and R
Experience with machine learning algorithms and predictive analytics
Natural curiosity to enjoy diving deep into the material to find answers to yet unknown questions.
Demonstrated ability to perform comfortably in a fast-paced work environment
Education, Experience, Skills and Abilities Required for Consideration as a Candidate:
PhD or MSC in a quantitative discipline: Statistics, Applied Mathematics, Operations Research, etc.
3+ years of experience in using statistical and data mining techniques to solve real business problems

Minimum of 3 years of experience in any one of the following:
Machine Learning
Data Mining
Predictive analysis
R & Python or SAS.
Passion for problem-solving, developing creative solutions, and continuous learning.
Experience in at least one of the following domain - Retail, Healthcare & Education.
Location
Bangalore & Hyderabad.",3.0,"BDB
3.0",Bengaluru,"London, United Kingdom",51 to 200 employees,1993,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"BDB
",0,27,1,0,0,0
Lead Data Scientist,"MAIN JOB PURPOSE:
Unilever is looking to disrupt status quo using data, data science and Machine Learning in a transformative way. Information and Analytics team leads this transformation by building data, data science and analytics as a core capability. The team delivers agile innovation, advanced analytics products (at scale) and work closely with the market teams to ensure that every decision in Unilever is augmented with insight & next best action recommendations.

The I&A In-Market team is composed of business analysts, data scientists, and data experts who can: quickly understand the business context + problem, apply advanced mathematics and/or statistics to large data sets; and operate in cloud-based environments. This is an exciting role for an experienced hands-on data scientist who likes working in the front line of business to re-imagine the future of enterprise.

JOB SUMMARY

Works with the business interpreter to fully understand the business problem and how to deliver relevant insights that lead to actions. Gathers, analyses, and model data to solve complex business problems
Builds Diagnostic and Predictive Models to solve the business problem applying range of techniques across classical statistics, Machine Learning and deep learning.
Power fast paced analytics experimentation (80% of time) through hands on data science solution building and creative approaches to solve ‘one of a kind’ problems.
Once proven industrialize the analytics solution (20 % of time) in partnership with the central data science hub with emphasis on tuning the model for high accuracy; coding it for optimal speed and scale
Manage small team of data scientists who are delivering according to priorities set forth by market and / or function.
Build data-science and algorithmic solutions to address business problems requiring descriptive, diagnostic, predictive, and / or prescriptive analytics

KEY REQUIREMENTS

B.S. or M.S. in a relevant technical field (Operations Research, Computer Science, Statistics, Business Analytics, Econometrics, or Mathematics). Overall experience of 8+ years preferred & 4+yrs exp in data science
Preferred experience in ‘digital native’ company applying advanced analytics with clear vision for applying previous experience in consumer goods
Expert knowledge in statistics (Regression, Clustering, Random Forrest, Decision Trees, Optimization, Time Series, Probability, and other related advanced methodologies)
Experienced knowledge working with large data sets, experience working with distributed computing tools a plus (Map/Reduce, Hadoop, Hive)
Experienced knowledge working in Microsoft Azure and applying Cortana to develop scaled analytic models in the cloud & Experienced knowledge with relational and columnar databases – SQL is a plus",3.9,"Unilever
3.9",Bengaluru,"London, United Kingdom",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Nestlé, Johnson & Johnson","Unilever
",0,148,0,0,0,0
Principal Software Engineering - Data Science,"Job Description:


Job TitlePrincipal - Data Science (Data Scientist)

The Purpose of This Role

The Artificial Intelligence Chapter delivers both internal use cases, digital tools and customer facing applications by leveraging a diverse set of data sources. We employ a full spectrum of data science techniques - statistical models, predictive models from machine learning, and topic modeling from natural language processing are all part of the mix. You will work on data science projects at the intersection of machine learning and financial services, with data engineers, software developers, and other data scientists. You will work on all phases of projects, from initial design to the final coding updates to put into production.

The Value You Deliver
Leading & building data science applications from inception to installation for various FMR business units
Supporting existing Analytics, Research & Data interdisciplinary teams, whose members will be data scientists, software developers, and data engineers
Designing and build machine learning models in latest frameworks and algorithms
Communicating project updates & value created through work to both technical and business stakeholders
The Skills that are Key to this role

Technical / Behavioral
You are knowledgeable about machine learning and statistics
Expert in handling various data types and structures: structured, unstructured, voice, static versus streaming data. Extensive prior experience in integrating data
Possess extensive knowledge of and experience in applying data mining and machine learning, deep learning and Reinforcement learning techniques
Expertise in Natural Language Processing (NLP) and Natural Language Understanding (NLU) techniques
You are fluent in Python and SQL with an ability to design, train, and code up machine learning and statistical models (experience with big data platforms such as Snowflake, Spark, and Hive is a big plus)
You know how to work well in a team to deliver on both business and technical requirements
The Skills that are Good to Have for this role
Experience in working with any AI/NLP for building chatbots with any one of the technologies (JavaScript, Node.js or Python).
You have excellent technical communication skills, with an ability to give compelling presentations
How Your Work Impacts the Organization

Analytics, Research & Data delivers business analytics, financial research & data capabilities to various business units with Fidelity. We use data and analytics to personalize incredible customer experiences and develop solutions that help our customers live the lives they want. As part of our digital transformation, we have significant investments to create innovative big data capabilities and platforms. One of them is to build various enterprise data lakes by gathering data across Business Units.

The Expertise Were Looking For
10+ years of hands-on experience in Data Science, Machine Learning/AI use cases
Graduate / Post Graduate degree with focus on Mathematics, Statistics & Programming
5+ years of hands-on Python, SQL programming experience
Location : Bangalore - Manyata/EGL

Shift timings: 11:30 am - 7:30 pm

Certifications:
Category:
Information Technology",4.0,"Fidelity Investments
4.0",Bengaluru,"Boston, MA",10000+ employees,1946,Company - Private,Investment Banking & Asset Management,Finance,₹500+ billion (INR),"Charles Schwab, Vanguard, Citi","Fidelity Investments
",0,74,1,1,0,1
"Data Scientist , Apple Care Online Support","Summary
Posted: Feb 24, 2020
Role Number:200131127
The people here at Apple don’t just build products — they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it.

Imagine what you could do here.

The AppleCare Digital team is looking for an outstanding data scientist who is interested in designing, developing and identifying data mining solutions that have direct and measurable impact to AppleCare’s support operations.

AppleCare has a tremendous amount of data, and we have just begun the exploration of data in the areas of NLP, pattern detection, predictive modelling and optimization. The person in this position will work with various Online business managers to help identify viable analytical opportunities and then implement an end to end analytical solution. The role requires both a broad knowledge of existing data mining algorithms and creativity to invent and customize when necessary.

The job is located in Bangalore, India
Key Qualifications
Hands-on experience in algorithms like Linear/Logistic, SVM, Random Forest, K-means, K-Nearest neighbour (KNN), PCA, Naive Bayes, apriori etc.
Exposure to deep learning algorithms like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTMs), Stacked Auto-Encoders etc.
Expertise in NLP concepts like Text wrangling & pre-processing, parts of speech tagging, NER and supervised & unsupervised models for Text data
Knowledge of SQL and strong programming skills in Python or R is a must
Excellent interpersonal, written, and verbal communication skills
Ability and comfort working independently and making key decisions on projects
Description
Analyze large datasets to glean actionable insights
Focusing on solving concrete customer and business problems at scale
Design classifiers and ranking algorithms
Perform ad-hoc statistical analysis
Present results of analysis to team and leadership across Apple
Create metrics to measure the success of the service
Education & Experience
Ph.D. in Data Science, Machine Learning, Statistics, Operations Research or related field or B.Tech/M.Tech/M.S. in related field with 5+ years experience applying data science techniques to real business problems.",4.7,"Apple
4.7",Bengaluru,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,₹500+ billion (INR),"Google, Microsoft, Samsung Electronics","Apple
",0,44,1,0,0,1
Data Scientist,"Data Scientist ( > 4 years experience ) :
Should be highly skilled in using deep learning algorithms and have expertise on tweaking them for Dunzo specific problem statement
Should be able to program in python. Should be highly skilled in this.
Should have experience in formulating problem statement and decide what data can help in solving the problem.
Should have overall idea on how to put machine learning models into production. Although there is no need to work on this directly, it is important to guide data engineering and backend team for getting desired results
Should be able to communicate with business and other stakeholders for understanding problems for producing possible solutions. Should give demos for proof of concepts(poc)
Should be interested in learning about advancements in deep learning field and going through research papers and latest updates of the field.
Should have skills in using pandas,numpy, scipy, sklearn, spacy, nltk, keras/pytorch/tensorflow and familiar in using gpu machines for training purpose
Should have an attitude of owning the problem and generating industry standard solutions and ultimately reach to state of the art solutions to the problems.
It will be really great if presenting at tech conferences is one of the interests. Also, we encourage you to write on tech blog. This part is optional",3.1,"Dunzo
3.1",Bengaluru,"Bengaluru, India",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Dunzo
",1,-1,1,0,0,0
Staff Engineer - Frontend,"Qubole is a simple, open, and secure Data Lake Platform for machine learning, streaming, and ad-hoc analytics. Our platform provides end-to-end services that reduce the time and effort required to run Data pipelines, Streaming Analytics, and Machine Learning workloads on any cloud. No other platform offers the openness and data workload flexibility of Qubole while lowering cloud data lake costs by over 50 per cent. Qubole customers process nearly an exabyte of data every month. Qubole investors include Charles River, Institutional Venture Partners, Lightspeed, Norwest, Harmony and Singtel Innov8.

UI engineers in Qubole are responsible for the rich web application hosted at api.qubole.com. We build user interfaces that cater to a wide variety of personas such as Data Analysts, ETL Engineers, and Data Scientists. We are looking for engineers to craft the next generation of Qubole’s user interface.
Some examples of work that UI engineers have done:
An IDE like interface for composing and analyzing big data queries.
Interfaces for exploring object stores and large datasets.
Support for multiple clouds such as Microsoft Azure, Google Compute Cloud etc.
Cluster management UI to create and manage big data clusters.
Reports and dashboards for monitoring performance of commands, clusters etc.… and many more

Primary Responsibilities:

Interact with UX designers and PMs to iterate and develop the product.
Use efficient abstractions and good programming practices to write testable, reusable and maintainable code.
Participate in design and code reviews.
Willingness to deep-dive across various levels of the stack to debug/understand/solve issues.
Interact with support engineers to identify customer pain points and address them.

Additional Responsibilities:

Make sound architectural choices when designing large applications across the whole stack (frontend, and middleware - including database).
Be a promoter of best practices while coding, and reviewing other’s code.
Be a strong mentor to juniors and help develop them while being hands-on.
Drive projects from initial requirements to rolling them out.

Requirements:

Strong grasp of JavaScript, HTML, and CSS fundamentals.Familiarity with building MVC applications.
Knowledge of RoR a plus.Knowledge of client side frameworks such as Ember, React.js is a plus.
Ability to write clean, modular, unit testable, and maintainable code.
Awareness of performance, web security, and cross-browser compatibility issues.
Attention to detail in UX.Hands-on experience in project estimation and planning.
Qubole is hitting that growth inflection point where we need talented people to help us scale up. Our company culture is special, and we are looking for people to join us who want to continue building a great company while going after the big data activation market.
Check us out on Glassdoor and LinkedIn
Learn more about us here, here, and here

Culture at Qubole
Trust and Autonomy: We absolutely pride ourselves on the lack of bureaucracy at work, and believe in delegating power and responsibility, aggressively to our employees.
Transparency and Teamwork: Complete transparency in all our thoughts and actions is integral to our genetic character, and it helps us to stick together and function effectively as a team.
Who Thrives: If you are a self-starter and thrive on complexity and independence and truly understand and live the tenets of humility, hunger and honesty and you will love Qubole.

Qubole is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Qubole does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Qubole also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.",4.5,"Qubole
4.5",Bengaluru,"Santa Clara, CA",201 to 500 employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,"Qubole
",0,9,0,0,1,0
Lead Data Scientist,"How will you create an impact within Flutura?

You will play a strategic role in helping us to continuously improve our products and business decisions with your strong problem-solving ability and knack for statistical analysis.

You will be challenged to

· Implement methodologies to standardize end to end data science project life cycle

· Implement state of the art data mining algorithms in production environment

· Building an End to End Data Science Framework designed to handle large volume data sets

· Lead Data Exploration and Statistical Inferences on datasets, Storytelling to communicate insights and findings in a simplified way

· Effective multitasking and delivery on time with quality

· Provide timely communications on significant issues or developments

· Evangelize new product features

· Manage a team of data scientists, machine learning engineers and big data specialists

· Work with cross functional teams for assessing data science use cases and product market fitment

The core competency you should possess

Technical/Functional Skills:

· Minimum 8 years of total experience with recent & relevant experience of at least 4 years as a data scientist

· Should have managed a team directly atleast for 2 years

· Solid understanding of Statistics, Machine Learning, Deep Learning and Artificial Intelligence Technologies

· Hands On experience in Python, R, Pyspark and equivalent programming languages

· Expertise in building, productionizing and scaling analytics solutions for big data problems

· Experience in building and scaling models for time series (such as sensors etc.) data is a priority

· Experience with SQL and NoSQL databases

· Familiarity with agile execution of data science projects

Desired Characteristics:
Strong oral and written communication skills
Strong interpersonal and leadership skills
Ability to influence others and lead small teams
Lead initiatives of moderate scope and impact
Ability to coordinate several projects simultaneously
Effective problem identification and solution skills
Proven analytical and organizational ability
Education:
Qualification: BE/B.Tech, ME/M.Tech, MS, MCA (with an aggregate of 75% and above)
Stream (Preferable): Computer Science, Data Science, Mathematics or similar field
Job Type: Full-time

Salary: ₹1,800,000.00 to ₹2,200,000.00 /year

Experience:
Tead Lead: 2 years (Required)
Work Remotely:
Temporarily due to COVID-19",3.7,"Flutura Decision Sciences & Analytics
3.7",Bengaluru,"Bengaluru, India",51 to 200 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹100 to ₹500 million (INR),"Mu Sigma, Analytics Quotient, PTC","Flutura Decision Sciences & Analytics
",1,8,1,1,0,0
Data Scientist - PhD,"Company Description

About Affine

Affine is a Data Sciences & AI services provider, offering capabilities across the analytical value chain from data engineering to analytical modelling and business intelligence to solve strategic & day to day business challenges of organizations worldwide. They empower their clients to make informed decisions & to take proactive actions through impeccable technology-based development & business acumen.

They develop solutions for multiple verticals such as Retail, CPG, E-commerce, High-Technology, BFSI, Media & Entertainment, Manufacturing among others and are respected as one of the Marquee names in the “Consultancies for Transformation” space.

Affine is headquartered in Bengaluru, India with other offices in New York & Seattle, United States and Singapore.

Job Description

Experience: 0 – 4 years
Education requirement: PhD in Machine Learning/Deep Learning/Artificial Intelligence/Image
processing/Statistics/Computer Science/ Mathematics

Responsibilities
• Utilizing artificial intelligence and machine learning concepts to solve challenging business problems
• Work on problems from various domains like NLP, Recommendation engine, computer vision
• Should participate in complete project cycle i.e. understanding a problem statement, data gathering,
analyzing data, implementing ML/AI solutions
• Should be able to learn new tools/languages quickly and continue expanding knowledge on latest
advances in ML/AI
• Managing project timing, client expectations and meeting deadlines
• Publishing research articles, papers and blogs

Desired skills and experience:
•Strong experience in machine learning/artificial intelligence in academics or academics plus
industry
• Expert level in at least one programming language. Preferably R or Python
• Knowledge of statistics and machine learning (Probability theory, parametric and non-parametric
models, supervised and unsupervised ML techniques, etc.)
• Knowledge of deep learning algorithms (CNN, RNN, autoencoders, etc.)
• Knowledge in databases preferable",3.8,"Affine Analytics
3.8",Bengaluru,"Bengaluru, India",201 to 500 employees,2011,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1,"Affine Analytics
",1,9,1,0,0,0
Associate Data Scientist - MFG,"Noodle's Data Scientists build advanced AI models that change the way our clients do business by empowering them to make better decisions. Our solutions impact small and large businesses ranging from media, to retail companies, to airlines, to e-commerce, financial services, to government agencies. Members of our Data Science team are passionate about problem solving with applied data science and work with clients to explore, specify, and communicate high-value, AI- based solutions. We geek out about AI technology.

As a Data Scientist at Noodle.ai, you will collaborate with the Noodle Client Service team, Data Engineers, SW Engineers, UX Designers, and industry-specific experts from our client companies to build a deep understanding of our clients' business context and then develop, test, and deploy advanced AI models. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the models, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Qualifications:
Must haves

1+ years of experience in applied artificial intelligence technologies including machine learning, predictive data analytics, and/or data science

BE/B.Tech or Advanced degree in a relevant field ( Computer Science, Operations Research, Statistics, Mathematics, Electrical Engineering, or other Computational Science )

Proficient in python

Experience with spark

Knowledge of data science/machine learning concepts

Demonstrated ability to iteratively conceptualize, design and build data-driven analytical models

Strong capabilities in modern analytics languages/tools

Collaborative, open, and respectful working style

Passion for learning and a desire to grow – Noodlers are life-long learners!

Nice to haves

Experience applying advanced AI techniques ( g., machine learning, predictive analytics. optimization, semantic analysis, time-series analysis, advanced visualization ) to real-world problems

Experience with R

Experience manipulating and preparing large, heterogeneous data sets (""Big Data"") to support advanced analytics

Demonstrated energy and passion that extends beyond your field of study – Are you a computer scientist who writes poetry? A mathematician who loves psychology? An engineer passionate about public policy? We want to build something with

Experience with (and excitement for) interdisciplinary collaboration",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1,"Noodle.ai
",0,4,1,1,0,0
Data Scientist,"Data Scientist Bangalore As a fully functioning analytics team member, applies best practices to analytics solutions and contributes to the development of improved best practices. Below are the MUST HAVES: • Experience as Data Scientist - Fortune 100 Clients - Prefer Product Base. • Data analysis experience working with large-scale data. • Strong experience using Python & SQL for analysis, modeling, and data visualization.
Advanced statistics, data mining and modeling knowledge. Requirements: • Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration. • Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework. • Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products",3.3,"Calsoft Labs
3.3",Bengaluru,"Bengaluru, India",1001 to 5000 employees,1992,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Mindtree, Happiest Minds Technologies, Altran Americas","Calsoft Labs
",1,28,1,0,0,0
Senior Data Scientist,"Role Summary:
We are looking for a highly motivated individual, passionate about technology to join Baker Hughes Digital team. As the Senior Data Scientist, in Baker Hughes Digital, you will focus on developing impactful and innovative analytics products for the O&G industry. The candidate will be responsible for designing analytics for products and solutions, leverage strong machine learning expertise to develop new analytics for driving growth in asset, application & industry coverage and lead engagements with external/internal customers. The candidate is also expected to mentor other engineers in analytics methods.

Essential Responsibilities:
Work in cross-functional teams to translate algorithms into commercially viable products and services.
Contribute to technical teams in development, deployment and application of applied analytics, predictive analytics and prescriptive analytics capabilities.
Develop self-learning systems that can predict failures and autocorrect based on multiple data sources
Work with the engineering team to incorporate your analyses and solutions, including working with the visualization team to create intuitive UI and rich UX stories. Partner with data engineers on data quality assessment, data cleansing and data analytics efforts
Gather and analyze data, devise innovative data science solutions and build prototypes to enable development of high-performance algorithms in scalable, product-ready code.
Initiate and propose unique and promising modeling features, develop new and innovative algorithms and technologies, pursuing patents where appropriate
Stay current on published state-of-the-art algorithms and competing technologies.
Contribute to the development of software and data delivery platforms that are service-oriented with reusable components across teams (multiple teams) that can be orchestrated together into different methods for different businesses.
Research and evaluate emerging technology, industry and market trends to assist in project development and/or operational support activities to for multiple teams or complex scenarios.

Qualifications/Requirements:
MS Degree in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
A minimum of 2 years as data scientist
A minimum of 3 years of technical hands-on coding experience

Eligibility Requirements:
Legal authorization to work in India. We will not sponsor individuals for employment visas, now or in the future, for this job
Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen
Must be willing to travel

Desired Characteristics:
PhD in Computer Science or in “STEM” Majors (Science, Technology, Engineering and Math)
Strong distributed systems and architecture knowledge, and experience with multitier architecture
Mission critical systems experience is preferred
Ability to manage complex technical projects.
Demonstrates expertise in problem solving and technical innovation.
Demonstrated experience of delivering on commitments to clients.
Demonstrates capability of 'rolling up sleeves and getting hands dirty'.
Works well in fast paced growing environment.
Provides excellent influential communication skills and business acumen to both an arbitrator and advocate for technical issues.
Experience developing applications in an agile/DevOps environment would be a distinct advantage
Solid understanding of software development tools & infrastructure

Effective teaming and problem-solving abilities

Strong interpersonal and leadership skills
Able to interface effectively with all levels of the organization and external customers

Technical Expertise:
Proven experience coding in Machine Learning/AI techniques including Deep learning techniques (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian modeling, time series modeling
Demonstrated experience in Parallel programming frameworks for GPUs, TPUs
Demonstrated ability to develop containerized solutions (Docker/Mesos etc)
Strong implementation experience with high-level languages and frameworks such as R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS
Demonstrated ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc…
Strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data including SQL and NoSQL databases
Experience with end-to-end modeling projects, from research to solutions to analytic products
Proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.
Participates in enterprise strategy development, including environmental analysis, opportunity identification, value cases and business innovation portfolio development. Reviews and/or analyzes and develops architectural requirements at domain level, aligning architectural requirements with software development strategy.
Leads and facilitates the domain’s architecture governance process based on EA’s governance structure.
Leads teams in developing plans and assessing improvement options.

Business Acumen:
Create, analyze and manage projects that provide direct business benefit; demonstrate detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities
Understand industry trends and competitive landscape and the implications for your business
Partner with business leaders to align projects with business goals and needs.

Leadership:
Recommends allocation of budget to meet architectural initiatives critical to business/mission success.
Develops the business case for approval.
Provides leadership, technology guidance and mentors others throughout their domain.
Define the skills, competencies in the skills and talents for architecture team members.
Facilitates dialogues that produce new perspectives and trigger recommendations for substantial innovative / enhancements, and analysis of consequences.
Influences through others.
Uses experts or other third parties to influence.
Builds direct and ""behind the scenes"" support for ideas, uses chains of indirect influence.

Personal Attributes:
Challenges conventional thinking and traditional ways of operating and invites stakeholders to identify issues and opportunities.
Takes a holistic systems perspective.
Envisions, compares and contrasts multiple potential long-range enterprise-wide futures.
Empathizes with multiple points of view

Locations:
Bangalore, India",3.6,"Baker Hughes
3.6",Bengaluru,"Houston, TX",10000+ employees,-1,Company - Public,Oil & Gas Services,"Oil, Gas, Energy & Utilities",₹500+ billion (INR),-1,"Baker Hughes
",0,-1,1,1,0,1
Junior Data Scientist,"Junior Data Scientist
Job Description


The ITS Data Scientist is responsible for integrating business, information, and technology into analytical models that help drive business performance and competitive advantage and providing the business with answers to questions. The role collaborates with Business, IT Functional Engineers and Platform architects to create value from varied data sources. Creating value from data requires a range of talents: from data integration and preparation, to architecting specialized computing/database environments, to data mining and intelligent algorithm development.

Hiring Requirements

Job Details

Development of analytics to help drive competitive advantage from data with accountabilities across multiple functional and technical areas with wide range of complexity. The Data Scientist must understand medium/complex data types (integrate, manipulate, prepare), know advanced analytics (appropriate techniques, interpret data and diagnose models, meet business requirements), and focus on the business outcomes (goals, constraints, decisions while communicating outcomes via presentations). Develop models and algorithms that drive innovation throughout the organization. This may include marketing, supply chain, inventory planning and deployment, network planning, order routing, and order fulfillment and delivery Conduct advanced statistical analysis to provide actionable insights, identify trends, and measure performance Build learning systems that monitor data flows and react to changes in customer preferences, network constraints, and business objectives Collaborate with engineers to implement and deploy scalable solutions Provide thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders Partners as a bridge between the business and the information management teams to make sure that the solution fits within the data management principals Coordinates data science implementations while leading design variances based upon business needs while ensuring artifacts and repositories are documented Manages engagements with vendors as they relate to evaluation, design and delivery of business capabilities Contributes to the evaluation and selection of software product standards Leader in industry representation, policy formation, User Groups, and strategic direction

Mentors others to complete Continuous Improvement (CI) initiatives; consults and shares knowledge across org; awareness of industry trends.

Education required/ preferred:
MS/PhD in computer science, statistics, or operations research or related technical discipline.
Experience:
2-3+ years of continuous experience in software engineering, software development, solution architecture
Knowledge of machine learning, statistics, optimization or related field
Experience with R, Python, Matlab is required
Experience building machine learning application in areas like time series forecasting, classification models, clustering models, multivariate regression models etc
Experience in Microsoft Azure Stack in the Cloud with focus on Data Factory, Data Bricks, BLOBs, Data Lake Storage, ML Studio, Azure Analysis Services, Azure Data Warehouse, Power BI etc
Experience working with large data sets and distributed computing tools a plus (Map/Reduce, Hadoop, Hive, Spark, Python, R, Gurobi, MySQL, etc.)
Excellent written and verbal communication skills along with strong desire to work in cross functional teams
Consumer products experience in an online and/or retail/manufacturing environment is preferred
Possess strong leadership skills and exhibit creative thinking to be able to come up with inventive solutions to solve business challenges
Provide thought leadership while keeping up with industry trends and disseminating information across the organization
Experience working with blended teams consisting of employees, vendors, and consultants with both onshore and offshore resources
Strong Technical leadership of advanced analytics teams and vendors
Extensive experience collaborating with Enterprise Architects and infrastructure engineers to identify, design, and implement highly complex, end-to-end solutions
Cultivates networking opportunities within the organization
Broad range of business and IT experiences; Has achieved technical and/or business certification(s).
Skills/Competencies:

Communication: Data scientists must communicate effectively up and down the data supply chain: first, to obtain access to the data they require; second, to work with those who understand the business meaning behind the data; and third, to articulate findings and implications to business leaders in language they understand. A data scientist must be able to use data to tell stories. Key components of these communication skills are those of persuasion and expectation management. The ability to insert themselves into core business functions and assert their ideas is therefore critical.

Collaboration: Working directly for business leaders and side-by-side with business unit personnel, they need to shed the introverted statistician stereotype. Increasingly, business professionals require access to analytic techniques beyond basic math and must be able to rely on the data scientist to work closely with them. The data scientist enables the broad consumerization of derivative result sets and analytics (if not the raw data). The data scientist must have the ability to juggle competing priorities and pressures.

Leadership. The role of the data scientist can incorporate data oversight responsibilities including directing the efforts of teams of consultant statisticians, data administration and integration professionals, and data visualization, reporting, and application integration developers.

Creativity. The work of the data scientist is very much an innovation-oriented exercise in solving open-ended conundrums. Data scientists are tasked with finding opportunities to optimize, expand or transform the business through the lens of information. Moreover, data scientists must be creative in sourcing data, modeling problems and employing a range of analytic techniques.

Discipline. Although creativity is critical, data scientists must remember that ""science"" is part of their directive. This means following established scientific methods, employing legitimate techniques, using valid data and embracing causality. Scientific methods demand that questions are well-defined, true data (observations) is collected, and hypotheses are formed, investigative methods are selected, data is analyzed and interpreted with yielding conclusions, and results are formally communicated and tested. Although rigid methodology is recommended, results perfection is not. Business opportunity costs in a fast-paced marketplace are too high to spend excessive time achieving incrementally better analyses. However, a data scientist — just as any good statistician or other analytics professional — must understand the differences between correlation and causality and between incidental and insightful patterns.

Passion: An obsession for information, solving insurmountable problems and finding unique ways to accelerate the business.

Consultancy: Manages provision of specialist knowledge over a range of topics in data science including the role of IT in the business; in own areas of expertise provides advice and guidance influencing the effectiveness of the organization’s business processes.

Data Design: Controls analytics data design practice within the enterprise. Influences industry-based models for the development of new technology applications. Develops effective implementation and procurement strategies, consistent with business needs.

Data Analysis: Sets standards for advanced analytics tool usage and techniques, advises on their application, and ensures compliance. Manages the investigation of corporate data requirements, and co-ordinates the application of data analysis and analytics techniques, based upon a detailed understanding of the corporate information requirements, in order to establish, modify or maintain analytical models and their associated components.

Autonomy: Has authority and responsibility for all aspects of data science, including policy formation and application. Is fully accountable for actions taken and decisions made, both by self and subordinates.

Influence: Makes decisions critical to organizational success. Influences developments within the IT industry at the highest levels. Advances the knowledge and/or exploitation of IT within one or more organizations. Develops long-term strategic relationships with customers, partners, industry leaders and government.

Complexity: Performs highly complex work activities covering technical, financial and quality aspects. Contributes to the formulation and implementation of IT strategy. Creatively applies a wide range of technical and/or management principles.

Business Skills Absorbs complex technical information and communicates effectively at all levels to both technical and non-technical audiences. Assesses and evaluates risk. Understands the implications of new technologies. Demonstrates clear leadership and the ability to influence and persuade. Has a broad understanding of all aspects of IT and deep understanding of own specialism(s). Understands and communicates the role and impact of IT in the employing organization and promotes compliance with relevant legislation. Takes the initiative to keep both own and subordinates' skills up to date and to maintain an awareness of developments in the IT industry.

Global VISA and Relocation Specifications:
K-C requires that an employee have authorization to work in the country in which the role is based. In the event an applicant does not have current work authorization, K-C will determine, in its sole discretion, whether to sponsor an individual for work authorization. However, based on immigration requirements, not all roles are suitable for sponsorship.
This role is available for local candidates already authorized to work in the role’s country only. K-C will not provide relocation support for this role.
Primary Location
IT Centre Bengaluru GDTC
Additional Locations
Worker Type
Employee
Worker Sub-Type
Regular
Time Type
Full time",3.9,"Kimberly-Clark
3.9",Bengaluru,"Irving, TX",10000+ employees,1872,Company - Public,Consumer Products Manufacturing,Manufacturing,₹500+ billion (INR),"Procter & Gamble, Georgia-Pacific, Unilever","Kimberly-Clark
",0,148,1,1,0,1
Principal Data Scientist - BLR,"As a Data Scientist at Noodle.ai, you will collaborate with our Enterprise Services team,Software Engineers, Designers, and industry-specific experts from our customers. You willvbuild a deep understanding of the business problems our customers are tackling and then develop, test, and deploy advanced machine learning algorithms. As we grow, you will also develop reusable IP to help us move faster, dive deeper, and work more efficiently by generalizing the algorithms, methodologies, and supporting infrastructure that you build. As one of the early hires to join the Noodle.ai team, you will have a significant impact on the future of Enterprise Artificial Intelligence.

Job responsibilities:
Implement a breadth of different modeling approaches/ techniques in machine learning

Manipulate and prepare large, heterogeneous data sets to support advanced analytics

Iteratively conceptualize, design and build data-driven analytical models

Develop processes and tools to monitor and analyze model performance and data accuracy

Translate deep mathematical concepts and practices into language that non-experts can understand and build upon. And conversely, translate business needs and user needs into language and concepts that other data scientists can understand and work with.

Productionalizing machine learning code and interfacing with industry standardmsoftware systems

Understand and manipulate unstructured data from different platforms.

Demonstrate proficiency at real-world modeling problems/DS problems - getting to a result that demonstrably generate business value

Qualifications:Required:
Graduate degree in a relevant field (Computer Science, Operations Research, Statistics, Applied Math...) or Bachelors degree and 2-4 years applying advanced AI techniques to real-world problems

Good to have:
7+years of experience applying advanced AI techniques to real-world problems

Experience tackling data science problems characterized as high-dimension, low sample size (i.e., lots of potentially predictive features and highly diverse but low quality or highly sparse data.)

Knowledge & understanding of a functional area of focus (i.e. Experience applying advanced analytics to supply chain optimization, demand forecasting, and/or revenue management)

Knowledge & understanding of an industry area of focus (i.e. retail, manufacturing,CPG, 3PL, travel...)

Skills and Competencies:
Experience with common analysis tools (SQL, R, and Python).

Demonstrable familiarity with code and programming concepts.

Knowledge of Spark and/or Hadoop

Knowledge of machine learning areas and techniques - Supervised machine learning,Unsupervised machine learning, Time series, Natural language processing, Outlier detection, Computer vision, Recommendation engines, Survival analysis,
Reinforcement learning, and Adversarial learning

Knowledge of data visualization tools - ggplot, d3.js and Matplottlib, and Tableau

Strong problem solving skills with an emphasis on product development

Focus on delivering value and building lasting relationships through collaboration in an open and respectful working style

Passion for learning and a desire to grow",4.5,"Noodle.ai
4.5",Bengaluru,"San Francisco, CA",201 to 500 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,₹1 to ₹5 billion (INR),-1,"Noodle.ai
",0,4,1,1,0,0
"Lead Data Engineer, Enterprise Data","Ref #:
5575702

Department:
Information Technology

City:
Bangalore

State/Province:
Bangalore

Country:
India

Company Description
Ralph Lauren Corporation (NYSE:RL) is a global leader in the design, marketing and distribution of premium lifestyle products in five categories: apparel, accessories, home, fragrances, and hospitality. For more than 50 years, Ralph Lauren's reputation and distinctive image have been consistently developed across an expanding number of products, brands and international markets. The Company's brand names, which include Ralph Lauren, Ralph Lauren Collection, Ralph Lauren Purple Label, Polo Ralph Lauren, Double RL, Lauren Ralph Lauren, Polo Ralph Lauren Children, Chaps, and Club Monaco, among others, constitute one of the world's most widely recognized families of consumer brands.

Position Overview
The Lead Data Engineer is an emerging role in Ralph Lauren’s Analytics team, and will play a pivotal role in operationalizing the most critical data and analytics initiatives for Ralph Lauren’s digital business initiatives.

Purpose & Scope

Based in Bengaluru, India this Sr Data Engineer will work with the Global Analytics team to build, maintain, and optimize data pipelines for key data and analytics consumers including business and data analysts and data scientists covering our digital and physical channels and value chain. Data engineers also need to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for Ralph Lauren’s data and analytics initiatives. The data engineer will be measured on their ability to integrate analytics and (or) data science results with Ralph Lauren’s business processes.
This role will require both creative and collaborative working with IT and the wider business. It will involve evangelizing effective data management practices and promoting better understanding of data and analytics. The data engineer will also be tasked with working with key business stakeholders, IT experts and subject-matter experts to plan and deliver optimal enterprise data assets.

Essential Duties & Responsibilities
Build data pipelines: The primary responsibility of data engineers is to architect, build, and maintain data pipelines that will provision high quality data ready for analysis. This includes ingestion, exploration, modeling, and curation of high value data.

Lead and Mentor Data Engineers: The lead data engineer will be responsible for leading and developing a team of data engineers focused on the growth in the team’s skills and ability to execute as a team using DevOps and DataOps principles.

Drive Automation through effective metadata management: The data engineer will be responsible for using innovative and modern tools, techniques and architectures to partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity.
Learning and using modern data preparation, integration and AI-enabled metadata management tools and techniques.
Tracking data consumption patterns.
Performing intelligent sampling and caching.
Monitoring schema changes.
Recommending — or sometimes even automating — existing and future integration flows.
Collaborate across departments: The newly hired data engineer will need strong collaboration skills in order to work with varied stakeholders within the organization. In particular, the data engineer will work in close relationship with data analysts and business analysts in refining their data requirements for various data and analytics initiatives and their data consumption requirements.

Educate and train: The data engineer should be curious and knowledgeable about new data initiatives and how to address them. This includes applying their data and/or domain understanding in addressing new data requirements. They will also be responsible for proposing appropriate (and innovative) data ingestion, preparation, integration and operationalization techniques in optimally addressing these data requirements. The data engineer will be required to train counterparts such as data scientists, data analysts, LOB users or any data consumers in these data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their own use cases.

Participate in ensuring compliance and governance during data use: It will be the responsibility of the data engineer to ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives. Data engineers should work with data governance teams (and information stewards within these teams) and participate in vetting and promoting content created in the business and by data scientists to the curated data catalog for governed reuse.

Become a data and analytics evangelist: The data engineer will be considered a blend of data and analytics “evangelist,” “data guru” and “fixer.” This role will promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals.

Experience, Skills & Knowledge
Education and Experience
A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field is required.
An advanced degree in computer science (MS), statistics, applied mathematics (Ph.D.), information science (MIS), data management, information systems, information science (postgraduation diploma or related) or a related quantitative field is preferred.
The ideal candidate will have a combination of IT skills, data governance skills, analytics skills and Retail industry knowledge with a technical or computer science degree.
At least 8 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.
At least 3 years of experience working in cross-functional teams and collaborating with business stakeholders in Retail in support of a departmental and/or multi-departmental data management and analytics initiative.
Deep Retail Industry knowledge or previous experience working in the business would be a plus.
Technical Knowledge/Skills
Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Scala, or similar.
Strong ability to design, build and manage data pipelines in PySpark and related technologies for data structures encompassing data transformation, data models, schemas, metadata and workload management. The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows.
Strong experience with popular database programming in relational and nonrelational environments including on AWS Redshift, AWS Aurora, SQL Server and similar platforms.
Strong experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement and upcoming data ingestion and integration technologies such as stream data integration and data virtualization.
Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production.
Strong experience in working with both open-source and commercial message queuing technologies such as Kafka, Amazon Simple queuing Service, stream data integration technologies such as Apache Nifi, Apache Kafka Streams, Amazon Kinesis and stream analytics technologies such as Apache Kafka KSQL.
Basic experience working with popular data discovery, analytics and BI software tools like MicroStrategy, Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.
Strong experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms.
Basic understanding of popular open-source and commercial data science platforms such as Python, R, KNIME, Alteryx, others are a strong plus but not required/compulsory.
Basic experience in working with data governance, data quality, and data security teams and specifically and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others.
Experienced in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization
Interpersonal Skills and Characteristics
Strong experience supporting and working with cross-functional teams in a dynamic business environment.
Required to be highly creative and collaborative. An ideal candidate would be expected to collaborate with both the business and IT teams to define the business problem, refine the requirements, and design and develop data deliverables accordingly. The successful candidate will also be required to have regular discussions with data consumers on optimally refining the data pipelines developed in nonproduction environments and deploying them in production.
Required to have the accessibility and ability to interface with, and gain the respect of, stakeholders at all levels and roles within the company.
Is a confident, energetic self-starter, with strong interpersonal skills.
Has good judgment, a sense of urgency and has demonstrated commitment to high standards of ethics, regulatory compliance, customer service and business integrity.
#LI-AD1

Lead Data Engineer, Enterprise Data",3.5,"Ralph Lauren
3.5",Bengaluru,"New York, NY",10000+ employees,1967,Company - Public,Other Retail Shops,Retail,₹500+ billion (INR),-1,"Ralph Lauren
",0,53,1,1,1,0
Data Scientist Intern,"Location: Bangalore, India.

Dasceq: Data – Science – Equilibrium
Transforming Collections with AI/ML and Big Data
In the digital age, businesses have access to more data than ever before, and this data can be leveraged to drive decision-making for improved growth and seamless consumer experience including collections. Since being founded in 2017, our team of data scientists and domain experts at Dasceq (Data – Science – Equilibrium) have created a AI platform to boost collections efficiency and amount collected. We are leading edge AI Startup converging Machine learning, AI with deep collection and servicing experience leveraging AI/ML and Big Data to create a unique platform for Collections. Our next generation product is enabling clients to improve consumer experience and ROI. Dasceq’s next-gen SaaS AI platform optimizes collections with data-driven insights.

We experiment and innovate leveraging the latest technologies to engineer breakthrough AI product, customer experiences, and bring simplicity and humanity to collections. At Dasceq Center for Artificial Intelligence and Innovation, you’ll be part of an elite team accelerating adoption of AI, ML and Big Data for Fortune enterprises in USA.

Do you have it in you to join Dasceq? We are a committed and passionate team of hard working individuals who are making a difference for our clients, our industry and our team members. We are looking for passionate individuals who are great performers and willing to be part of team passionate about building production-quality applications using cutting-edge machine learning algorithms? They must be Self Starter, Hard Workers, Great Team Spirit and a willing to become experts in their domain? If the answer is YES then APPLY

We are looking for a Data Scientist who will work in our AI/Data Science Innovation Team and will leverage data to gain insights by analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.
They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations.
They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.
Responsibilities for Data Scientist:
Data mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications for Data Scientist
Has a bachelor’s degree in Computer Science, Economics, Statistics or another quantitative field, and is familiar with data science algorithms.
Strong problem-solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets and experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone of experience manipulating data sets and building statistical models, has a master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several language C++, python, R, SQL.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc.
Experience visualizing/presenting data for stakeholders using: BI tools.
Only those candidates can apply who for internship:
Have a great attitude, willing to learn and work hard and excel in career.
Are available for full time (in-office) internship at our Jaynagar Office in Bengaluru
can start the internship between 1st March19 and 15th Mar’19
are available for duration of 6 months
have relevant skills and interests
Other requirements:
Should have an ability to work in a team with good communication skills
Should have the ability to meet routine production deadlines
Should be well versed with computer concepts of the internet, networking, browser, website, apps, MS Office, etc.
Should have basic knowledge of Excel, Word, Presentation, Google Sheets, and Google Docs
Should have a strong attitude to learn and logical reasoning
Open to work long hours and weekend as needed (one to two weekend a month).
Perks:
Certificate
Letter of recommendation
Job offer (On successful conversion to a permanent employee, the candidate can expect a salary of Rs. 2 to 3 Lac/annum)
Daily Lunch and Snacks Provided
Bi-Weekly Team Events and Office Party.

Required for Interview:
Current and past jobs pay slip and appointment letter (pdf)
All diploma and certificate copies (pdf)
Three References
* Women willing to start/restart their career can also apply",2.0,"Dasceq
2.0",Bengaluru,"Irving, TX",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,"Dasceq
",0,-1,1,0,0,1
Lead Data Scientist,"Position Description

This position is in the data science team under the Advertising Technology organization. The mission of the Advertising Technology organization is to advance Walmart eCommerce by driving higher value for our customers and vendor partners. Walmart is investing in building a world class advertising platform and the Ads team is responsible for defining and performance advertising products that drive discovery, sales and profits.

We are a highly motivated group of Big Data Geeks, Data Scientists and Applications Engineers, working in small agile group to solve sophisticated and high impact problems. We are building smart data systems that ingest, model and analyse massive flow of data from online and offline user activity. We use cutting edge machine learning, data mining and optimization algorithms on ad relevance, ranking and campaign optimization.

The senior data scientist of ad targeting will be leading a team of data scientists and machine learning engineers to build the next generation ad targeting and scoring solution. Join us if you want to be spending your time on:

• Working with product and other business stakeholders to define our roadmap to drive advertiser value and enhance customer experience;

• Leading a team of data scientists and machine learning engineers to develop, implement, and test scalable solutions for improving ad targeting; interacting with other teams to define interfaces and resolving dependencies;

• Researching and implementing methodologies to measure the impact of the technologies;

• Initiating and proposing unique and promising modelling projects, developing new and innovative algorithms and technologies, pursuing patents where appropriate;

• Staying current on published data mining, machine learning and modelling techniques and competing technologies and sharing these findings with scientists and engineers in the organization;

• Maintaining world-class academic credentials through publications, presentations, external collaborations and service to the research community.

Minimum Qualifications

Bachelors or equivalent degree in a computational science with 10+ years OR Masters or equivalent degree in a computational science with 6+ years of experience in Machine Learning/Statistics/Data Science;

Experience with traditional as well as modern machine learning/statistical techniques, including Regression, Classification, Ensemble Methods, Deep Learning and Reinforcement Learning;

Strong implementation experience with high-level languages, such as Python, R, Scala or similar scripting language, and familiarity with Linux/Unix/Shell environments;

Strong hands-on skills in sourcing, cleaning, manipulating and analysing large volumes of data using distributed computing platform;

2+ years of experience mentoring junior data scientists;

Strong written and oral communication skills.

Preferred Qualifications

Ph.D. in a computational science with an emphasis in Machine Learning;

Experience in online advertising, recommender system, ecommerce or relevant areas;

Experience with end-to-end modelling projects emerging from research efforts;

Excellent academic or industrial track record of proposing, conducting and reporting results of original research, plus collaborative research with publications;

2+ years of experience managing a data science/modelling team.",3.3,"Walmart
3.3",Bengaluru,"Bentonville, AR",1001 to 5000 employees,1962,Company - Public,"Department, Clothing, & Shoe Shops",Retail,₹500+ billion (INR),"Target, Costco Wholesale, Amazon","Walmart
",0,58,1,0,0,1
Data Scientist Intern,"Pursuing Masters or equivalent advanced degree from a top tier Technology school
Record of delivering large analytical solutions with business impact
Experience on R/SAS/Matlab and SQL
Excellent Microsoft Office skills, including a strong working knowledge of Excel
Problem solving ability and passion for big data
Excellent communication and data presentation skills
Fluent written and spoken English
Amazon's looking for Data Scientist to optimize one of the most complex logistics systems in the world. Academic and/or practical background in Computer Science, Engineering, Operations Research, or Process Control are particularly relevant for this position. Experience in the integration of model-based engineering tools and/or multidisciplinary analysis & optimization is also a plus.

Major Responsibilities:
Use data analyses and statistical techniques to develop solutions to improve customer experience and to guide business decision making
Identify predictors and causes of business related problems and implement novel approaches related to forecasting and prediction
Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations
Collaborate with multiple teams as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity
Analyze and solve business problems at their root
Masters or equivalent advanced degree in Computer Science, Computer Engineering, Statistics, Mathematics or related technical discipline. Hands-on experience and project based learning in computer science, engineering or mathematics is preferred.
Academic experience in manipulating/transforming data, model selection, model training, cross-validation and deployment at scale.
Academic or Project Experience with Machine and Deep Learning toolkits such as MXNet, TensorFlow, Caffe and PyTorch.
Academic Experience with Big Data platforms like Apache Spark and Hadoop.
Familiarity with data processing with Python, R & SQL.
Familiarity with AWS services related to AI/ML highly desirable, particularly Amazon EMR, AWS Lambda, SageMaker, Machine Learning, IoT, Amazon DynamoDB, Amazon S3, Amazon EC2 Container Service, Green Grass etc.",-1.0,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,ADCI - Karnataka,0,-1,1,1,1,1
Principal Data Scientist,"Yodlee’s Data Science team is driving innovations using Big Data at Yodlee. We have a high-caliber, focused and a mission-driven culture for our teams. The models we build and the analysis that we derive from financial data matters to crucial cutting-edge business decisions made across the global financial services firms every day and solves real world problems. We are leveraging our deep expertise in financial data to launch innovative solutions into the Financial Services Industry.

Description

You need to be a thinker. We are looking for a very curious data scientist who enjoys a deep dive into the raw data to help figure out the right set of questions and find the answers to those questions.

You also need to be a doer. You will be responsible for data cleansing, transformation and creating predictive models and classifiers.

You need to be smart and build smart products. A big part of this job is about creating actionable insights for our customers and the business using machine learning and statistical techniques. Translate analytic insights into concrete, actionable recommendations for business or product improvement.

You need to be ambitious. You must be passionate about applying mathematical modeling to solve real world problems. You must be willing to work with a team of modelers on cutting-edge prediction techniques who knows the best practices around modeling and validation. And more than anything, you must love to turn ideas into reality. If you are the happiest when you can prove the impact of statistical models/machine learning in generating business impact, let us know.

Required Skills and Experience:
8+ years of experience in the area of data science/machine learning (OR) PhD degree specializing in a relevant field such as Probability, Statistics, Machine Learning, Data Mining, Artificial intelligence/Computer Science.
Deep understanding of statistical modeling/machine learning/ data mining concepts
Strong analytical and quantitative problem solving ability
Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data, to folks across various levels of the company.
Experience in managing high performance teams",-1.0,Envestnet | Yodlee,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Envestnet | Yodlee,0,-1,0,0,0,0
Lead Data Scientist,"Brillio is forging ahead aggressively amidst the current COVID-19 situation and continues to hire for various roles globally - with all interviewing and on-boarding done virtually. Brillio has invested in the right capabilities to adapt to the new normal and empower its employees to operate seamlessly. All the new joiners, along with the Brillio family, will temporarily work remotely until it is safe to return to our offices. Read Brillio’s Chief Operating and Delivery Officer, Aftab Ullah’s statement about Brillio's hiring plans in the leading publications - The Times of India and The Week’s latest stories about the positive hiring sentiments of tech firms.



As a Brillian what your day would look like:

o Take ownership of large-scale data science engagements and drive end-to-end solutions that have efficient and productionable algorithms, and communicate relevant insights to stakeholders through storyboards/presentations

o Engage and mentor those around you in advanced statistical analysis concepts and foster data driven thinking

o Stay abreast with current technical and industry development and constantly strive to devise innovative statistical models for data analysis

o Communicate with multi-disciplinary teams, internal and external stakeholders define problems, uncover insights hidden in large data sets that drive impactful business decisions

o Actively participate in external forums and industry conclaves



To succeed, you’d have technical experience and expertise in –

A. For you to be successful, you must:

o Build partnerships within and outside the team regardless of formal authority

o Create value by anticipating and meeting needs of customers and delivering high-quality results and be accountable for outcomes

o Disseminate personal knowledge, share own experiential learning with others and empower others by mentoring those around you

o Be open and flexible to accommodate and implement new ideas, understand business complexities, nurture innovation and challenge the status quo persistently

o Be subject matter expert in chosen area of specialty through continuous learning

o Have an eye for detail to ensure accurate conclusions in data analysis and presentations

B. For you to be successful, you must: -

o Critical Thinking in order to drive end-to-end solutions to ambiguous problem; with excellent sense of risk and resource management

o Strong analytical skills with the ability to collect, organize, review significant amounts of information

o Strong problem-solving skills with an emphasis on product development

o Experience using statistical computer languages (R, Python, SAS) to manipulate data and draw insights from large data sets

o Expertise in basic statistical concepts such as properties of distributions, statistical tests and their proper usage

o Expertise in advanced machine learning techniques such as Clustering, Regression/Classification, Time Series Analysis, Network Analysis, Popular Deep Learning architectures and theory, simulation, scenario analysis

o Experience with some optimization techniques (Linear Programming, Genetic Algorithm, Sim. Annealing, MC Simulation)

o Clear, professional written and verbal communication skills, ability to easily communicate complex ideas

o Experience with any distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, etc. or AWS/Azure

o Experience with machine learning on big data

C. It would be exceptional, if you also have this:

o Expertise in Image, Video, Speech, Sound, Text domain

o Working knowledge of concepts and application of Design of Experiments

o Depth across areas within the domain or industry",3.1,"Brillio
3.1",Bengaluru,"Santa Clara, CA",1001 to 5000 employees,2014,Company - Private,IT Services,Information Technology,₹10 to ₹50 billion (INR),-1,"Brillio
",0,6,1,1,1,1
"Director, Engineering","Danaher Digital

Danaher Digital is our digital innovation, incubation and acceleration center where were bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danahers digital innovation journey by partnering with Danaher operating companies to develop and commercialize emerging and disruptive digital technologies such as AI, Machine Learning (ML), Big Data, IoT, Augmented Reality (AR), Cloud (SaaS/PaaS) and other Digital frontiers. If you are driven to forge new disruptive and transformative digital apps, platforms and services by working with such cool and emerging technologies, you belong in Danaher Digital.

As a member of Danaher Digital, you will help identify new product ideas and operating models, and then design, develop and deliver them. Working together with our operating companies, you will also help foster and support an entrepreneurial culture that will push Danaher to launch new software and data products better, and faster.

To learn more about Danaher Digital and our team, please visit www.danaherdigital.com or visit www.linkedin.com/company/danaher-digital/about.

Position Description

You will report to the VP & GM of Danaher Digital and are responsible for developing the Danaher Digital engineering team and lead the India build-out and operations.
While developing the strategy, vision and plans for Danaher Digital site in India, you will lead a team of highly skilled Architects, IoT/Edge Engineering, Data & ML Engineering and DevOps to inspire, innovate, develop and accelerate IoT/Edge and Data Analytics solutions for Danaher OPCOs.
You will be comfortable to be simultaneously part adviser, part evangelist, part product manager, part architect and visionary, part engineering manager and part operations maestro for our software engineering initiatives in India.

Responsibilities

• Develop a vision, drive and manage the execution of that vision, and deliver top-tier results while load balancing and prioritizing efforts across strategy, leadership and software development operations for Danaher Digital site in India
• Drive success of all work activities across multiple software engineering disciplines, without requiring daily direction from other Danaher Digital leadership.
• Build, develop, inspire and lead a team of highly skilled associates in different functional roles; raise the bar relative to the best of the best in the external software market place.
• Hire, develop and motivate staff across multiple disciplines, monitoring performance, adjusting as necessary. Mentor staff, and ensure backup and team resiliency
• Connect and understand multiple technical disciplines and market segments across Danaher OPCOs. Provide hands-on detailed technical mentorship to development and operations teams to meet product deliverables and highest quality benchmarks.
• Work closely with leadership across Danaher Digital globally to ensure that tactical needs are understood and that the work of the India team(s) is clearly delineated and fully understood. Some of your teams may be working in a matrix reporting structure with Danaher Digital leaders in the US.
• Own and drive accountability for success (timeliness, velocity, completeness, quality, cost) of all product work and assignments.
• Define and lead daily operational and risk management and risk mitigation processes, tools and techniques. Provide transparent and effective status reports on activities, including risk mitigation.
• Design and deploy industry best practices; raise the bar on software innovation and processes across Danaher, including but not limited to Agile/Scrum/SAFe, SDLC, Release Management, Metric Reporting, DevOps, Data and ML validations/governance, and more.
• Develop, monitor and report financials and cost forecasting to ensure best-in-class productivity and synergies via highest quality cost management of engineering operations. Provide presentations and reports on programs, costs, and KPIs.
• Ensure compliance and ethical behavior without exception.
• Travel to other domestic and/or international locations as required (about 25% on average).

Minimum Qualifications:

More specifically, it is anticipated that the ideal candidate will possess the following direct experiences and skills during their progressive career (as they relate to the specified technology domains below):
Technology Acumen & Vision
• Broad knowledge and is frequently described as visionary. Strong Cloud, IoT platforms, Edge Computing and/or Data & Machine Learning platforms related technology foundations with solid understanding of disruptive technologies and developing innovative software solutions leveraging contemporary cloud-native and data-first SaaS/PaaS solutions or IoT platforms.
• Strong technical expertise in software development, architectural patterns and tradeoffs, and operations acumen, with years of experience leading in high growth companies that leverage IoT, Data, cloud or SaaS/PaaS solutions (preferably in industrial, life sciences, healthcare or manufacturing markets).
• Designed, developed, deployed and scaled end-to-end cloud-based and hybrid (on-premise) cloud or SaaS/PaaS solutions (preferably IoT and Edge solutions) including backend micro- services and APIs as well as customer-facing user experiences (mobile and web apps).
• Successful years of experience in developing customer-facing and market-selling contemporary software services and applications
Setting Strategy
• Prior experience communicating the vision and strategy in bold, persuasive terms gaining buy-in from all relevant stakeholders. S/he will be accessible, yet an independent thinker, embracing and synthesizing disparate views. Experience managing what if scenarios and managing a high degree of ambiguity well.
• Ability to define issues clearly, despite ambiguity and take a holistic perspective when making decisions.
• Experience of strong awareness of both external and internal best practice perspectives, anticipating industry and product trends, capability prioritization and tradeoffs, balancing business needs versus technical and resource constraints. All while maintaining a balanced and fresh viewpoint.
• Experience defining and deploying effective, efficient and scalable engineering organizational strategies, hiring and talent building strategies.
Executing for Results
• Distinct track record of demonstrating Organizational Agility by balancing the role of strategist with simultaneously setting and achieving aggressive short and long-term milestones and metrics, managing and delivering results in a high-urgency, high-growth environment.
• Distinct track record of software product engineering operational excellence and program management.
• Proven experience rapidly building and growing large engineering teams in India.
• Prior experience of owning and driving accountability for success (timeliness, velocity, completeness, quality, cost) of all product work and initiatives.
• Proven experience in building and maintaining budget plans, forecasts, tracking and overall financial managements of software development and engineering operations/DevOps teams
• Prior experience of superior organizational skills and an affinity for detail. Track record of simultaneously managing multiple, mission-critical projects and the flexibility to adapt to changing priorities.
• Broad and Deep understanding of technology best practices, including, but not limited to: agile SDLC, release management, metric tracking, DevOps, ITIL, and cloud-based service management, and have implemented best practices in a former role with proven results.
Leading Teams
• Successful track record to attract, retain, coach, develop, and mentor IoT/Edge or Data/ML specialists and product management talent. Created a culture of openness and collaboration that fosters innovation. Inspired others to achieve results.
• Demonstrated acumen in organizational change and design for best-in-class contemporary SaaS/PaaS solutions.
• Exceptional interpersonal and leadership skills servant leader with the ability to collaborate, leading through influence across a complex, global organization to drive direction. Strong facilitation and negotiation skills.
• Proven ability to explain complex technical issues in a way that non-technical people and senior leadership may understand
Building Relationships and Using Influence
• Strong communication and influencing skills with the ability and personal style to inspire confidence and work successfully with varied audiences.
• An engaging, open, genuine personality that naturally encourages interaction with individuals at all levels.
Other qualifications:
• 10+ yrs in senior management/executive leadership roles in software product management and/or engineering. 15+ yrs total in software engineering and/or product management
• Compelling leadership style, consistent with Danaher values and culture. Presence and stature to generate respect, trust and a positive image for the organization; credibility through demonstrated expertise.
• Highest levels of personal and professional integrity and ethics.
• Likes to win, has fun doing it, and energizes the organization around a winning agenda
• Bachelors degree in Computer Science, Engineering, or related discipline. MS or MBA preferred.

Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,0,0,0,1
Advanced Analytics Cons 3,"About Enterprise Global Services Enterprise Global Services (EGS) enables global talent capabilities for Wells Fargo Bank NA., by supporting over half of Wells Fargo's business lines and staff functions across Technology, Business Services, Risk Services and Product, Analytics and Modeling (PAM). EGS operates in Hyderabad, Bengaluru and Chennai in India and in Manila, Philippines. Learn more about EGS at our International Careers website Department Overview Product, Analytics and Modeling (PAM) brings a team member-based approach to the international talent pool focusing on analytical requirements. PAM encompasses roles that deliver meaningful insights, analysis and reporting based on skills, experience and judgment to support the Enterprise Analytics and Data Science (EADS) organization operate successfully today, and continue on the right trajectory to operate successfully in the future. About the Role Analytic Consultant/Data Scientist is a partner-facing role and is responsible for delivering high impact analytic and data science projects by using analytics, in support of operational risk initiatives across consumer lending. This role supports analytics requirements for Credit Bureau Oversight and Quality reporting along with reporting for Issues Management. EADS is the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargos analytic community. We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this highly consultative and visible role, you will support development analytic projects from multiple business lines using various technology and techniques ranging from but not limited to supervised, unsupervised and semi-supervised machine learning, deep-learning, NLP, optimization algorithms in both edge nodes and in big data environments (like hortonworks, MapR, Aster etc.) Responsibilities : Person would be required to work individually or as part of a team on data science projects and work closely with business partners across the organization. He/she would be developing statistical/machine learning models using various techniques (supervised, unsupervised, semi-supervised) and technologies including but not limited to SAS, R, Python, Spark, H2O, Aster etc. Work closely with data engineers, BI and UI specialists and deliver top notch analytical solution for the bank. Define business problem and translate it into analytical problem. 49159",3.6,"Wells Fargo
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1,"Wells Fargo
",0,168,1,1,0,0
"Software Developer, Cloud Services Engineering","Software Engineer Cloud Platform Services

Company Overview

Danaher Corporation:

Danaher is a global science and technology innovator with more than 59,000 associates committed to helping our customers solve complex challenges and improve quality of life around the world. Our world class brands have unparalleled leadership positions in some of the most demanding and attractive industries and our technologies address a broad range of societal needs:
Protecting the global water supply and ensuring environmental stewardship
Protecting the world's food supply and verifying pharmaceutical dosages and authenticity
Leading scientific research and advancing patient health with the highest diagnostic confidence
Improving dental outcomes and promoting access to comfortable patient care around the world Danaher generates over $18 billion USD of annual revenue from five business segments: Life Sciences, Diagnostics, Dental, Water Quality, and Product Identification.
For additional company details, see www.danaher.com.

Danaher Digital:

Danaher Digital is our digital innovation, incubation and acceleration center where were bringing together the leading strategic product and business leaders, technologists and data scientists for the common purpose of accelerating development and commercialization of disruptive and transformative digital solutions into the marketplace.

We accelerate Danahers digital innovation journey by partnering with Danaher operating companies

(OPCOs) to monetize and commercialize the potential of emerging and disruptive digital trends such as AI, Machine Learning (ML), Big Data, IoT, Augmented Reality (AR), Cloud (SaaS/PaaS) and other Digital frontiers. If you are driven to forge new disruptive and transformative digital apps, platforms and services by working with such cool and emerging technologies, you belong in Danaher Digital.

True to Danahers shared purpose of Helping Realize Lifes potential, we work alongside industrys leading companies in large, diverse and growing markets segments from industrials to environmental sciences to life sciences to medical diagnostics. If you are inspired by and motivated to create true impact on lives and industries, at a scale and breadth that Danaher is uniquely positioned for, then you belong in Danaher Digital.

If you thrive in startup-like environments where you can envision, architect and rapidly build hi-tech solutions that are literally ground-breaking in the diverse markets Danaher is uniquely positioned to lead, then Danaher Digital is where you want to be.

Located in Silicon Valley, the heart of global innovation, Danaher Digital is ideally situated to capitalize on the digital mega trends transforming our world. And now we are establishing a strategic talent and innovation hub in Indias Silicon Valley Bangalore, with broad ranging product capabilities and leadership.

Position Description


As a SW Engineer for our IoT, Data, and Analytics Cloud Platform, you will join a team of skilled software engineers developing the next generation cloud platform for Danaher. You will drive Danahers Digital transformative initiatives in IoT, Data and Analytics (Machine Learning) applications targeted at multiple market segments such as Life Sciences, Diagnostics, Industrial manufacturing and environmental sciences. You will be responsible for designing and implementing highly scalable, distributed, reliable cloud-native platform that will serve as the backbone of Danahers digital platforms. You will apply your knowledge and proficiency in architecting and coding software components using cutting edge IoT and big data technologies that run on AWS (preferred) or Azure IaaS or PaaS infrastructure. You will work on Event driven systems that interact with back end databases and other services. You will be called upon to solve complex analytical problems independently as well as with your team members. You will work with a globally distributed agile team in a fast-paced environment.

We are looking for talented, passionate Cloud Platform Engineers to join our cloud engineering team and develop our new large scale, high-performance digital platform. You will be part of a new team that has been tasked with building the next generation, highly available, global scale, multi-cloud PaaS platform with open source technologies to enable and accelerate Danahers growth. You will get to be a technology thought leader, evangelize new, cutting edge technologies and solve complex problems.

Responsibilities
Design, develop, and deploy highly scalable backend cloud microservices based on distributed systems using Java
Design and implement serverless services based on AWS and/or Azure cloud components.
Design and develop event driven systems.
Interact with both business and technical stakeholders to deliver high quality products and services that meets/exceeds business customer, and technical requirements.
Work with geographically distributed teams while maintaining highest standards in collaboration and communication.
Contribute to the team charter to design and build a highly scalable and resilient platform services utilizing Kubernetes cluster.
Establish best practices and standards for software development.
Requirements
Proven hands-on experience (5+ years) in developing highly scalable, distributed backend RESTful APIs and back-end services
Experience in building products utilizing Java based services on Big Data Platforms
Proven hands-on experience (3+ years) in developing solutions using AWS Cloud services such as AWS Lambda, AWS S3, AWS DynamoDB, AWS EMR SPARK or equivalent, Cloud Formation, or other Big-Data solutions (Cloudera, Hortonworks, Databricks); Equivalent experience in Microsoft Azure will also be considered
Experience in multiple programming languages: Java/ Python/Javascript
Energetic and passionate about being successful and open to different technologies; Be familiar and comfortable with new technologies, trade-offs and emerging design patterns
Experience designing and developing collection and storage for big data solutions using one or more of the following: MySQL, MongoDB, Cassandra, Elasticsearch, Redshift, ObjectStore, timeseries databases, HDFS/HBase, etc.
Deep understanding of Object Oriented Programming; Solid understanding and experience of
Domain Modeling in relational and non-relational databases
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing and operations
Clear written and verbal communications skills; Attention to detail, self-motivated, creative and flexible; Excellent time management and organizational skills.
A proven team player and problem solver with the ability to work collaboratively to brainstorm, uncover key issues, troubleshoot and recommend/implement solutions
Degree in Computer Science or a related field
Willingness to travel (<10>
Preferred Requirements:
Experience and knowledge of Git, JIRA, and Jenkins.
Machine learning, AI and deep learning technologies experience.
Experience in digital health industry with HIPAA compliance training
Experience with agile development methodology; Ability to work with multi-geography/site teams.
Good knowledge of distributed systems, APIs, cloud computing.
An automation mindset including monitoring, reporting, iterating and CI/CD practices
Familiarity with authentication & authorization standards (e.g. OAuth 2.0, SAML) multi-factor authentication, and IDP integrations
Experience in any one or more of the following technologies:
HDFS/Hbase
Spark/Kafka/Kinesis
Kubernetes clustering
Splunk
Restful APIs
Maven/Jenkins/Gatling/JMeter
SQL and key-value store
Dockers & Containerization
SpringBoot framework
Functional (serverless) programming
Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The EEO is the Law poster is available here.",-1.0,Danaher Digital,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Danaher Digital,0,-1,1,1,1,1
Data Scientist,"About Mate Labs (https://www.matelabs.ai/):

Mate Labs is looking for a kick-ass and enthusiastic Data Scientist who has a really good understanding of machine learning and deep learning. We love GitHub and open source projects. We look for guys who are passionate for open source projects and contributions.

Mate Labs has built Mateverse for Data Analysts so that they can build customized machine learning and data science models for quick prediction like sales forecasting without writing even a single line of code.

At Mate Labs, we are solving a unique problem of algorithm & Hyperparameter selection in the field of Artificial Intelligence.

Job Responsibilities:

Be working on client projects, majorly on the solutions.

Be working with Regression Algorithms (Linear Regression, Logistic Regression, Polynomial Regression, Ridge Regression, Lasso Regression etc.)

Be working with ARIMA and LSTMs for time-series forecasting

Be working with custom Mateverse algorithms

Be working with technologies like Scikit-learn, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Be building mathematical models and implementing it in Python (preferably).

Skills Required:

Machine Learning Algorithms(Regression(MUST)& Time-series forecasting (MUST), Classification, Clustering)

Frameworks - Scikit-learn, Keras, Tensorflow, Pandas, Numpy, Scipy, Matplotlib, Seaborn and Statsmodels

Has worked on multiple business use-cases.

SAS or equivalent, Tableau or any other data preparation tools.

Requirements:

2 - 3 years of experience

B.Tech graduate.

Benefits:

Startup culture (immense scope to learn and grow).

Amazing team to work with.

Health Insurance for the employees.

A lot of freedom to experiment with new things.",-1.0,Matelabs Innovations Pvt. Ltd.,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Matelabs Innovations Pvt. Ltd.,0,-1,1,0,0,0
Advanced Analytics Cons 4,"About Enterprise Global Services Enterprise Global Services (EGS) enables global talent capabilities for Wells Fargo Bank NA., by supporting over half of Wells Fargo's business lines and staff functions across Technology, Business Services, Risk Services and Product, Analytics and Modeling (PAM). EGS operates in Hyderabad, Bengaluru and Chennai in India and in Manila, Philippines. Learn more about EGS at our International Careers website Department Overview Product, Analytics and Modeling (PAM) brings a team member-based approach to the international talent pool focusing on analytical requirements. PAM encompasses roles that deliver meaningful insights, analysis and reporting based on skills, experience and judgment to support the Enterprise Analytics and Data Science (EADS) organization operate successfully today, and continue on the right trajectory to operate successfully in the future. About the Role Analytic Consultant/Data Scientist is a partner-facing role and is responsible for delivering high impact analytic and data science projects by using analytics, in support of operational risk initiatives across consumer lending. This role supports analytics requirements for Credit Bureau Oversight and Quality reporting along with reporting for Issues Management. EADS is the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargos analytic community. We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this highly consultative and visible role, you will support development analytic projects from multiple business lines using various technology and techniques ranging from but not limited to supervised, unsupervised and semi-supervised machine learning, deep-learning, NLP, optimization algorithms in both edge nodes and in big data environments (like hortonworks, MapR, Aster etc.) Responsibilities : Person would be required to work individually or as part of a team on data science projects and work closely with business partners across the organization. He/she would be developing statistical/machine learning models using various techniques (supervised, unsupervised, semi-supervised) and technologies including but not limited to SAS, R, Python, Spark, H2O, Aster etc. Work closely with data engineers, BI and UI specialists and deliver top notch analytical solution for the bank. Define business problem and translate it into analytical problem 49162",3.6,"Wells Fargo
3.6",Bengaluru,"San Francisco, CA",10000+ employees,1852,Company - Public,Banks & Building Societies,Finance,₹500+ billion (INR),-1,"Wells Fargo
",0,168,1,1,0,0
Data Scientist,"Apply Now

Understanding and experience with leading supervised and unsupervised machine learning methods such as GLM/Regression, Logistic Regression, Neural Networks, Deep Learning, KNN, Naive Bayes, SVM, Decision Trees, Random Forest, Gradient Boosting, Ensemble Methods, Text Mining, Social Network Analysis, Unobserved Components Modeling (UCM) and Use Scenario based Optimization Techniques.
Should be a Data Scientist with extensive predictive Modeling and Machine Learning Experience. The Candidate will be responsible for conducting data analysis and developing predictive models leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for sales and marketing organization.
Candidate should have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

For more details, Contact :
+91 - 7022998695",-1.0,Shiras HR Advisory & Services,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,Shiras HR Advisory & Services,0,-1,0,0,0,0
Applied Scientist,"Bachelor’s/Master Degree in Computer Science with advanced degrees preferred.
5+ years of hands on experience in building machine learning systems for large data sets.
Strong skills in problem solving, programming and computer science fundamentals.
Expertise in using Python, Java / C++, or other programming languages, as well as ML toolkits such as scikit-learn, Theano, Tensorflow, Keras or similar machine learning tools.
Amazon’s Selection Monitoring team is responsible for making the biggest catalog on the planet even bigger. We build software to find products not already sold on Amazon and algorithmically add them to the Amazon catalog. Our work involves building Information Retrieval (IR) infrastructure, Machine Learning systems, and distributed compute and storage systems to process data at cloud-scale to extend and enrich the Amazon catalog. We apply the state- of- the-art Web-mining, Cloud Computing and Deep Learning to process millions of products from the web every day and make the data actionable. We constantly stretch the boundaries of Machine Learning to tackle business challenges. If you are customer obsessed, self-driven, tenacious and analytical, you will have fun solving our business problems of unprecedented scale. As an experienced machine learning scientist, you will help research and develop new computer algorithms leveraging both classical and deep learning techniques.

We are looking for ML Scientist to tackle challenging problems in the areas of information retrieval at internet scale using data science. You should have depth and breadth of knowledge in text mining, information retrieval and deep learning. You should also have programming and design skills to manipulate unstructured data and systems that work at internet scale.

You will encounter many challenges, including
Scale (build models to handle billions of pages),
Accuracy (extreme requirements for precision and recall),
Speed (generate predictions for millions of new or changed pages with low latency),
Diversity (models need to work across different languages, market places and data sources)
Come join us in our journey to make everything – and yes, we do mean *everything* – that anyone wants to buy, available on Amazon!
PhDs, specialized in Information Retrieval and Machine Learning.
Experience in designing and implementing information retrieval, web mining systems using Deep Learning and Neural Networks.
Big thinker that can take broad visions and concepts and develop structured plans, actions and measurable metrics and then execute those plans.",-1.0,ADCI - Karnataka,Bengaluru,-1,-1,-1,-1,-1,-1,-1,-1,ADCI - Karnataka,0,-1,1,0,0,0
